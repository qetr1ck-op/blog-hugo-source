[
    {
        "uri": "/about",
        "title": "Orest Prystayko",
        "content": "\nFront End Developer @ Eleks\n\nI try to learn something new every day. It may relate to personal finances, physical health, algorithms, computer programming. And the learning process might take place for a few minutes or from sunrise to sunset. I believe that every time when I achieve new knowledge, I typically observe how increase my quality of live.\n\nlinkedin\ngithub\ntwitter\nfacebook\n",
        "tags": []
    },
    {
        "uri": "/content-types",
        "title": "",
        "content": "",
        "tags": []
    },
    {
        "uri": "/post/5-principles-that-will-make-a-more-SOLID-Javascript-Engineer",
        "title": "5 principles that will make a more SOLID Javascript Engineer",
        "content": "\nBeing a SOLID developer in JS isn't so as straight forward as in other languages. Some developers consider functional approach. Others chose OOP style. Some stand in both line. And other think that having class is wrong and redundant and prefer factories. But still, SOLID principles are the basic pillars of object oriented programming.\n\nBut what are they?\n\n!--more--\n\nThe SOLID principles are: \n\n*S* - Single responsibility principle\n*O* - Open-Close principle\n*L* - Liskov Substitution principle\n*I* - Interface segregation principle\n*D* - Dependency Inversion principle\n\n Single responsibility principle\n\nVery similar to Unix slogan: \n\n \"Do one thing and do it well\"\n\nThis one is easy to comprehend but harder to implement. Every function should do exactly one thing. It should have \none clearly defined goal.\n\nSo were should we draw a line to decouple on big peace of code. I have 2 basic strategies for dealing with complexity:\n\nIf you find yourself writing/calling function loginUserAndSaveToken() you're probably breaking the SRP. Break \nthis function into two separate ones.\nFor every function imagine if there are possibility to extract reusable part to not repeat your self.\n\nBut there is a tricky moment.\n\nUsing this logic, runFacebook() is indeed a single responsible function. But this only applies as long as the body \nof function runFacebook() is implemented correctly in small divided functions. \n\nOpen-Close principle\n\nIt means that our module should be open to extension, but closed to modification.\n\nMeaning is simple, if someone wants to extend your module behavior, they won't need to modify existing code if they \ndon't want to.\n\nThere is a easy rule to follow here: \n\nIf you have to open a JS file and need to make a modification there, in order to extend it - you've failed OCP\n\nclass IceCreamMachine {\n    constructor() {\n        this.flavors = ['chocolate', 'vanilla'];\n    }\n    create() {\n        if (this.flavors.includes(flavor)) { // warning, ES7 Array.prototype.includes\n            console.log('Great success. You now can eat your ice cream');\n        } else {\n            console.log('A bad choice, not ice cream today');\n        }\n    }\n}\n\nexport default IceCreamMachine\n\nAs far as you can see there's no way to add new ice cream flavor without literally open the module and edit \nIceCreamMachine.flavors array.\n\nTo follow OCP we can easily change that:\n\nclass IceCreamMachine {\n    constructor() {\n        this.flavors = ['chocolate', 'vanilla'];\n    }\n    create() {\n        if (this.flavors.includes(flavor)) {\n            console.log('Great success. You now can eat your ice cream');\n        } else {\n            console.log('A bad choice, not ice cream today');\n        }\n    }\n    flavorAdd(flavor) {\n        this.flavors = [...this.flavors, flavor];\n    }\n}\n\n Liskov Substitution Principle\n\nThis is one of the most obscure name I've ever seen in programming world. \n\nAnd even more the classical description is: \n\n \"Child classes should never break the parent class type definition.\"\n\nWhat a tough explanation. I'll make it more simple:\n\n \"It means that we must make sure that new derived classes are extending the base class without changing their behavior.\"\n\nTo illustrate we will go with classical example with:\n\nclass Rectangle {\n    constructor() {\n        // init procedure\n    }\n    setWidth(width) {\n        this.width = width;\n    }\n    setHeigth(height) {\n        this.height = height;\n    }\n    getArea() {\n        return this.width * this.height;\n    }\n}\n\nWe start with basic geometry abstraction Rectangle. Imagine that is a working and already is deployed to several clients.\n\nNow we need a new feature. A possibility to manipulate Square's.\n\nIn real life, in geometry, a square is a form of rectangle. So we could try to implement Square class that extends Rectangle.\n\nBut is a Square really a Rectangle in programming?..\n\nclass Square extends Rectangle {\n    constructor() {\n        super();\n        // init procedure\n    }\n    setWidth(width) {\n        this.width = width;\n        this.height = width;\n    }\n    setHeigth(height) {\n        this.height = height;\n        this.width = height;\n    }\n}\n\nA square is a rectangle with equal width and height, and we do a strange implementation like in example above. \nWe overwrite both setters.\n\nSo, our Square class isn't a Rectangle after all. \n\nIt breaks the law of geometry. It fails the LSP principle.\n\nInterface Segregation principle\n\nThe SRP is about actors and high lever architecture. \nThe OCP is about design and feature extension.\nThe LSP is about sub-typing and inheritance.\nAnd the ISP is about business logic to client communication.\n\n \"Interface Segregation actually means you shouldn't create bloated interfaces\"\n\nSince JS doesn't have an interfaces, I'm going to use more abstractive description.\n\nSo how should we define our interfaces? We could thing about our model and expose all functionality we want it to offer:\n\nLet's say your friend created a brand new HTML5 route library. He convinced you to implement it in your project.\n\nYou start to play around and register the first route via registerRouter(routeName). And you thing all are set up.\n\nBut your friend lied.\n\nHe forgot to mention that you also need to implement onErrorHandler() and handleIE8() for every your registered route.\n\n \"The lesson is whenever you expose a module, make sure only essential are required, everything else is optional. Otherwise your friends will hate you.\"\n\n Dependency Inversion Principle\n\nYou've might heard about dependency inversion as a standalone term. Dependency Injection and Inversion of Control also mean the same.\n\n \"A. High-level modules shouldn't depend on low-level modules. Both should depend on abstraction.\"\n\n \"B. Abstraction shouldn't depend upon details. Details should depend on details.\"\n\nDI is all about handling over control from the function itself to the caller function. In our case it means defining who controls the type of parameters the function receives. Let's use an example.\n\nWe've started to use an event emitter implementation. Your old functionality looks like this:\n\nfunction awesomeFoo(dispatcher) {\n    dispatcher.trigger('awesome/foo');\n}\n\nfunction awesomeFooListener(dispatcher) {\n    dispatcher.on('awesome/foo', event = {\n        console.log(event)\n    };    \n}\n\nThere is one problem. New dispatcher methods are called with emit() and listen().\n\nYou could refactor your code. But what if implementation isn't all that great.\n\n \"You'd like to be able easily switch between implementations\"\n\nYou realize that you don't need the whole dispatcher object in every function. You change your code to receive only the relevant methods for every function:\n\nfunction awesomeFoo(dispatcher) {\n    dispatch('awesome/foo');\n}\n\nfunction awesomeFooListener(dispatcher) {\n    listen('awesome/foo', event = {\n        console.log(event)\n    };    \n}\n\nYour code now doesn't depend on any concrete implementation of event emitter object.\n\nIt does depend on abstraction. You can now freely switch between new/old implementation or even use a mock implementation for testing.\n\nSave my day:\n\nThe Full Stack\nAspiring Craftsman\ncode.tutsplus",
        "tags": []
    },
    {
        "uri": "/post/Article-Intro-Effects-Examples",
        "title": "Article Intro Effects Examples",
        "content": "\nMost of the effects we tried are highly experimental; animating large images can become a bit sluggish, also because a couple of transitions happening at the same time. The effect gets triggered when scrolling begins  or when the button is clicked.\n\n!--more--\n\nSaveMyDay:\n\non tympanus.net",
        "tags": []
    },
    {
        "uri": "/post/Awesome-terminal-emulator-for-Windows",
        "title": "Awesome terminal emulator for Windows",
        "content": "\nCmder is a software package created out of pure frustration over the absence of nice console emulators on Windows. It is based on amazing software, and spiced up with the Monokai color scheme and a custom prompt layout. Looking sexy from the start.\n\n!--more--\n\nDownload here\n\nInstruction to add cmder to context menu.",
        "tags": []
    },
    {
        "uri": "/post/Bootstrap3-Components",
        "title": "Bootstrap 3: Components",
        "content": "\nSet of standard components from popular library.\n\n!--more--\n\nIcons\n\nUse them in buttons, button groups for a toolbar, navigation, or prepended form inputs.\n\np data-height=\"268\" data-theme-id=\"10606\" data-slug-hash=\"zAupx\" data-default-tab=\"result\" data-user=\"qetr1ck-op\" class='codepen'See the Pen a href='http://codepen.io/qetr1ck-op/pen/zAupx/'Bootstrap Components: Icons Examples/a by qetr1ck-op (a href='http://codepen.io/qetr1ck-op'@qetr1ck-op/a) on a href='http://codepen.io'CodePen/a./p\nscript async src=\"//assets.codepen.io/assets/embed/ei.js\"/script\n\n Dropdowns\n\nWrap the dropdown's trigger and the dropdown menu within .dropdown, or another element that declares position: relative;. Then add the menu's HTML:\n\nVia data attributes or JavaScript, the dropdown plugin toggles hidden content (dropdown menus) by toggling the .open class on the parent list item. When opened, the plugin also adds .dropdown-backdrop as a click area for closing dropdown menus when clicking outside the menu.\n\nCall the dropdowns via JavaScript: $('.dropdown-toggle').dropdown() or use data-toggle=\"dropdown\".\n\nFull list Dropdown methods\n\np data-height=\"268\" data-theme-id=\"10606\" data-slug-hash=\"yoehq\" data-default-tab=\"result\" data-user=\"qetr1ck-op\" class='codepen'See the Pen a href='http://codepen.io/qetr1ck-op/pen/yoehq/'yoehq/a by qetr1ck-op (a href='http://codepen.io/qetr1ck-op'@qetr1ck-op/a) on a href='http://codepen.io'CodePen/a./p\nscript async src=\"//assets.codepen.io/assets/embed/ei.js\"/script\n\nButtons group\n\nGroup a series of buttons together on a single line with the button group. Control via JavaScript: $('.btn').button()\n\nFull list methods\n\np data-height=\"268\" data-theme-id=\"10606\" data-slug-hash=\"qCbxy\" data-default-tab=\"result\" data-user=\"qetr1ck-op\" class='codepen'See the Pen a href='http://codepen.io/qetr1ck-op/pen/qCbxy/'Bootstrap Components: Buttons Group/a by qetr1ck-op (a href='http://codepen.io/qetr1ck-op'@qetr1ck-op/a) on a href='http://codepen.io'CodePen/a./p\nscript async src=\"//assets.codepen.io/assets/embed/ei.js\"/script\n\n Input groups\n\nExtend form controls by adding text or buttons before, after, or on both sides of any text-based input. Use .input-group with an .input-group-addon to prepend or append elements to a single .form-control.\n\np data-height=\"268\" data-theme-id=\"10606\" data-slug-hash=\"Cypci\" data-default-tab=\"result\" data-user=\"qetr1ck-op\" class='codepen'See the Pen a href='http://codepen.io/qetr1ck-op/pen/Cypci/'Bootstrap: Components - Input groups/a by qetr1ck-op (a href='http://codepen.io/qetr1ck-op'@qetr1ck-op/a) on a href='http://codepen.io'CodePen/a./p\nscript async src=\"//assets.codepen.io/assets/embed/ei.js\"/script\n\nNavs\n\nNavs available in Bootstrap have shared markup, starting with the base .nav class, as well as shared states. Swap modifier classes to switch between each style.\n\nNavs via JavaScript: $('myTab a').tab()\n\nFull list methods\n\np data-height=\"762\" data-theme-id=\"10606\" data-slug-hash=\"ousCl\" data-default-tab=\"result\" data-user=\"qetr1ck-op\" class='codepen'See the Pen a href='http://codepen.io/qetr1ck-op/pen/ousCl/'Bootstrap: Copmonents - Navs/a by qetr1ck-op (a href='http://codepen.io/qetr1ck-op'@qetr1ck-op/a) on a href='http://codepen.io'CodePen/a./p\nscript async src=\"//assets.codepen.io/assets/embed/ei.js\"/script\n\nPagination\n\nProvide pagination links for your site or app with the multi-page pagination component, or the simpler pager alternative.\n\nSimple pagination inspired by Rdio, great for apps and search results. The large block is hard to miss, easily scalable, and provides large click areas.\n\np data-height=\"366\" data-theme-id=\"10606\" data-slug-hash=\"zwqHv\" data-default-tab=\"result\" data-user=\"qetr1ck-op\" class='codepen'See the Pen a href='http://codepen.io/qetr1ck-op/pen/zwqHv/'Bootstrap: Components - Pagination/a by qetr1ck-op (a href='http://codepen.io/qetr1ck-op'@qetr1ck-op/a) on a href='http://codepen.io'CodePen/a./p\nscript async src=\"//assets.codepen.io/assets/embed/ei.js\"/script\n\n Labels and Badges\n\nAdd any of the below mentioned modifier classes to change the appearance of a label.\n\np data-height=\"332\" data-theme-id=\"10606\" data-slug-hash=\"Aiywe\" data-default-tab=\"result\" data-user=\"qetr1ck-op\" class='codepen'See the Pen a href='http://codepen.io/qetr1ck-op/pen/Aiywe/'Bootstrap: Components - Labels and Badges/a by qetr1ck-op (a href='http://codepen.io/qetr1ck-op'@qetr1ck-op/a) on a href='http://codepen.io'CodePen/a./p\nscript async src=\"//assets.codepen.io/assets/embed/ei.js\"/script\n\nThumbnails\n\nWith a bit of extra markup, it's possible to add any kind of HTML content like headings, paragraphs, or buttons into thumbnails.\n\np data-height=\"355\" data-theme-id=\"10606\" data-slug-hash=\"rtbqu\" data-default-tab=\"result\" data-user=\"qetr1ck-op\" class='codepen'See the Pen a href='http://codepen.io/qetr1ck-op/pen/rtbqu/'Bootstrap: Components - Thumbnail/a by qetr1ck-op (a href='http://codepen.io/qetr1ck-op'@qetr1ck-op/a) on a href='http://codepen.io'CodePen/a./p\nscript async src=\"//assets.codepen.io/assets/embed/ei.js\"/script\n\n Alerts\n\nProvide contextual feedback messages for typical user actions with the handful of available and flexible alert messages.\n\nFull list methods\n\np data-height=\"268\" data-theme-id=\"10606\" data-slug-hash=\"roLJc\" data-default-tab=\"result\" data-user=\"qetr1ck-op\" class='codepen'See the Pen a href='http://codepen.io/qetr1ck-op/pen/roLJc/'Bootstrap: Components - Alerts/a by qetr1ck-op (a href='http://codepen.io/qetr1ck-op'@qetr1ck-op/a) on a href='http://codepen.io'CodePen/a./p\nscript async src=\"//assets.codepen.io/assets/embed/ei.js\"/script\n\nProgress Bars\n\nProvide up-to-date feedback on the progress of a work-flow or action with simple yet flexible progress bars.\n\np data-height=\"268\" data-theme-id=\"10606\" data-slug-hash=\"acvLq\" data-default-tab=\"result\" data-user=\"qetr1ck-op\" class='codepen'See the Pen a href='http://codepen.io/qetr1ck-op/pen/acvLq/'Bootstrap: Components - Progress Bar/a by qetr1ck-op (a href='http://codepen.io/qetr1ck-op'@qetr1ck-op/a) on a href='http://codepen.io'CodePen/a./p\nscript async src=\"//assets.codepen.io/assets/embed/ei.js\"/script",
        "tags": []
    },
    {
        "uri": "/post/Bootstrap3-CSS",
        "title": "Bootstrap 3: CSS",
        "content": "\nA detailed look for implementation of UI popular library.\n\n!--more--\n\nMobile First\n\nTo ensure proper rendering and touch zooming, add the viewport meta tag:\n\nmeta name=\"viewport\" content=\"width=device-width, initial-scale=1\"\n\nYou can disable zooming capabilities on mobile devices by adding:\n\nmeta name=\"viewport\" content=\"width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no\"\n\n Typography and links\n\nBootstrap sets basic global display, typography, and link styles. Specifically, we:\n\nSet background-color: #fff; on the body\nUse the @font-family-base, @font-size-base, and @line-height - base attributes as our typographic base\nSet the global link color via @link-color and apply link underlines only on :hover\n\nThese styles can be found within scaffolding.less.\n\nNormalize.css\n\nFor improved cross-browser rendering, Bootstrap uses Normalize.css, a project by Nicolas Gallagher and Jonathan Neal.\n\n Media queries\n\nBootstrap includes a responsive, mobile first fluid grid system that appropriately scales up to 12 columns as the device or viewport size increases.\n\nHere's how the Bootstrap grid system works:\n\nRows must be placed within a .container (fixed-width) or .container-fluid (full-width) for proper alignment and padding.\nUse rows to create horizontal groups of columns.\nContent should be placed within columns, and only columns may be immediate children of rows.\nPredefined grid classes like .row and .col-xs-4 are available for quickly making grid layouts. Less mixins can also be used for more semantic layouts.\nColumns create gutters (gaps between column content) via padding. That padding is offset in rows for the first and last column via negative margin on .rows.\nThe negative margin is why the examples below are outdented. It's so that content within grid columns is lined up with non-grid content.\nGrid columns are created by specifying the number of twelve available columns you wish to span. For example, three equal columns would use three .col-xs-4.\nIf more than 12 columns are placed within a single row, each group of extra columns will, as one unit, wrap onto a new line.\nGrid classes apply to devices with screen widths greater than or equal to the breakpoint sizes, and override grid classes targeted at smaller devices. Therefore, e.g. applying any .col-md- class to an element will not only affect its styling on medium devices but also on large devices if a .col-lg- class is not present.\n\nInitial grid system implementation:\n\n/* Extra small devices (phones, less than 768px) */\n/* No media query since this is the default in Bootstrap */\n@media (min-width: @screen-xs-min) { ... }\n\n/* Small devices (tablets, 768px and up) */\n@media (min-width: @screen-sm-min) { ... }\n\n/* Medium devices (desktops, 992px and up) */\n@media (min-width: @screen-md-min) { ... }\n\n/* Large devices (large desktops, 1200px and up) */\n@media (min-width: @screen-lg-min) { ... }\n\nUsing a single set of .col-md-* grid classes, you can create a basic grid system that starts out stacked on mobile devices and tablet devices (the extra small to small range) before becoming horizontal on desktop (medium) devices. Place grid columns in any .row.\n\nStacked-to-horizontal\n\ndiv class=\"row\"\n  div class=\"col-md-1\".col-md-1/div\n  div class=\"col-md-1\".col-md-1/div\n  div class=\"col-md-1\".col-md-1/div\n  div class=\"col-md-1\".col-md-1/div\n  div class=\"col-md-1\".col-md-1/div\n  div class=\"col-md-1\".col-md-1/div\n  div class=\"col-md-1\".col-md-1/div\n  div class=\"col-md-1\".col-md-1/div\n  div class=\"col-md-1\".col-md-1/div\n  div class=\"col-md-1\".col-md-1/div\n  div class=\"col-md-1\".col-md-1/div\n  div class=\"col-md-1\".col-md-1/div\n/div\ndiv class=\"row\"\n  div class=\"col-md-8\".col-md-8/div\n  div class=\"col-md-4\".col-md-4/div\n/div\ndiv class=\"row\"\n  div class=\"col-md-4\".col-md-4/div\n  div class=\"col-md-4\".col-md-4/div\n  div class=\"col-md-4\".col-md-4/div\n/div\ndiv class=\"row\"\n  div class=\"col-md-6\".col-md-6/div\n  div class=\"col-md-6\".col-md-6/div\n/div\n\n Fluid container\n\nTurn any fixed-width grid layout into a full-width layout by changing your outermost .container to .container-fluid.\n\nhtml class=\"container-fluid\"\n  div class=\"row\"\n    ...\n  /div\n/div\n\nOffseting columns\n\ndiv class=\"row\"\n  div class=\"col-md-4\".col-md-4/div\n  div class=\"col-md-4 col-md-offset-4\".col-md-4 .col-md-offset-4/div\n/div\ndiv class=\"row\"\n  div class=\"col-md-3 col-md-offset-3\".col-md-3 .col-md-offset-3/div\n  div class=\"col-md-3 col-md-offset-3\".col-md-3 .col-md-offset-3/div\n/div\ndiv class=\"row\"\n  div class=\"col-md-6 col-md-offset-3\".col-md-6 .col-md-offset-3/div\n/div\n\nMove columns to the right using .col-md-offset-* classes. These classes increase the left margin of a column by * columns. For example, .col-md-offset-4 moves .col-md-4 over four columns:\n\n Grid System Examples\n\np data-height=\"268\" data-theme-id=\"10606\" data-slug-hash=\"qLfBk\" data-default-tab=\"result\" data-user=\"qetr1ck-op\" class='codepen'See the Pen a href='http://codepen.io/qetr1ck-op/pen/qLfBk/'Bootstrap CSS: Grids/a by qetr1ck-op (a href='http://codepen.io/qetr1ck-op'@qetr1ck-op/a) on a href='http://codepen.io'CodePen/a./p\nscript async src=\"//assets.codepen.io/assets/embed/ei.js\"/script\n\nHeadings and Secondary Text\n\nAll HTML headings, h1 through h6, are available. .h1 through .h6 classes are also available, for when you want to match the font styling of a heading but still want your text to be displayed inline.\n\nCreate lighter, secondary text in any heading with a generic small tag or the .small class.\n\nh1h1. Bootstrap heading smallSecondary text/small/h1\nh2h2. Bootstrap heading smallSecondary text/small/h2\nh3h3. Bootstrap heading smallSecondary text/small/h3\nh4h4. Bootstrap heading smallSecondary text/small/h4\nh5h5. Bootstrap heading smallSecondary text/small/h5\nh6h6. Bootstrap heading smallSecondary text/small/h6\n\n Body copy\n\nBootstrap's global default font-size is 14px, with a line-height of 1.428\\. This is applied to the body and all paragraphs. In addition, p (paragraphs) receive a bottom margin of half their computed line-height (10px by default).\n\nMake a paragraph stand out by adding .lead.\n\np class=\"lead\".../p\n\nInline text elements\n\np data-height=\"268\" data-theme-id=\"10606\" data-slug-hash=\"hoLwb\" data-default-tab=\"result\" data-user=\"qetr1ck-op\" class='codepen'See the Pen a href='http://codepen.io/qetr1ck-op/pen/hoLwb/'Inline text element/a by qetr1ck-op (a href='http://codepen.io/qetr1ck-op'@qetr1ck-op/a) on a href='http://codepen.io'CodePen/a./p\nscript async src=\"//assets.codepen.io/assets/embed/ei.js\"/script\n\n Alignment classes\n\nEasily realign text to components with text alignment classes.\n\np class=\"text-left\"Left aligned text./p\np class=\"text-center\"Center aligned text./p\np class=\"text-right\"Right aligned text./p\np class=\"text-justify\"Justified text./p\np class=\"text-nowrap\"No wrap text./p\n\nTransformation clases\n\nTransform text in components with text capitalization classes\n\np class=\"text-lowercase\"Lowercased text./p\np class=\"text-uppercase\"Uppercased text./p\np class=\"text-capitalize\"Capitalized text./p\n\n Abbreviations\n\nStylized implementation of HTML's abbr element for abbreviations and acronyms to show the expanded version on hover. Abbreviations with a title attribute have a light dotted bottom border and a help cursor on hover, providing additional context on hover.\n\nabbr title=\"attribute\"attr/abbr\n\nBlockquotes\n\nFor quoting blocks of content from another source within your document.\n\nAdd a footer for identifying the source. Add .blockquote-reverse for a blockquote with right-aligned content.\n\nblockquote\n  pLorem ipsum dolor sit amet, consectetur adipiscing elit. Integer posuere erat a ante./p\n  footerSomeone famous in cite title=\"Source Title\"Source Title/cite/footer\n/blockquote\n\nblockquote class=\"blockquote-reverse\"\n  ...\n/blockquote\n\n Lists\n\nol\n  li.../li\n/ol\n\nul class=\"list-unstyled\"\n  li.../li\n/ul\n\nul class=\"list-inline\"\n  li.../li\n/ul\n\ndl class=\"dl-horizontal\"\n  dt.../dt\n  dd.../dd\n/dl\n\n* *\n\nCodes\n\nWrap inline snippets of code with code.\n\nFor example, &lt;section&gt; should be wrapped as inline.\n\n User Input\n\nUse the kbd to indicate input that is typically entered via keyboard.\n\nTo switch directories, type kbdcd/kbd followed by the name of the directory.\n\nBasic block\n\nUse &lt;pre&gt; for multiple lines of code. Be sure to escape any angle brackets in the code for proper rendering.\n\npre&lt;p&gt;Sample text here...&lt;/p&gt;/pre\n\nYou may optionally add the .pre-scrollable class, which will set a max-height of 350px and provide a y-axis scrollbar.\n\n Varible\n\nFor indicating variables use the &lt;var&gt; tag.\n\nvary/var = varm/varvarx/var + varb/var\n\nSample output\n\nFor indicating blocks sample output from a program use the &lt;samp&gt; tag.\n\nsampThis text is meant to be treated as sample output from a computer program./samp\n\n Typography Examples\n\nSee the Pen Bootstrap CSS: Typography by qetr1ck-op (@qetr1ck-op) on CodePen.\n\nBasic example\n\nFor basic styling—light padding and only horizontal dividers—add the base class .table to any table.\n\ntable class=\"table\"\n  ...\n/table\n\n Bordered table\n\nAdd .table-bordered for borders on all sides of the table and cells.\n\ntable class=\"table table-bordered\"\n  ...\n/table\n\nHover rows\n\nAdd .table-hover to enable a hover state on table rows within a tbody.\n\ntable class=\"table table-hover\"\n  ...\n/table\n\n Condensed table\n\nAdd .table-condensed to make tables more compact by cutting cell padding in half.\n\ntable class=\"table table-condensed\"\n  ...\n/table\n\nContextual classes\n\nUse contextual classes to color table rows or individual cells:\n\n!-- On rows --\ntr class=\"active\".../tr\ntr class=\"success\".../tr\ntr class=\"warning\".../tr\ntr class=\"danger\".../tr\ntr class=\"info\".../tr\n\n!-- On cells (td or th) --\ntr\n  td class=\"active\".../td\n  td class=\"success\".../td\n  td class=\"warning\".../td\n  td class=\"danger\".../td\n  td class=\"info\".../td\n/tr\n\n Responsive tables\n\nCreate responsive tables by wrapping any .table in .table-responsive to make them scroll horizontally on small devices (under 768px). When viewing on anything larger than 768px wide, you will not see any difference in these tables.\n\ndiv class=\"table-responsive\"\n  table class=\"table\"\n    ...\n  /table\n/div\n\nTable Examples\n\nSee the Pen Bootstrap CSS: Tables by qetr1ck-op (@qetr1ck-op) on CodePen.\n\nscript async src=\"//codepen.io/assets/embed/ei.js\"/script\n\n Basic example\n\nIndividual form controls automatically receive some global styling. All textual input, textarea, and select elements with .form-control are set to width: 100%; by default. Wrap labels and controls in .form-group for optimum spacing.\n\nform role=\"form\"\n  div class=\"form-group\"\n    label for=\"exampleInputEmail1\"Email address/label\n    input type=\"email\" class=\"form-control\" id=\"exampleInputEmail1\" placeholder=\"Enter email\"\n  /div\n  div class=\"form-group\"\n    label for=\"exampleInputPassword1\"Password/label\n    input type=\"password\" class=\"form-control\" id=\"exampleInputPassword1\" placeholder=\"Password\"\n  /div\n  div class=\"form-group\"\n    label for=\"exampleInputFile\"File input/label\n    input type=\"file\" id=\"exampleInputFile\"\n  /div\n  div class=\"checkbox\"\n    label\n      input type=\"checkbox\" Check me out\n    /label\n  /div\n  button type=\"submit\" class=\"btn btn-default\"Submit/button\n/form\n\nInline form\n\nAdd .form-inline to your form for left-aligned and inline-block controls. This only applies to forms within viewports that are at least 768px wide.\n\nFor these inline forms, you can hide the labels using the .sr-only class.\n\nform class=\"form-inline\" role=\"form\"\n  div class=\"form-group\"\n    label class=\"sr-only\" for=\"exampleInputEmail2\"Email address/label\n    input type=\"email\" class=\"form-control\" id=\"exampleInputEmail2\" placeholder=\"Enter email\"\n  /div\n  div class=\"form-group\"\n    div class=\"input-group\"\n      div class=\"input-group-addon\"@/div\n      input class=\"form-control\" type=\"email\" placeholder=\"Enter email\"\n    /div\n  /div\n  div class=\"form-group\"\n    label class=\"sr-only\" for=\"exampleInputPassword2\"Password/label\n    input type=\"password\" class=\"form-control\" id=\"exampleInputPassword2\" placeholder=\"Password\"\n  /div\n  div class=\"checkbox\"\n    label\n      input type=\"checkbox\" Remember me\n    /label\n  /div\n  button type=\"submit\" class=\"btn btn-default\"Sign in/button\n/form\n\n Horizontal form\n\nUse Bootstrap's predefined grid classes to align labels and groups of form controls in a horizontal layout by adding .form-horizontal to the form. Doing so changes .form-groups to behave as grid rows, so no need for .row.\n\nform class=\"form-horizontal\" role=\"form\"\n  div class=\"form-group\"\n    label for=\"inputEmail3\" class=\"col-sm-2 control-label\"Email/label\n    div class=\"col-sm-10\"\n      input type=\"email\" class=\"form-control\" id=\"inputEmail3\" placeholder=\"Email\"\n    /div\n  /div\n  div class=\"form-group\"\n    label for=\"inputPassword3\" class=\"col-sm-2 control-label\"Password/label\n    div class=\"col-sm-10\"\n      input type=\"password\" class=\"form-control\" id=\"inputPassword3\" placeholder=\"Password\"\n    /div\n  /div\n  div class=\"form-group\"\n    div class=\"col-sm-offset-2 col-sm-10\"\n      div class=\"checkbox\"\n        label\n          input type=\"checkbox\" Remember me\n        /label\n      /div\n    /div\n  /div\n  div class=\"form-group\"\n    div class=\"col-sm-offset-2 col-sm-10\"\n      button type=\"submit\" class=\"btn btn-default\"Sign in/button\n    /div\n  /div\n/form\n\nInput focus\n\nBootstrap remove the default outline styles on some form controls and apply a box-shadow in its place for :focus:\n\n Validation states\n\nBootstrap includes validation styles for error, warning, and success states on form controls. To use, add .has-warning, .has-error, or .has-success to the parent element. Any .control-label, .form-control, and .help-block within that element will receive the validation styles.\n\nYou can also add optional feedback icons with the addition of .has-feedback and the right icon.\n\nControl sizing and help text\n\nSet heights using classes like .input-lg, and set widths using grid column classes like .col-lg-*.\n\nWrap inputs in grid columns, or any custom parent element, to easily enforce desired widths.\n\nSee the Pen Bootstrap CSS: Forms by qetr1ck-op (@qetr1ck-op) on CodePen.\n\n Options\n\nUse any of the available button classes to quickly create a styled button:\n\n!-- Standard button --\nbutton type=\"button\" class=\"btn btn-default\"Default/button\n\n!-- Provides extra visual weight and identifies the primary action in a set of buttons --\nbutton type=\"button\" class=\"btn btn-primary\"Primary/button\n\n!-- Indicates a successful or positive action --\nbutton type=\"button\" class=\"btn btn-success\"Success/button\n\n!-- Contextual button for informational alert messages --\nbutton type=\"button\" class=\"btn btn-info\"Info/button\n\n!-- Indicates caution should be taken with this action --\nbutton type=\"button\" class=\"btn btn-warning\"Warning/button\n\n!-- Indicates a dangerous or potentially negative action --\nbutton type=\"button\" class=\"btn btn-danger\"Danger/button\n\n!-- Deemphasize a button by making it look like a link while maintaining button behavior --\nbutton type=\"button\" class=\"btn btn-link\"Link/button\n\nSizes\n\nFancy larger or smaller buttons? Add .btn-lg, .btn-sm, or .btn-xs for additional sizes\nCreate block level buttons—those that span the full width of a parent— by adding .btn-block.\n\nbutton type=\"button\" class=\"btn btn-primary btn-lg\"Large button/button\nbutton type=\"button\" class=\"btn btn-default btn-lg\"Large button/button\n\nbutton type=\"button\" class=\"btn btn-primary\"Default button/button\nbutton type=\"button\" class=\"btn btn-default\"Default button/button\n\nbutton type=\"button\" class=\"btn btn-primary btn-sm\"Small button/button\nbutton type=\"button\" class=\"btn btn-default btn-sm\"Small button/button\n\nbutton type=\"button\" class=\"btn btn-primary btn-xs\"Extra small button/button\nbutton type=\"button\" class=\"btn btn-default btn-xs\"Extra small button/button\n\n!-- Block level button --\nbutton type=\"button\" class=\"btn btn-primary btn-lg btn-block\"Block level button/button\nbutton type=\"button\" class=\"btn btn-default btn-lg btn-block\"Block level button/button\n\n Active state\n\nButtons will appear pressed (with a darker background, darker border, and inset shadow) when active. For button elements, this is done via :active. For a elements, it's done with .active. However, you may use .active on button should you need to replicate the active state programmatically.\n\nDisabled state\n\nMake buttons look unclickable by fading them back 50%.\n\nAdd the disabled attribute to button or .disabled class to a:\n\nbutton type=\"button\" class=\"btn btn-lg btn-primary\" disabled=\"disabled\"Primary button/button\nbutton type=\"button\" class=\"btn btn-default btn-lg\" disabled=\"disabled\"Button/button\n!-- Anchors elements --\na href=\"\" class=\"btn btn-primary btn-lg disabled\" role=\"button\"Primary link/a\na href=\"#\" class=\"btn btn-default btn-lg disabled\" role=\"button\"Link/a\n\nSee the Pen Bootstrap CSS: Buttons by qetr1ck-op (@qetr1ck-op) on CodePen.\n\nResponsive images\n\nImages in Bootstrap 3 can be made responsive-friendly via the addition of the .img-responsive class. This applies max-width: 100%; and height: auto; to the image so that it scales nicely to the parent element.\n\nimg src=\"...\" class=\"img-responsive\" alt=\"Responsive image\"\n\n Images shapes\n\nAdd classes to an img element to easily style images in any project:\n\nimg src=\"...\" alt=\"...\" class=\"img-rounded\"\nimg src=\"...\" alt=\"...\" class=\"img-circle\"\nimg src=\"...\" alt=\"...\" class=\"img-thumbnail\"\nSee the Pen Images shapes by qetr1ck-op (@qetr1ck-op) on CodePen.\n\nContextual colors\n\nConvey meaning through color with a handful of emphasis utility classes: text-muted, text-primary, text-success, text-info, text-warning, text-danger:\n\np class=\"text-muted\".../p\np class=\"text-primary\".../p\np class=\"text-success\".../p\np class=\"text-info\".../p\np class=\"text-warning\".../p\np class=\"text-danger\".../p\n\n Contextual backgrounds\n\nSimilar to the contextual text color classes, easily set the background of an element to any contextual class. Anchor components will darken on hover, just like the text classes.\n\np class=\"bg-primary\".../p\np class=\"bg-success\".../p\np class=\"bg-info\".../p\np class=\"bg-warning\".../p\np class=\"bg-danger\".../p\n\nClose icon\n\nUse the generic close icon for dismissing content like modal and alert.\n\nbutton type=\"button\" class=\"close\"span aria-hidden=\"true\"&times;/spanspan class=\"sr-only\"Close/span/button\n\n Carets\n\nUse carets to indicate drop-down functionality and direction.\n\nspan class=\"caret\"/span\n\nQuick floats\n\ndiv class=\"pull-left\".../div\ndiv class=\"pull-right\".../div\n\n Center content blocks\n\nSet an element to display: block and center via margin\n\ndiv class=\"center-block\".../div\n\nClearfix\n\nEasily clear floats by adding .clearfix to the parent element.\n\n!-- Usage as a class --\ndiv class=\"clearfix\".../div\n\n Showing and hiding content\n\nForce an element to be shown or hidden (including for screen readers) with the use of .show and .hidden classes.\n\ndiv class=\"show\".../div\ndiv class=\"hidden\".../div\n\nHelper Classes Examples\n\nSee the Pen Helper Classes by qetr1ck-op (@qetr1ck-op) on CodePen.\n\nThe materials which save my day:\n\nBootstrap Official Site",
        "tags": []
    },
    {
        "uri": "/post/Browsers-Layout-engines",
        "title": "Browsers Layout engines",
        "content": "\nThe list of popular layout engines.\n\n!--more--\n\nSpider monkey is developed by the Mozilla Foundation.\nPresto is developed by Opera Software for use in Opera. Development stopped as Opera transitions to Blink.\nTrident is developed by Microsoft for use in the Windows version of their web browser, from Internet Explorer 4 to the present time.\nEdgeHTML in Microsoft Edge\nWebKit used in Apple Safari, Chromium and Google Chrome.\nBlink is a 2013 fork of WebKit by Google used in Chromium, Google Chrome and Opera.\n\nFull list of Browsers Layout engines on wiki\n",
        "tags": []
    },
    {
        "uri": "/post/building-a-javaScript-development-environment",
        "title": "Building a JavaScript development environment",
        "content": "\nStarting a new JavaScript project from scratch is overwhelming. This course provides a playbook outlining the key decisions you need to make. Build a robust development environment that handles bundling, linting, transpiling, testing, and much more.\n\n!--more--\n\nDescription\n\nBuilding a JavaScript application from scratch today is overwhelming. You have to make decisions about package management, bundling, linting, transpiling, automated testing, and much more. There are literally over 40 important decisions to consider. This course is a playbook of potential options that provides a clear path through the key decisions. Along the way, we'll build a robust automated development environment from the ground up using ES6. You’ll learn how to set up a reusable development environment that provides a powerful foundation for future projects, that’s tailored just for your team’s needs.\n\n Link\n\ncourse on pluralsight\n\n",
        "tags": []
    },
    {
        "uri": "/post/call-apply-VS-bind-the-simplest-explanation",
        "title": "call & apply VS bind, the simplest explanation",
        "content": "\nEvery one know that apply() and call() are similar function, which set this (change context of function).\n\nBut when should be used the bind() method?\n\n!--more--\n\ncall and apply attach this into function/method and execute it immediately:\n\nconst foo = {\n  name: 'Foo',\n  hello(toWhom) {\n    return Hello from ${this.name} to ${toWhom};\n  }\n}\n\nfoo.hello('bar'); // \"Hello from Foo to bar\"\nfoo.hello.call(foo, 'world'); // \"Hello from Foo to world\"\n\nFunction.prototype.bind(), on the other hand, creates a new function with a given this value, and returns that function without executing it. It is needed to be invoked separately:\n\nconst foo = {\n  name: 'Foo',\n  hello(toWhom) {\n    return Hello from ${this.name} to ${toWhom};\n  }\n}\n\nconst newHello = foo.hello.bind(foo);\nnewHello('world'); //\"Hello from Foo to world\"\n\nIt's very useful with callbacks:\n\nconst bar = { message: 'Hello world' };\n\nfunction sayMsg() {\n  this.message;\n}\n\nsetTimeout(sayMsg.bind(bar)); // \"Hello world\"\n`",
        "tags": []
    },
    {
        "uri": "/post/Canvas-off-icon-navigation-with-an-animated-border-effect",
        "title": "Canvas-off icon navigation with an animated border effect",
        "content": "\n!--more--\n\nThe Markup\n\nThe HTML structure for our menu will consist of a nav element that will contain a trigger anchor and an unordered list with the menu items which will consist of icons:\n\nnav id=\"bt-menu\" class=\"bt-menu\"\n    spanMenu/span\n\nZoom\nRefresh\nLock\nSound\nFavorite\n/nav\n\n    The CSS\n\nLet’s use the border-box box-sizing:\n\n*,\n*:after,\n*::before {\n    box-sizing: border-box;\n}\n\nAnd let’s set some styles for the body and the main container:\n\nbody  {\n    background: #04a466;\n}\n\n.container {\n    padding: 80px;\n}\n\nThe padding will help providing some space around our content so that when the border appears, we guarantee that there is enough space around.\n\nThe main menu element will have position fixed so that, no matter where we are in the page, the border is always around the viewport. We set an initial border style which we will transition to a bigger border. Setting the initial height to 0 will make sure that the menu does not cover anything initially. The “backward” or closing height transition will have a delay of 0.3s:\n\n.bt-menu {\n    position: fixed;\n    top: 0;\n    left: 0;\n    width: 100%;\n    height: 0;\n    border-width: 0px;\n    border-style: solid;\n    border-color: #333;\n    background-color: rgba(0,0,0,0);\n    transition: border-width 0.3s, background-color 0.3s, height 0s 0.3s;\n}\n\nWhen we open the menu, we’ll set the height to 100% (but we won’t transition that property) and the border will animate to 90px on the left side and 30px on all the other sides. The background color will be semi-transparent using an RGBA value:\n\n.bt-menu.bt-menu-open {\n    height: 100%;\n    border-width: 30px 30px 30px 90px;\n    background-color: rgba(0,0,0,0.3);\n    transition: border-width 0.3s, background-color 0.3s;\n}\n\nNow we have to use a little trick. We will add another element using JavaScript which will server as a dummy container covering the whole page except the border. This will allow us to distinguish where we are clicking in order to close the whole thing. We don’t want the menu to close when clicking on the border but only when clicking in the space between:\n\n.bt-overlay {\n    position: absolute;\n    width: 100%;\n}\n\nWhen we open the menu, this element will have full height:\n\n.bt-menu-open .bt-overlay {\n    height: 100%;\n}\n\nLet’s style that little trigger element. We’ll give it a fixed position and we’ll show it in the top left corner of the page:\n\n.bt-menu-trigger {\n    position: fixed;\n    top: 15px;\n    left: 20px;\n    display: block;\n    width: 50px;\n    height: 50px;\n    cursor: pointer;\n}\n\nThe trigger anchor itself will serve as a container and the span will be the middle line of our hamburger menu icon. So we position it in the middle by setting the top to 50% and giving it a negative top margin of half of its height:\n\n.bt-menu-trigger span {\n    position: absolute;\n    top: 50%;\n    left: 0;\n    display: block;\n    width: 100%;\n    height: 4px;\n    margin-top: -2px;\n    background-color: #fff;\n    font-size: 0px;\n    user-select: none;\n    transition: background-color 0.3s;\n}\n\nWhen opening the menu, we will make a cross out of the icon. The other two lines will be created by pseudo-elements and when the menu is open, the middle line will disappear:\n\n.bt-menu-open .bt-menu-trigger span {\n    background-color: transparent;\n}\n\nNow, let’s create the two other lines. The pseudo-elements will be positioned absolutely and their height is going to be the same like of their parent by setting it to 100%:\n\n.bt-menu-trigger span:before,\n.bt-menu-trigger span:after {\n    position: absolute;\n    left: 0;\n    width: 100%;\n    height: 100%;\n    background: #fff;\n    content: '';\n    transition: transform 0.3s;\n}\n\nFor positioning them correctly, we’ll use translateY:\n\n.bt-menu-trigger span:before {\n    transform: translateY(-250%);\n}\n\n.bt-menu-trigger span:after {\n    transform: translateY(250%);\n}\n\nThe cross will be formed when opening the menu by setting the translateY to 0 and rotating the pseudo-elements accordingly:\n\n.bt-menu-open .bt-menu-trigger span:before {\n    transform: translateY(0) rotate(45deg);\n}\n\n.bt-menu-open .bt-menu-trigger span:after {\n    transform: translateY(0) rotate(-45deg);\n}\n\nThe unordered list with our icons will also have a fixed position and we’ll set it to the left side of the window:\n\n.bt-menu ul {\n    position: fixed;\n    top: 75px;\n    left: 0;\n    margin: 0;\n    padding: 0;\n    width: 90px;\n    list-style: none;\n    backface-visibility: hidden;\n}\nLet’s set the list items and the anchors to display: block and give them full width:\n\n.bt-menu ul li,\n.bt-menu ul li a {\n    display: block;\n    width: 100%;\n    text-align: center;\n}\n\nEach list item will be hidden initially and the opacity will be 0. The “backward” transition of the visibility will be delayed until all the other transitions of the transform and the opacity are finished:\n\n.bt-menu ul li {\n    padding: 16px 0;\n    opacity: 0;\n    visibility: hidden;\n    transition: transform 0.3s, opacity 0.2s, visibility 0s 0.3s;\n}\n\nNow we will transform each of the list items differently so that they are all placed in the middle and to the left until they are hidden (-100% on the Y axis):\n\n.bt-menu ul li:first-child { \n    transform: translate3d(-100%,200%,0);\n}\n\n.bt-menu ul li:nth-child(2) { \n    transform: translate3d(-100%,100%,0);\n}\n\n.bt-menu ul li:nth-child(3) { \n    transform: translate3d(-100%,0,0);\n}\n\n.bt-menu ul li:nth-child(4) { \n    transform: translate3d(-100%,-100%,0);\n}\n\n.bt-menu ul li:nth-child(5) { \n    transform: translate3d(-100%,-200%,0);\n}\n\nWhen opening the menu, the list items will become visible (instantly, because we are not setting a transition for it) and they will fade in. They will also move to their original positions by setting the transform3d to 0 for all axes:\n\n.bt-menu.bt-menu-open ul li {\n    visibility: visible;\n    opacity: 1;\n    transition: transform 0.3s, opacity 0.3s;\n    transform: translate3d(0,0,0);\n}\n\nNow, let’s style the anchors. We will use an icon font and include the font reference and the icon classes in another CSS which will be provided by a service like Fontastic or the IcoMoon app.\n\nBy setting the font size of the anchor to 0 and make it transparent, we’ll hide the text:\n\n.bt-menu ul li a {\n    display: block;\n    outline: none;\n    color: transparent;\n    text-decoration: none;\n    font-size: 0px;\n}\n\nWe’ll reset the font size for the pseudo-element which contains the icon. We’ll need to use a pixel-based value because the main element has a font-size of 0 so ems won’t work here:\n\n.bt-menu ul li a:before {\n    color: #04a466;\n    font-size: 48px;\n    transition: color 0.2s;\n}\n\nOn hover we’ll make them white:\n\n.bt-menu ul li a:hover:before,\n.bt-menu ul li a:focus:before  {\n    color: #fff;\n}\n\nAnd last, but not least, we want the icons to be smaller on mobile screens:\n\n@media screen and (max-height: 31.125em) {\n    .bt-menu ul li a:before {\n        font-size: 32px;\n    }\n}\n\nThe Javascript\n\nOur script is pretty straightforward; when we click on the trigger anchor, we toggle the class bt-menu-open and bt-menu-close on the nav element.\n\nWhen we click on the overlay, we will close the menu. We’ll also add some touch support:\n\n(function() {\n\n    // http://stackoverflow.com/a/11381730/989439\n    function mobilecheck() {\n        var check = false;\n        (function(a){if(/(android|ipad|playbook|silk|bb\\d+|meego).+mobile|avantgo|bada\\/|blackberry|blazer|compal|elaine|fennec|hiptop|iemobile|ip(hone|od)|iris|kindle|lge |maemo|midp|mmp|netfront|opera m(ob|in)i|palm( os)?|phone|p(ixi|re)\\/|plucker|pocket|psp|series(4|6)0|symbian|treo|up\\.(browser|link)|vodafone|wap|windows (ce|phone)|xda|xiino/i.test(a)||/1207|6310|6590|3gso|4thp|50[1-6]i|770s|802s|a wa|abac|ac(er|oo|s\\-)|ai(ko|rn)|al(av|ca|co)|amoi|an(ex|ny|yw)|aptu|ar(ch|go)|as(te|us)|attw|au(di|\\-m|r |s )|avan|be(ck|ll|nq)|bi(lb|rd)|bl(ac|az)|br(e|v)w|bumb|bw\\-(n|u)|c55\\/|capi|ccwa|cdm\\-|cell|chtm|cldc|cmd\\-|co(mp|nd)|craw|da(it|ll|ng)|dbte|dc\\-s|devi|dica|dmob|do(c|p)o|ds(12|\\-d)|el(49|ai)|em(l2|ul)|er(ic|k0)|esl8|ez([4-7]0|os|wa|ze)|fetc|fly(\\-|)|g1 u|g560|gene|gf\\-5|g\\-mo|go(\\.w|od)|gr(ad|un)|haie|hcit|hd\\-(m|p|t)|hei\\-|hi(pt|ta)|hp( i|ip)|hs\\-c|ht(c(\\-| ||a|g|p|s|t)|tp)|hu(aw|tc)|i\\-(20|go|ma)|i230|iac( |\\-|\\/)|ibro|idea|ig01|ikom|im1k|inno|ipaq|iris|ja(t|v)a|jbro|jemu|jigs|kddi|keji|kgt( |\\/)|klon|kpt |kwc\\-|kyo(c|k)|le(no|xi)|lg( g|\\/(k|l|u)|50|54|\\-[a-w])|libw|lynx|m1\\-w|m3ga|m50\\/|ma(te|ui|xo)|mc(01|21|ca)|m\\-cr|me(rc|ri)|mi(o8|oa|ts)|mmef|mo(01|02|bi|de|do|t(\\-| |o|v)|zz)|mt(50|p1|v )|mwbp|mywa|n10[0-2]|n20[2-3]|n30(0|2)|n50(0|2|5)|n7(0(0|1)|10)|ne((c|m)\\-|on|tf|wf|wg|wt)|nok(6|i)|nzph|o2im|op(ti|wv)|oran|owg1|p800|pan(a|d|t)|pdxg|pg(13|\\-([1-8]|c))|phil|pire|pl(ay|uc)|pn\\-2|po(ck|rt|se)|prox|psio|pt\\-g|qa\\-a|qc(07|12|21|32|60|\\-[2-7]|i\\-)|qtek|r380|r600|raks|rim9|ro(ve|zo)|s55\\/|sa(ge|ma|mm|ms|ny|va)|sc(01|h\\-|oo|p\\-)|sdk\\/|se(c(\\-|0|1)|47|mc|nd|ri)|sgh\\-|shar|sie(\\-|m)|sk\\-0|sl(45|id)|sm(al|ar|b3|it|t5)|so(ft|ny)|sp(01|h\\-|v\\-|v )|sy(01|mb)|t2(18|50)|t6(00|10|18)|ta(gt|lk)|tcl\\-|tdg\\-|tel(i|m)|tim\\-|t\\-mo|to(pl|sh)|ts(70|m\\-|m3|m5)|tx\\-9|up(\\.b|g1|si)|utst|v400|v750|veri|vi(rg|te)|vk(40|5[0-3]|\\-v)|vm40|voda|vulc|vx(52|53|60|61|70|80|81|83|85|98)|w3c(\\-| )|webc|whit|wi(g |nc|nw)|wmlb|wonu|x700|yas\\-|your|zeto|zte\\-/i.test(a.substr(0,4)))check = true})(navigator.userAgent||navigator.vendor||window.opera);\n        return check;\n    }\n\n    function init() {\n\n        var menu = document.getElementById( 'bt-menu' ),\n            trigger = menu.querySelector( 'a.bt-menu-trigger' ),\n            // event type (if mobile, use touch events)\n            eventtype = mobilecheck() ? 'touchstart' : 'click',\n            resetMenu = function() {\n                classie.remove( menu, 'bt-menu-open' );\n                classie.add( menu, 'bt-menu-close' );\n            },\n            closeClickFn = function( ev ) {\n                resetMenu();\n                overlay.removeEventListener( eventtype, closeClickFn );\n            };\n\n        var overlay = document.createElement('div');\n        overlay.className = 'bt-overlay';\n        menu.appendChild( overlay );\n\n        trigger.addEventListener( eventtype, function( ev ) {\n            ev.stopPropagation();\n            ev.preventDefault();\n\n            if( classie.has( menu, 'bt-menu-open' ) ) {\n                resetMenu();\n            }\n            else {\n                classie.remove( menu, 'bt-menu-close' );\n                classie.add( menu, 'bt-menu-open' );\n                overlay.addEventListener( eventtype, closeClickFn );\n            }\n        });\n\n    }\n\n    init();\n\n})();\n\n    View Demo\n\nView demo\n\nSaveMyDay:\n\non tympanus.net",
        "tags": []
    },
    {
        "uri": "/post/Centering-in-CSS",
        "title": "Centering in CSS",
        "content": "\nA fast guide to help centering everything with CSS.\n\n!--more--\n\nSo now you can easy to say, that centering in CSS isn't a big deal. \n\nSave My Day:\n\non Css tricks",
        "tags": []
    },
    {
        "uri": "/post/Class-manipulation-in-Javascript-jQuery-and-AngularJS",
        "title": "Class manipulation in Javascript, jQuery and AngularJS",
        "content": "\nIn this article, I would like to create short reference for how add/remove/toogle class in pure Javascript and with framework.\n\n!--more--\n\nJavascript\n\n className\n\nProperty className has value of HTML-atribute class:\n\nbody class=\"class1 class2\"/body\n\nconsole.log(document.body.className);\n//class1 class2\n\ndocument.body.className += ' class3';\n\nconsole.log(document.body.className);\n//class1 class2 class3\n\nclassList\n\nProperty classList gives convenient interface for work with certain classes.\n\nelem.classList.contains(cls) - return true/false if element has class cls\nelem.classList.add/remove(cls) - adding/removing class cls\nelem.classList.toogle(cls) - if element has class cls, remove it, else add class cls\n\n jQuery\n\nThese methods inspect and manpulate classes assigned to elements:\n\n$(elem).hasClass(cls) - return true/false if element has class cls\n$(elem).addClass/removeClass(cls) - adding/removing class cls\n$(elem).toogleClass(cls) - if element has class(es) cls, remove it, else add class(es) cls\n\nAngularJS\n\n ng-class\n\nng-class accepts an \"expression\" that must evaluate to one of the following:\n\na string of space-delimited class names\nan array of class names\na map/object of class names to boolean values\n\nSee the Pen AngularJS, ng-class example by qetr1ck-op (@qetr1ck-op) on CodePen.\nscript async src=\"//codepen.io/assets/embed/ei.js\"/script\n\nng-style\n\nng-style accepts an \"expression\" that must evaluate to:\n\nan map/object of CSS style names to CSS values\n\nSee the Pen AngularJS, ng-style example by qetr1ck-op (@qetr1ck-op) on CodePen.",
        "tags": []
    },
    {
        "uri": "/post/CLI-in-Windows-useful-commands",
        "title": "CLI in Windows, useful commands",
        "content": "\nThe command line lets you communicate directly with your computer and instruct it to perform various tasks. For this you have to use specific commands\n\n!--more--\n\nhelp\nc:\\command /?\n\nPath working directory\nc:\\pwd\n\nComputer name (hostname)\nc:\\hostname\n\ndir\nc:\\dir\n\nList files (size, time, reverse)\nc:\\ls -lSr\n\nchange to drive\nc:\\f:\n\nchange to folder\nf:\\cd folder\n\nchange to root drive\nf:\\cd \\\n\nmake a directory\nc:\\md\n\nremove a directory\nc:\\rd\n\nremove a file/s\nc:\\rm name\nc:\\rm -rf dir_name\nc:\\rm *\n\ncopy a file/s\nc:\\cp file.txt dir_name\n\nmove\nc:\\mv file.txt dir_name \n\nopen explorer window\nc:\\start .\n\ncreate file\ncopy con myfile.txt\ntouch myfile.txt\n\nread file\nc:\\more file_name\n\nfind files\nc:\\find . -name \"*.txt\"\n\nPipes And Redirection\n\nThe | takes the output from the command on the left, and \"pipes\" it to the command on the right.\nc:\\cat file_name | less\n\nThe  takes the output of the command on the left, then writes it\nc:\\cat filename  filename2\n\nThe  takes the output of the command on the left, then appends it\nc:\\cat filename  filename2\n\nEnvironment variable\nc:\\env\nc:\\env | grep subl\n\nHow To Launch Git Bash from DOS Command Line?\nx64\nstart \"\" \"%SYSTEMDRIVE%\\Program Files (x86)\\Git\\bin\\sh.exe\" --login\nx86\nstart \"\" \"%ProgramFiles%\\Git\\bin\\sh.exe\" --login\n\nalias\ndoskey subl=\"C:\\Program Files\\Sublime Text 3\\sublime_text.exe\" $*\n\nSave my day:\nThe Command Line Crash Course",
        "tags": []
    },
    {
        "uri": "/post/CSS-Transforms",
        "title": "CSS Transforms",
        "content": "\nSo what are transforms and transitions? At their most basic level, transforms move or change the appearance of an element, while transitions make the element smoothly and gradually change from one state to another.\n!--more--\n\nHow to use transforms\n\nThere are two categories of transform - 2D transforms and 3D transforms. 2D transforms are more widely supported, whereas 3D transforms are only in newer browsers.\n\n 2D examples\n\n//don't forget about prefixes\nskew {\n  -webkit-transform:skew(35deg);\n   -moz-transform:skew(35deg);\n    -ms-transform:skew(35deg);\n     -o-transform:skew(35deg);\n        transform:skew(35deg);\n}\nscale {\n  -webkit-transform:scale(1,0.5);\n   -moz-transform:scale(1,0.5);\n    -ms-transform:scale(1,0.5);\n     -o-transform:scale(1,0.5);\n        transform:scale(1,0.5);\n}\nrotate {\n  -webkit-transform:rotate(45deg);\n   -moz-transform:rotate(45deg);\n    -ms-transform:rotate(45deg);\n     -o-transform:rotate(45deg);\n        transform:rotate(45deg);\n}\ntranslate {\n  -webkit-transform:translate(10px, 20px);\n   -moz-transform:translate(10px, 20px);\n    -ms-transform:translate(10px, 20px);\n     -o-transform:translate(10px, 20px);\n        transform:translate(10px, 20px);\n}\n\n.thumbnail {\n  -webkit-transition: all .5s ease-in;\n  -moz-transition: all .5s ease-in;  \n  -o-transition: all .5s ease-in;\n  transition: all .5s ease-in;\n}\n\np data-height=\"473\" data-theme-id=\"10606\" data-slug-hash=\"BGAaf\" data-default-tab=\"result\" data-user=\"qetr1ck-op\" class='codepen'See the Pen a href='http://codepen.io/qetr1ck-op/pen/BGAaf/'CSS Transforms: 2D examples/a by qetr1ck-op (a href='http://codepen.io/qetr1ck-op'@qetr1ck-op/a) on a href='http://codepen.io'CodePen/a./p\nscript async src=\"//assets.codepen.io/assets/embed/ei.js\"/script\n\n3D examples and hadle `onTransitionEnd\n\n3D CSS transforms are similar to 2D CSS transforms. The basic properties are translate3d, scale3d, rotateX, rotateY and rotateZ. translate3d and scale3d take three arguments for x,y and z, whereas the rotates just take an angle. Here are some examples:\n\nrotateX{\n-webkit-transform:rotateX(180deg);\n   -moz-transform:rotateX(180deg);\n    -ms-transform:rotateX(180deg);\n     -o-transform:rotateX(180deg);\n        transform:rotateX(180deg);\n}\nrotateY{\n-webkit-transform:rotateY(180deg);\n   -moz-transform:rotateY(180deg);\n    -ms-transform:rotateY(180deg);\n     -o-transform:rotateY(180deg);\n        transform:rotateY(180deg);\n}\nrotateZ{\n-webkit-transform:rotateZ(180deg);\n   -moz-transform:rotateZ(180deg);\n    -ms-transform:rotateZ(180deg);\n     -o-transform:rotateZ(180deg);\n        transform:rotateZ(180deg);\n}\n\n$('.thumbnail').on('transitionend webkitTransitionEnd MSTransitionEnd', function(e) {\n  //transitionend fires for each property transitioned\n  if (e.originalEvent.propertyName != 'transform') return;\n\n  alert('webkitTransitionEnd')\n});\n\np data-height=\"474\" data-theme-id=\"10606\" data-slug-hash=\"CDrkj\" data-default-tab=\"result\" data-user=\"qetr1ck-op\" class='codepen'See the Pen a href='http://codepen.io/qetr1ck-op/pen/CDrkj/'CSS Transforms: 3D example and transtionEnd/a by qetr1ck-op (a href='http://codepen.io/qetr1ck-op'@qetr1ck-op/a) on a href='http://codepen.io'CodePen/a./p\n\n3D Transform image slider\n\nNote that because of the way a cube works, the image is moved out towards the screen, and is bigger than it should be. You should move it back by half the width of an image to make sure it is normal size.\n\np data-height=\"545\" data-theme-id=\"10606\" data-slug-hash=\"GgCah\" data-default-tab=\"result\" data-user=\"qetr1ck-op\" class='codepen'See the Pen a href='http://codepen.io/qetr1ck-op/pen/GgCah/'CSS Transforms: 3D Transform image slider/a by qetr1ck-op (a href='http://codepen.io/qetr1ck-op'@qetr1ck-op/a) on a href='http://codepen.io'CodePen/a./p\n\nSaveMyDay:\n\non css3.bradshawenterprises.com",
        "tags": []
    },
    {
        "uri": "/post/cycle-js-fundamentals",
        "title": "сусle.js fundamentals",
        "content": "\nCycle.js is a framework where your app is described as a simple function taking an event stream as input and outputting an event stream.\n\nCycle.js builds on RxJS and is as a reactive and functional JavaScript framework. What does that mean?\n!--more--\n\n1.The cycle.js principle: separate logic from effects\n\nSo cycle.js is based on Rxjs and virtual DOM.\n\nGet Rxjs from cdn.js:\n\nhttps://cdnjs.cloudflare.com/ajax/libs/rxjs/4.0.7/rx.min.js\n\nCreating element when everything will mount:\n\ndiv id=\"app\"div   \n\nNow create an observable timer, which will show elapsed seconds:\n\nRx.Observable.timer(0, 1000)\n    .map(i = Second elapsed ${i})\n    .subsribe(text = {\n        document.querySelector('app')\n            .textContent = text;\n    })\n\nSo the guide principle in cycle.js is separate logic from affects.\n\nAffect is everything what change external world aka changing the DOM.\nLogic it's just an event steam.\n\n//Logic (functional), in developer hands\nRx.Observable.timer(0, 1000)\n    .map(i = Second elapsed ${i})\n\n//Effects (imperative), in framework\n    .subsribe(text = {\n        document.querySelector('#app')\n            .textContent = text;\n    })\n\nTODO: finish the post",
        "tags": []
    },
    {
        "uri": "/post/Data-URIs",
        "title": "Data URIs",
        "content": "\nDid you know that you don't have to link to an external image file when using an img element in HTML, or declaring a background-image in CSS? You can embed the image data directly into the document with data URIs.\n\n!--more--\n\nWhy would you do this?\n\nThe biggest reason: it saves HTTP Requests. Other than pure document size, this is the 1 factor concerning how fast a page loads. Less = better.\n\nThe format, to be specific:\n\ndata:mime type[;base64],encoded data\n\nli {\n  background:\n    url(data:image/gif;base64,R0lGODlhEAAQAMQAAORHHOVSKudfOulrSOp3WOyDZu6QdvCchPGolfO0o/XBs/fNwfjZ0frl3/zy7////wAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACH5BAkAABAALAAAAAAQABAAAAVVICSOZGlCQAosJ6mu7fiyZeKqNKToQGDsM8hBADgUXoGAiqhSvp5QAnQKGIgUhwFUYLCVDFCrKUE1lBavAViFIDlTImbKC5Gm2hB0SlBCBMQiB0UjIQA7)\n    no-repeat\n    left center;\n  padding: 5px 0 5px 25px;\n}\n\nimg width=\"16\" height=\"16\" alt=\"star\" src=\"data:image/gif;base64,R0lGODlhEAAQAMQAAORHHOVSKudfOulrSOp3WOyDZu6QdvCchPGolfO0o/XBs/fNwfjZ0frl3/zy7////wAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACH5BAkAABAALAAAAAAQABAAAAVVICSOZGlCQAosJ6mu7fiyZeKqNKToQGDsM8hBADgUXoGAiqhSvp5QAnQKGIgUhwFUYLCVDFCrKUE1lBavAViFIDlTImbKC5Gm2hB0SlBCBMQiB0UjIQA7\" /\n\nHow do you get the code?\n\nUse this online conversion tool. It's the nicest one I have found. Here's a drag and drop one.\n\nSave my day: css-tricks.com",
        "tags": []
    },
    {
        "uri": "/post/Deferred-and-promise-in-jQuery",
        "title": "Deferred and promise in jQuery",
        "content": "\nHow handle async code with jQuery via promises and creating own promise via deffered.\n\n!--more--\n\nSo in which cases are Promises useful?\n\nAJAX request handler spaghetti?\n\n$.ajax({\n  type: 'GET',\n  url: 'http://www.html5rocks.com/en/tutorials/file/xhr2/',\n  success: function(response) {\n    var insertDiv1 = $('div/div');\n    insertDiv1.html($(response).find('section').html());\n    $.ajax({\n      type: 'GET',\n      url: 'http://www.html5rocks.com/en/tutorials/audio/scheduling/',\n      success: function(response) {\n        var insertDiv2 = $('div/div');\n        insertDiv2.html($(response).find('section').html());\n        $('body').append(insertDiv1, insertDiv2);\n      }\n    });\n  }\n});\n\n  Why we need Deferred and Promises?\n\nLet's do a step back in time. A time without iPod or Xbox or Facebook. If you wanted to catch a mouseclick, you did it with element.onclick = someFunction; This became a problem when another part of the code also wanted to listen to this click. This was not possible, because you could only assign one function. This was solved at the time with the addEventListener function. With this, you can add as many listener functions as you want. \n\nNow we have a similar problem with Ajax calls. This time it’s not the events, but the fact that Ajax supports only one callback function. Not only the jQuery $.ajax() call, but also the underlying XMLHttpRequest object.\n\nDeferred and promise are part of jQuery since version 1.5 and they help in handling asynchronous functions like Ajax.\n\nA typical $.ajax() call looked like this:\n\n$.ajax({\n  url: \"/myServerScript\",\n  success: mySuccessFunction,\n  error: myErrorFunction\n});\n\nSince version 1.5, the returned object implements the CommonJS Promises/A interface. CommonJS is a initiative to define common and independent interfaces API’s. Promises/A is one such interface. The advantage is that these are not jQuery specific. For example, if you work with Node.js, there is a good chance you’ll program with this same interface.\n\nThe way of assigning callbacks with Promises: \n\nvar promise = $.ajax({\n  url: \"/myServerScript\"\n});\n\npromise.done(mySuccessFunction);\npromise.fail(myErrorFunction);\n\nYou can combine the done() and fail() functions in one then() function:\n\nvar promise = $.ajax({\n  url: \"/myServerScript\"\n});\n\npromise.then(mySuccessFunction, myErrorFunction);\n\nThe advantages of promises are:\n\nYou can call the done() and fail() functions more times, with different callbacks. Maybe you have a callback function that stops an animation, one that does a new Ajax call and another function that shows the received data to the visitor:\n\nvar promise = $.ajax({\n  url: \"/myServerScript\"\n});\n\npromise.done(myStopAnimationFunction);\npromise.done(myOtherAjaxFunction);\npromise.done(myShowInfoFunction);\npromise.fail(myErrorFunction);\n\nYou can combine promises. Sometimes you need to do two simultaneous Ajax calls and you want to execute a function when both are successfully finished. To do this, you use the new $.when() function:\n\nvar promise1 = $.ajax(\"/myServerScript1\");\nvar promise2 = $.ajax(\"/myServerScript2\");\n\n$.when(promise1, promise2).done(function(xhrObject1, xhrObject2) {\n  // Handle both XHR objects\n});\n\nSince jQuery 1.8, you can chain the then() function sequentially. In the code below, first promise1 is run and when resolved successfully, getStuff is run, returning a promise and when this is resolved successfully, the anonymous function is executed:\n\nvar promise1 = $.ajax(\"/myServerScript1\");\n\nfunction getStuff() {\n    return $.ajax(\"/myServerScript2\");\n}\n\npromise1.then(getStuff).then(function(myServerScript2Data){\n  // Both promises are resolved\n});\n\nEvery callback function receives the result of the previous asynchronous function, in the case of Ajax, that would be the returned data.\n\nSo what is a deferred and what is the difference with a promise?\n\nAs you have seen above, a promise is an object that is returned from an asynchronous function. You need a deferred when you write such a function yourself.\n\nA deferred object has a resolve() functions for a successful result and to execute the functions assigned with done(). The reject() function is for a failed result and executes the functions assigned with fail().\n\nYou can give parameters to both the resolve() and reject() functions and they will be passed on to the functions registered with done() and fail().\n\nThe promise object does not have resolve() or reject() functions. This is because you give the promise away to other scripts and you don’t want them to resolve or reject the promise.\n\nBelow is a simple script that illustrates how it works:\n\n$('result').html('waiting...');\n\nvar promise = wait();\npromise.done(result);\n\nfunction result() {\n  $('#result').html('done');\n}\n\nfunction wait() {\n  var deferred = $.Deferred(); // (!)\n\n  setTimeout(function() {\n    deferred.resolve();\n  }, 2000);\n\n  return deferred.promise();\n}\n\nThe wait() function is the function returning a promise. This will be resolved with a setTimeout of two seconds. Instead of setTimeout, everything can be used that is asynchronous, like animations, Web workers etcetera. It should be clear that inside the wait() function, we use the deferred object, but we return the limited promise object.\n\nSave My Day:\nDeferred and promise in jQuery\nAn introduction to jQuery Deferred / Promise and the design pattern in general",
        "tags": []
    },
    {
        "uri": "/post/Development-with-Webpack",
        "title": "Development with Webpack",
        "content": "\nWebpack simplifies web development by solving a fundamental problem: bundling. It takes in various assets, such as JavaScript, CSS, and HTML, and then transforms these assets into a format that’s convenient to consume through a browser. Doing this well takes away a significant amount of pain from web development.\n\nIt's not the easiest tool to learn due to its configuration-driven approach, but it's incredibly powerful. The purpose of this guide is to help you get started with webpack and then to go beyond the basics.\n\n!--more--\n\nList of well known links to become an expert with Webpack v.~2.\n\nSurviveJS\n\nA solid book\n\n Official guides\n\nGuides\n\n",
        "tags": []
    },
    {
        "uri": "/post/Difference-of-HTTP-and-HTTPS",
        "title": "Difference of HTTP and HTTPS",
        "content": "\nHyper Text Transfer Protocol Secure (HTTPS) is a secure version of the Hyper Text Transfer Protocol (HTTP). HTTPS allows secure e-commerce transactions, such as on-line banking.\n\n!--more--\n\nWhen a user connects to a website via HTTPS, the website encrypts the session with a Digital Certificate called as a Secure Sockets Layer (SSL), sometimes called Transport Layer Security (TLS) to send the information back.\n\nSecure Sockets Layer uses a cryptographic system that encrypts data with two keys.\n\nWeb browsers show a padlock icon to indicate that the website is secure, as it also displays https:// in the address bar. When a SSL Digital Certificate is installed on a web site, users can see a padlock icon at the bottom area of the navigator. When an Extended Validation Certificates is installed on a web site, users with the latest versions of browser will see the green address bar at the URL area of the navigator.\n\nWhy Is A SSL Certificate Required?\n\nWith booming Internet trends and fraud, most will not submit their private details on the web unless they know that the information they provide is securely transmitted and not accessible for anyone to view.\n\nSave my day:\nHTTP and HTTPS",
        "tags": []
    },
    {
        "uri": "/post/essential-programming-books",
        "title": "Essential Programming Books",
        "content": "\nThe list of 129 books deemed fundamental to the art of programming and includes books for various languages.\n\n!--more--\n\nLink\n\ngood reads",
        "tags": []
    },
    {
        "uri": "/post/Exploring-AngularJS-1-5-component-method",
        "title": "Exploring AngularJS 1.5 .component() method",
        "content": "\nAngularJS 1.5 introduce .component() helper method which is much simpler than the .directive() definitions and advocates best practices and common default behavior.\n\nUsing .component() will allow to write in Angular 2 style as well, which will turn transition to Angular 2 much easier.\n\nLet's compare the difference in syntax and the possibility of new abstraction.\n\n!--more--\n\nFrom \"directrive()\" to \"component()\"\n\nThe syntax change is simple:\n\n// before\nmodule.directive(name, fn);\n\n// after\nmodule.component(name, options);\n\nI've rebuild a simple counter directive which which we'll refactor to component():\n\nmodule\n  .directive('counter', function counter() {\n    return {\n      scope: {},\n      bindToController: {\n        count: '='\n      },\n      contorllerAs: '$ctlr',\n      controller: function() {\n        this.increment = () = this.count++;\n        this.decrement = () = this.count--;\n      },\n      template: `\n        div\n          input type=\"number\" ng-model=\"$ctlr.count\"\n          button ng-click=\"$ctrl.increment()\"+/button\n          button ng-click=\"$ctrl.decrement()\"-/button\n        /div\n      `\n    }\n  })\n\n Function to Object\n\nLet's start from the top and refactor the function argument to object:\n\n// before\nmodule\n  .directive('counter', function counter() {\n    return {\n\n    }\n  })\n\n// after\nmodule\n  .component('counter', {\n\n  })\n\nNice and simple.\n\n\"scope\" and \"bindToController\" become \"bindings\"\n\nIn directive() the scope property allows us to define whether we want to isolate the $scope or inherit it. So repeating every time just create an extra boilerplate. With bindToController we can explicitly define binding directly to instance of controller via this.\n\nWith bindings we can remove this boilerplate and simple define what we want to pass down to the component.\n\nAnd component() will always have an isolated scope.\n\n// before\nmodule\n  .directive('counter', function counter() {\n    return {\n      scope: {\n        count: '='\n      },\n      bindToController: true\n    }\n  })\n\n// after\nmodule\n  .component('counter', {\n    binding: {\n      count: '='\n    }\n  })\n\n Controller and \"contorllerAs\" changes\n\nNothing has changed in the way we declare controller, however it's now smarter and has a default contorllerAs value of $ctrl.\n\nUnder the hood it looks like:\n\n// inside angular.js\ncontrollerAs: identifierForController(options.controller) || options.controllerAs || '$ctrl'\n\n//...\n\nvar CNTRL_REG = /^(\\S+)(\\s+as\\s+(\\w+))?$/;\nfunction identifierForController(controller, ident) {\n  if (ident && isString(ident)) return ident;\n  if (isString(controller)) {\n    var match = CNTRL_REG.exec(controller);\n    if (match) return match[3];\n  }\n}\n\nThis allows us to do the following inside .component():\n\n{\n  ...\n  controller: 'FooController as foo'\n}\n\nBased on the information we refactor our Directive to Component by dropping controllerAs property:\n\n// before\n.directive('counter', function counter() {\n  return {\n    scope: {\n      count: '='\n    },\n    bindToController: true,\n    controller: function () {\n      this.increment = () = this.count++;\n      this.decrement = () = this.count--;\n    },\n    controllerAs: 'counter'\n  };\n});\n\n// after\n.component('counter', {\n  bindings: {\n    count: '='\n  },\n  controller: function () {\n    this.increment = () = this.count++;\n    this.decrement = () = this.count--;\n  }\n});\n\nThings now are becoming much simpler and funny.\n\nTemplate\n\nThe template property can be defined as a function property with injected $elem and $attrs values:\n\n{\n  ...\n  template: function ($element, $attrs) {\n    // access to $element and $attrs\n    return `\n      div\n        input type=\"text\" ng-model=\"$ctrl.count\"\n        button type=\"button\" ng-click=\"$ctrl.decrement();\"-/button\n        button type=\"button\" ng-click=\"$ctrl.increment();\"+/button\n      /div\n    `\n  }\n  ...\n}\n\n Inheriting behavior with \"require\"\n\nInherited Directive or Component methods will be bound to this.parent property in the Controller:\n\n{\n  ...\n  require: {\n    parent: '^^parentComponet'\n  },\n  controller: function() {\n    // use this object to access to required Object\n    this.parent.foo();\n  }\n}\n\nOne-way binding\n\nA new syntax expression for isolate scope values:\n\n{\n  ...\n  bindings: {\n    oneWay: '<',\n    twoWay: '='\n  },\n  ...\n}\n\n But still remember that object are passed by reference, and Angular doesn't make a clone of the object when it passed via one-way binding, it actually sets the same value, which means that objects have still two-way binding somehow.\n\n Upgrading to Angular 2\n\nWriting in this style using .component() allows you easily transit to Angular 2, it'd look something like this:\n\nimport { Component } from '@angular/core'\n\n@Component({\n  selector: 'counter',\n  template: `\n    div\n      input type=\"number\" [(ng-model)]=\"count\"\n      button (click)=\"increment()\"+/button\n      button (click)=\"decrement()\"-/button\n    /div\n  `,\n})\n\nexport default class CounterComponent {\n  constructor() {}\n  increment() {\n    this.count++;\n  }\n  decrement() {\n    this.count++;\n  }\n}\n\nSave my day: \n\ntoddmotto",
        "tags": []
    },
    {
        "uri": "/post/Firebase-and-AngularJS",
        "title": "Firebase and AngularJS",
        "content": "\nAngularFire is the officially supported AngularJS binding for Firebase. The combination of Angular and Firebase provides a three-way data binding between your HTML, your, JavaScript, and the Firebase database.\n\n!--more--\n\nWho and why?\n\nFirebase is developed by Google and its a rich API to store and sync data in realtime. Firebase has full-featured libraries for support all major web framework.\n\nAngularFire is the officially supported by AngularJS binding fir Firebase. The combination of Angular and Firebase provides a three-way between your Firebase data store and Angular's bindings (i.e. JavaScript variables to DOM elements).\n\n Quick start\n\nSimply include source from CDN:\n\n!-- Angular --\nscript src=\"https://ajax.googleapis.com/ajax/libs/angularjs/1.3.2/angular.min.js\"/script\n\n!-- Firebase --\nscript src=\"https://cdn.firebase.com/js/client/2.0.4/firebase.js\"/script\n\n!-- AngularFire --\nscript src=\"https://cdn.firebase.com/libs/angularfire/0.9.0/angularfire.min.js\"/script\n\nAlso sources are available via Bower or Yeoman scaffolding.\n\nNext we need to include ANgularFire service by adding firebase as a module dependency in our app. And than inject dependency the $firebase into a controller, factory, or service.\n\nvar app = angular.module('app', ['firebase']);\n\napp.controller('MainCtrl', function($scope, $firebase) {\n    var ref = new Fireabase(\"https://your-firebase.firebaseio.com/\");\n    var sync = $firebase(ref);\n})\n\nSynchronize data with $asObject(). Thee way data-binding\n\nKeep in mind that $firebase does not actually download any data from the Firebase server until $asArray() or $asObject() are called.\n\nThe full list for $firebase methods can be found in the API documentation.\n\nSynchronizing changes from the server is pretty magical via $save(). To achieve three-way data binding simply call $bindTo() on a synchronized object and now any changes in the DOM are pushed to Angular, and then automatically to Firebase. And inversely, any changes on the server get pushed into Angular and straight to the DOM:\n\np data-height=\"506\" data-theme-id=\"10606\" data-slug-hash=\"QwyJvg\" data-default-tab=\"result\" data-user=\"qetr1ck-op\" class='codepen'See the Pen a href='http://codepen.io/qetr1ck-op/pen/QwyJvg/'Synchronize data with $asObject(). Thee way data-binding/a by qetr1ck-op (a href='http://codepen.io/qetr1ck-op'@qetr1ck-op/a) on a href='http://codepen.io'CodePen/a./p\nscript async src=\"//assets.codepen.io/assets/embed/ei.js\"/script\n\n Synchronize Arrays with $asArray()\n\nSynchronized arrays should be used for any list of objects that will be sorted, iterated and have unique IDs. The complete list of methods can be found in the API for $FirebaseArray.\n\nThe contents of this array are synchronized with a remote server, and AngularFire controls adding, removing, and ordering the elements. Because of this special arrangement, AngularFire provides the concurrency safe methods $add(), $remove(), and $save() to modify the array elements.\n\np data-height=\"348\" data-theme-id=\"10606\" data-slug-hash=\"ByjXeq\" data-default-tab=\"result\" data-user=\"qetr1ck-op\" class='codepen'See the Pen a href='http://codepen.io/qetr1ck-op/pen/ByjXeq/'Synchronize Arrays with $asArray()/a by qetr1ck-op (a href='http://codepen.io/qetr1ck-op'@qetr1ck-op/a) on a href='http://codepen.io'CodePen/a./p\n\nSave my day:\nAngularFire Development Guide",
        "tags": []
    },
    {
        "uri": "/post/First-look-at-React-js",
        "title": "First reaction about React.js",
        "content": "\nBuilding a dead simple application with following component structure:\n\n!--more--\n\nCommentBox\n  CommentList\n    Comment\n  CommentForm\n\nGetting started\n\nOpen up public/index.html in your favorite editor. It should look something  like this:\n\n!-- index.html --\n!DOCTYPE html\nhtml\n  head\n    meta charset=\"utf-8\" /\n    titleReact Tutorial/title\n    script src=\"https://cdnjs.cloudflare.com/ajax/libs/react/0.14.7/react.js\"/script\n    script src=\"https://cdnjs.cloudflare.com/ajax/libs/react/0.14.7/react-dom.js\"/script\n    script src=\"https://cdnjs.cloudflare.com/ajax/libs/babel-core/5.8.23/browser.min.js\"/script\n    script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/2.1.1/jquery.min.js\"/script\n    script src=\"https://cdnjs.cloudflare.com/ajax/libs/marked/0.3.2/marked.min.js\"/script\n  /head\n  body\n    div id=\"content\"/div\n    script type=\"text/babel\" src=\"scripts/example.js\"/script\n    script type=\"text/babel\"\n      // To get started with this tutorial running your own code, simply remove\n      // the script tag loading scripts/example.js and start writing code here.\n    /script\n  /body\n/html\n\nWe included jQuery here because we want to simplify the code of our future ajax calls, but it's NOT mandatory for React to work.\n\n Your first component\n\nReact is all about modular, composable components. For our comment box example, we'll have the following component structure:\n\nCommentBox\n  CommentList\n    Comment\n  CommentForm\n\nLet's build the CommentBox component, which is just a simple div:\n\n// tutorial1.js\nvar CommentBox = React.createClass({\n  render: function() {\n    return (\n      div className=\"commentBox\"\n        Hello, world! I am a CommentBox.\n      /div\n      /* Imperative way\n      React.createElement('div', {className: \"commentBox\"},\n        \"Hello, world! I am a CommentBox.\"\n      )\n      */\n    );\n  }\n});\nReactDOM.render(\n  CommentBox /,\n  document.getElementById('content')\n);\n\nReact.createClass() to create a new React component. The most important of these methods is called render which returns a tree of React components that will eventually render to HTML.\n\nThe div tags are not actual DOM nodes; they are instantiations of React div components. \n\nComposing components\n\nLet's build skeletons for CommentList and CommentForm which will, again, be simple divs. Add these two components to your file, keeping the existing CommentBox declaration and ReactDOM.render call:\n\nvar CommentList = React.createClass({\n  render: function() {\n    return (\n      div className=\"commentList\"\n        Hello, world! I am a CommentList.\n      /div\n    );\n  }\n});\n\nvar CommentForm = React.createClass({\n  render: function() {\n    return (\n      div className=\"commentForm\"\n        Hello, world! I am a CommentForm.\n      /div\n    );\n  }\n});\n\nNext, update the CommentBox component to use these new components:\n\nvar CommentBox = React.createClass({\n  render: function() {\n    return (\n      div className=\"commentBox\"\n        h1Comments/h1\n        CommentList /\n        CommentForm /\n      /div\n    );\n  }\n});\n\nNotice how we're mixing HTML tags and components we've built. HTML components are regular React components, just like the ones you define, with one difference. The JSX compiler will automatically rewrite HTML tags to React.createElement(tagName) expressions and leave everything else alone.\n\n Using props\n\nLet's create the Comment component, which will depend on data passed in from its parent. Data passed in from a parent component is available as a property on the child component. These properties are accessed through this.props:\n\nvar Comment = React.createClass({\n  render: function() {\n    return (\n      div className=\"comment\"\n        h2 className=\"commentAuthor\"\n          {this.props.author}\n        /h2\n        {this.props.children}\n      /div\n    );\n  }\n});\n\nWe access named attributes passed to the component as keys on this.props and any nested elements as this.props.children.\n\nComponent Properties\n\nNow let's add some comments within our CommentList:\n\nvar CommentList = React.createClass({\n  render: function() {\n    return (\n      div className=\"commentList\"\n        Comment author=\"Pete Hunt\"This is one comment/Comment\n        Comment author=\"Jordan Walke\"This is another comment/Comment\n      /div\n    );\n  }\n});\n\nFor example, we passed Pete Hunt (via an attribute) and This is one comment (via an XML-like child node) to the first Comment. As noted above, the Comment component will access these properties through this.props.author, and this.props.children.\n\n Adding Markdown\n\nIn this tutorial we use a third-party library marked which takes Markdown text and converts it to raw HTML:\n\nvar Comment = React.createClass({\n  render: function() {\n    return (\n      div className=\"comment\"\n        h2 className=\"commentAuthor\"\n          {this.props.author}\n        /h2\n        {marked(this.props.children.toString())} // .toString() from React's wrapped text to a raw string\n      /div\n    );\n  }\n});\n\nBut there's a problem! Our rendered comments look like this in the browser: pThis is emanother/em comment/p. We want those tags to actually render as HTML.\n\nThat's React protecting you from an XSS attack. There's a way to get around it but the framework warns you not to use it:\n\nvar Comment = React.createClass({\n  rawMarkup: function() {\n    var rawMarkup = marked(this.props.children.toString(), {sanitize: true});\n    return { __html: rawMarkup };\n  },\n\n  render: function() {\n    return (\n      div className=\"comment\"\n        h2 className=\"commentAuthor\"\n          {this.props.author}\n        /h2\n        span dangerouslySetInnerHTML={this.rawMarkup()} /\n      /div\n    );\n  }\n});\n\nMock up the data model\n\nSo far we've been inserting the comments directly in the source code. Instead, let's render a blob of JSON data into the comment list. Eventually this will come from the server, but for now, write it in your source:\n\nvar data = [\n  {id: 1, author: \"Pete Hunt\", text: \"This is one comment\"},\n  {id: 2, author: \"Jordan Walke\", text: \"This is another comment\"}\n];\n\nWe need to get this data into CommentList in a modular way. Modify CommentBox and the ReactDOM.render() call to pass this data into the CommentList via props:\n\nvar CommentBox = React.createClass({\n  render: function() {\n    return (\n      div className=\"commentBox\"\n        h1Comments/h1\n        CommentList data={this.props.data} /\n        CommentForm /\n      /div\n    );\n  }\n});\n\nReactDOM.render(\n  CommentBox data={data} /,\n  document.getElementById('content')\n);\n\nNow that the data is available in the CommentList, let's render the comments dynamically:\n\nvar CommentList = React.createClass({\n  render: function() {\n    var commentNodes = this.props.data.map(function(comment) {\n      return (\n        Comment author={comment.author} key={comment.id}\n          {comment.text}\n        /Comment\n      );\n    });\n    return (\n      div className=\"commentList\"\n        {commentNodes}\n      /div\n    );\n  }\n});\n\n Fetching from the server.\n\nWe will remove the data prop and replace it with a URL to fetch:\n\nReactDOM.render(\n  CommentBox url=\"/api/comments\" /, document.getElementById('content')\n);\n\nThis component is different from the prior components because it will have to re-render itself.\n\nReactive state\n\nSo far, based on its props, each component has rendered itself once. props are immutable: they are passed from the parent and are owned by the parent. \n\nTo implement interactions, we introduce mutable state to the component. this.state is private to the component and can be changed by calling this.setState(). When the state updates, the component re-renders itself.\n\nWhen the server fetches data, we will be changing the comment data we have. Let's add an array of comment data to the CommentBox component as its state:\n\nvar CommentBox = React.createClass({\n  getInitialState: function() {\n    return { data: [] };\n  },\n  render: function() {\n    return (\n      div className=\"commentBox\"\n        h1Comments/h1\n        CommentList data={this.state.data} /\n        CommentForm /\n      /div\n    );\n  }\n});\n\ngetInitialState() executes exactly once during the lifecycle of the component and sets up the initial state of the component.\n\n Updating state\n\nWhen the component is first created, we want to GET some JSON from the server and update the state to reflect the latest data, so once it's fetched, this.state.data will look something like this:\n\n[\n  {\"author\": \"Pete Hunt\", \"text\": \"This is one comment\"},\n  {\"author\": \"Jordan Walke\", \"text\": \"This is another comment\"}\n]\n\nvar CommentBox = React.createClass({\n  getInitialState: function() {\n    return {data: []};\n  },\n  componentDidMount: function() {\n    $.ajax({\n      url: this.props.url,\n      dataType: 'json',\n      cache: false,\n      success: function(data) {\n        this.setState({ data: data });\n      }.bind(this),\n      error: function(xhr, status, err) {\n        console.error(this.props.url, status, err.toString());\n      }.bind(this)\n    });\n  },\n  render: function() {\n    return (\n      div className=\"commentBox\"\n        h1Comments/h1\n        CommentList data={this.state.data} /\n        CommentForm /\n      /div\n    );\n  }\n});\n\nHere, componentDidMount is a method called automatically by React after a component is rendered for the first time. \n\nThe key to dynamic updates is the call to this.setState(). We replace the old array of comments with the new one from the server and the UI automatically updates itself. \n\nBecause of this reactivity, it is only a minor change to add live updates. We will use simple polling here but you could easily use WebSockets or other technologies.\n\nAfter refactoring:\n\n// tutorial14.js\nvar CommentBox = React.createClass({\n  loadCommentsFromServer: function() {\n    $.ajax({\n      url: this.props.url,\n      dataType: 'json',\n      cache: false,\n      success: function(data) {\n        this.setState({data: data});\n      }.bind(this),\n      error: function(xhr, status, err) {\n        console.error(this.props.url, status, err.toString());\n      }.bind(this)\n    });\n  },\n  getInitialState: function() {\n    return {data: []};\n  },\n  componentDidMount: function() {\n    this.loadCommentsFromServer();\n    setInterval(this.loadCommentsFromServer, this.props.pollInterval);\n  },\n  render: function() {\n    return (\n      div className=\"commentBox\"\n        h1Comments/h1\n        CommentList data={this.state.data} /\n        CommentForm /\n      /div\n    );\n  }\n});\n\nReactDOM.render(\n  CommentBox url=\"/api/comments\" pollInterval={2000} /,\n  document.getElementById('content')\n);\n\nAdding new comments\n\nOur CommentForm component should ask the user for their name and comment text and send a request to the server to save the comment:\n\nvar CommentForm = React.createClass({\n  render: function() {\n    return (\n      form className=\"commentForm\"\n        input type=\"text\" placeholder=\"Your name\" /\n        input type=\"text\" placeholder=\"Say something...\" /\n        input type=\"submit\" value=\"Post\" /\n      /form\n    );\n  }\n});\n\nWe will be using this.state to save the user's input as it is entered. We define an initial state with two properties author and text and set them to be empty strings. In our input elements, we set the value prop to reflect the state of the component and attach onChange handlers to them. These input elements with a value set are called controlled components:\n\nvar CommentForm = React.createClass({\n  getInitialState: function() {\n    return {author: '', text: ''};\n  },\n  handleAuthorChange: function(e) {\n    this.setState({author: e.target.value});\n  },\n  handleTextChange: function(e) {\n    this.setState({text: e.target.value});\n  },\n  render: function() {\n    return (\n      form className=\"commentForm\"\n        <input\n          type=\"text\"\n          placeholder=\"Your name\"\n          value={this.state.author}\n          onChange={this.handleAuthorChange}\n        /\n        <input\n          type=\"text\"\n          placeholder=\"Say something...\"\n          value={this.state.text}\n          onChange={this.handleTextChange}\n        /\n        input type=\"submit\" value=\"Post\" /\n      /form\n    );\n  }\n});\n\n Events, submitting the form\n\nReact attaches event handlers to components using a camelCase naming convention. We attach onChange handlers to the two input elements. \n\nLet's make the form interactive. When the user submits the form, we should clear it, submit a request to the server, and refresh the list of comments:\n\nvar CommentForm = React.createClass({\n  getInitialState: function() {\n    return {author: '', text: ''};\n  },\n  handleAuthorChange: function(e) {\n    this.setState({author: e.target.value});\n  },\n  handleTextChange: function(e) {\n    this.setState({text: e.target.value});\n  },\n  handleSubmit: function(e) {\n    e.preventDefault();\n    var author = this.state.author.trim();\n    var text = this.state.text.trim();\n    if (!text || !author) {\n      return;\n    }\n    // TODO: send request to the server\n    this.setState({author: '', text: ''});\n  },\n  render: function() {\n    return (\n      form className=\"commentForm\" onSubmit={this.handleSubmit}\n        <input\n          type=\"text\"\n          placeholder=\"Your name\"\n          value={this.state.author}\n          onChange={this.handleAuthorChange}\n        /\n        <input\n          type=\"text\"\n          placeholder=\"Say something...\"\n          value={this.state.text}\n          onChange={this.handleTextChange}\n        /\n        input type=\"submit\" value=\"Post\" /\n      /form\n    );\n  }\n});\n\nCallbacks as props, pass data from the child component back up to its parent\n\nWhen a user submits a comment, we will need to refresh the list of comments to include the new one. It makes sense to do all of this logic in CommentBox since CommentBox owns the state that represents the list of comments.\n\nWe need to pass data from the child component back up to its parent. We do this in our parent's render method by passing a new callback handleCommentSubmit into the child, binding it to the child's onCommentSubmit event. Whenever the event is triggered, the callback will be invoked:\n\nvar CommentBox = React.createClass({\n  loadCommentsFromServer: function() {\n    $.ajax({\n      url: this.props.url,\n      dataType: 'json',\n      cache: false,\n      success: function(data) {\n        this.setState({data: data});\n      }.bind(this),\n      error: function(xhr, status, err) {\n        console.error(this.props.url, status, err.toString());\n      }.bind(this)\n    });\n  },\n  //--------------------------------------------------\n  handleCommentSubmit: function(comment) {\n    // TODO: submit to the server and refresh the list\n  },\n  //--------------------------------------------------\n  getInitialState: function() {\n    return {data: []};\n  },\n  componentDidMount: function() {\n    this.loadCommentsFromServer();\n    setInterval(this.loadCommentsFromServer, this.props.pollInterval);\n  },\n  render: function() {\n    return (\n      div className=\"commentBox\"\n        h1Comments/h1\n        CommentList data={this.state.data} /\n        //-------------------------------------------------------- \n        CommentForm onCommentSubmit={this.handleCommentSubmit} /\n        //--------------------------------------------------------\n      /div\n    );\n  }\n});\n\nCall the callback from the CommentForm when the user submits the form:\n\nvar CommentForm = React.createClass({\n  getInitialState: function() {\n    return {author: '', text: ''};\n  },\n  handleAuthorChange: function(e) {\n    this.setState({author: e.target.value});\n  },\n  handleTextChange: function(e) {\n    this.setState({text: e.target.value});\n  },\n  handleSubmit: function(e) {\n    e.preventDefault();\n    var author = this.state.author.trim();\n    var text = this.state.text.trim();\n    if (!text || !author) {\n      return;\n    }\n    //--------------------------------------------------------\n    this.props.onCommentSubmit({author: author, text: text});\n    //--------------------------------------------------------\n    this.setState({author: '', text: ''});\n  },\n  render: function() {\n    return (\n      form className=\"commentForm\" onSubmit={this.handleSubmit}\n        <input\n          type=\"text\"\n          placeholder=\"Your name\"\n          value={this.state.author}\n          onChange={this.handleAuthorChange}\n        /\n        <input\n          type=\"text\"\n          placeholder=\"Say something...\"\n          value={this.state.text}\n          onChange={this.handleTextChange}\n        /\n        input type=\"submit\" value=\"Post\" /\n      /form\n    );\n  }\n});\n\nNow that the callbacks are in place, all we have to do is submit to the server and refresh the list:\n\nvar CommentBox = React.createClass({\n  loadCommentsFromServer: function() {\n    $.ajax({\n      url: this.props.url,\n      dataType: 'json',\n      cache: false,\n      success: function(data) {\n        this.setState({data: data});\n      }.bind(this),\n      error: function(xhr, status, err) {\n        console.error(this.props.url, status, err.toString());\n      }.bind(this)\n    });\n  },\n  //-----------------------------------------------------------\n  handleCommentSubmit: function(comment) {\n    $.ajax({\n      url: this.props.url,\n      dataType: 'json',\n      type: 'POST',\n      data: comment,\n      success: function(data) {\n        this.setState({data: data});\n      }.bind(this),\n      error: function(xhr, status, err) {\n        console.error(this.props.url, status, err.toString());\n      }.bind(this)\n    });\n  },\n  //-----------------------------------------------------------\n  getInitialState: function() {\n    return {data: []};\n  },\n  componentDidMount: function() {\n    this.loadCommentsFromServer();\n    setInterval(this.loadCommentsFromServer, this.props.pollInterval);\n  },\n  render: function() {\n    return (\n      div className=\"commentBox\"\n        h1Comments/h1\n        CommentList data={this.state.data} /\n        CommentForm onCommentSubmit={this.handleCommentSubmit} /\n      /div\n    );\n  }\n});\n\n Optimization: optimistic updates\n\nIt feels slow to have to wait for the request to complete before your comment appears in the list. We can optimistically add this comment to the list to make the app feel faster:\n\nvar CommentBox = React.createClass({\n  loadCommentsFromServer: function() {\n    $.ajax({\n      url: this.props.url,\n      dataType: 'json',\n      cache: false,\n      success: function(data) {\n        this.setState({data: data});\n      }.bind(this),\n      error: function(xhr, status, err) {\n        console.error(this.props.url, status, err.toString());\n      }.bind(this)\n    });\n  },\n  handleCommentSubmit: function(comment) {\n    //-------------------------------------------------------------------------\n    var comments = this.state.data;\n    // Optimistically set an id on the new comment. It will be replaced by an\n    // id generated by the server. In a production application you would likely\n    // not use Date.now() for this and would have a more robust system in place.\n    comment.id = Date.now();\n    var newComments = comments.concat([comment]);\n    this.setState({data: newComments});\n    //-------------------------------------------------------------------------\n    $.ajax({\n      url: this.props.url,\n      dataType: 'json',\n      type: 'POST',\n      data: comment,\n      success: function(data) {\n        this.setState({data: data});\n      }.bind(this),\n      error: function(xhr, status, err) {\n        //---------------------------------------------------------------------\n        this.setState({data: comments});\n        //---------------------------------------------------------------------\n        console.error(this.props.url, status, err.toString());\n      }.bind(this)\n    });\n  },\n  getInitialState: function() {\n    return {data: []};\n  },\n  componentDidMount: function() {\n    this.loadCommentsFromServer();\n    setInterval(this.loadCommentsFromServer, this.props.pollInterval);\n  },\n  render: function() {\n    return (\n      div className=\"commentBox\"\n        h1Comments/h1\n        CommentList data={this.state.data} /\n        CommentForm onCommentSubmit={this.handleCommentSubmit} /\n      /div\n    );\n  }\n});\n\nDemo app\n\nThe total result as a demo you can find here.\n\nSave my day:\n\nOff site",
        "tags": []
    },
    {
        "uri": "/post/Fluid-three-column-layout-with-positioning-floats-tables-and-flexbox",
        "title": "Fluid three column layout with positioning, floats, tables and flexbox",
        "content": "\nIn Web world, fluid layout with 3 column is the most flexible and customizable layout. Mixing percentages and pixels for specify width of column allows create different layouts, for different task.\n\n!--more--\n\nIn article sumbols mean:\nHere sumbol % define, that column width is given in persantage of layout width;\npx- column width in static pixels;\n∞ - column occupies all remain width space.\n\nUsing positioning\n\nTo control position layout relative to the parent element layers, necessary establish for parent property - position: relative. And for child element set position: absolute, conrols fluid element with right/left, width in some cases used margin-right/left.\n\nSee the Pen Three column fluid layout with positionig by qetr1ck-op (@qetr1ck-op) on CodePen.\nscript async src=\"//codepen.io/assets/embed/ei.js\"/script\n\n    Floats\n\nFor this approach I used float in combinatition with properties margin and width. In some case used nested or additional div.wrap, because we can't use in the same time for onу HTML element margin in px and %.\n\nSee the Pen Fluid three column layout using floats by qetr1ck-op (@qetr1ck-op) on CodePen.\n\nTable columns\n\nActually, it's convinient to use table when you want to create column with same height. Width of column calculated automatcaly based on their content so I just need to specify the require width. Remain columns would streach to avaible width of table.\n\nSee the Pen Fluid three column layout using table by qetr1ck-op (@qetr1ck-op) on CodePen.\n\n    Flex box\n\nMost layout or if you want grid system use one of next methods: positioning, tables, and most popular - inline-blocks or float. All this methods have pretty significaте problems and limetations.\n\nFor for achive bunch of three column layout Flex boxes are super ease. In generaly I used for parents : display: flex and for children flex: 1 it's shorthand for flex-grow, flex-shrink and flex-basis\n\nIn furture post I should discover this literally one of the most promosing feature of web disign.\n\nSee the Pen Fluid three column layout with flexbox by qetr1ck-op (@qetr1ck-op) on CodePen.\n\nThis resources Save My Day:\n\nhtmlbook.ru\ncss-tricks.com\nSolved by Flexbox",
        "tags": []
    },
    {
        "uri": "/post/Fluid-two-column-layout-with-float-and-flexbox",
        "title": "Fluid two-column layout with float and flexbox",
        "content": "\nTwo-column layout allows effective use browser space. Layout doesn't require hard work and it can used with combining column in pixels or percentage.\n\n!--more--\n\n!--toc--\n\nThere are several approach for formation such layout, but the quickest and easiest is combine margin and float.\n\nFor left side bar with static width\n\n| For left layer with width 20%     |                    |\n|-----------------------------------|--------------------|\n| Left column                     | Right column     |\n| float: left width: 20%            | margin-left: 21%   |\n| For left layer with width 200px   |                    |\n| float: left width: 200px          | margin-left: 210px |\n\n  For right side bar:\n\n| For right layer with width 20%   |                          |\n|----------------------------------|--------------------------|\n| Left column                      | Right column             |\n| margin-right: 21%                | float: right, width: 20% |\n| For right layer with width 200px |                          |\n| float: right width: 200px        | margin-left: 210px       |\n\nbr\n\np data-height=\"400\" data-theme-id=\"dark\" data-slug-hash=\"oAtih\" data-default-tab=\"result\" data-user=\"qetr1ck-op\" data-embed-version=\"2\" data-pen-title=\"Fluid two-column layout with float\" data-preview=\"true\" class=\"codepen\"See the Pen a href=\"http://codepen.io/qetr1ck-op/pen/oAtih/\"Fluid two-column layout with float/a by qetr1ck-op (a href=\"http://codepen.io/qetr1ck-op\"@qetr1ck-op/a) on a href=\"http://codepen.io\"CodePen/a./p\nscript async src=\"https://production-assets.codepen.io/assets/embed/ei.js\"/script\n\nWith display: flex\n\np data-height=\"400\" data-theme-id=\"dark\" data-slug-hash=\"MwdvEV\" data-default-tab=\"result\" data-user=\"qetr1ck-op\" data-embed-version=\"2\" data-pen-title=\"Two-column layout with Flexbox\" data-preview=\"true\" class=\"codepen\"See the Pen a href=\"http://codepen.io/qetr1ck-op/pen/MwdvEV/\"Two-column layout with Flexbox/a by qetr1ck-op (a href=\"http://codepen.io/qetr1ck-op\"@qetr1ck-op/a) on a href=\"http://codepen.io\"CodePen/a./p\n\nMake my day:\nfluid 2 column layout\nawesome checkboxes",
        "tags": []
    },
    {
        "uri": "/post/Form-pop-up-with-inputs-navigation",
        "title": "Form pop-up with inputs navigation",
        "content": "\nModal pop-up confirm with \"correct\" navigation through inputs.\n\n!--more--\n\nMain functional requirements are:\n\nWhen submitting a form OK / Enter - the callback function must be called with the value of the field\n\nClicking on Cancel or press the Esc should be call the function callback. Esc key to close the form should always, even if the message input field is not in focus.\n\nForm should do modal affect, all other element on page must be unclickable.\n\nForm always centered in middle, height of form has no matter\n\nWhen form appears input field in focus and user have possibility use Tab / Tab-Shift for switch only inputs in the form.\n\np data-height=\"268\" data-theme-id=\"0\" data-slug-hash=\"xuizw\" data-default-tab=\"result\" class='codepen'See the Pen a href='http://codepen.io/qetr1ck-op/pen/xuizw/'xuizw/a by qetr1ck-op (a href='http://codepen.io/qetr1ck-op'@qetr1ck-op/a) on a href='http://codepen.io'CodePen/a./p\nscript async src=\"//codepen.io/assets/embed/ei.js\"/script\n\nMake my day:\n\nForms: method and event \"submit\"\n",
        "tags": []
    },
    {
        "uri": "/post/front-end-handbook-2017",
        "title": "Front End Handbook 2017",
        "content": "\nThis is a guide that anyone could use to learn about the practice of front-end development. It broadly outlines and discusses the practice of front-end engineering: how to learn it and what tools are used when practicing it in 2017\n\n!--more--\n\nThe handbook is divided into three parts:\n\nPart I. The Front-End Practice\n    Part one broadly describes the practice of front-end engineering.\nPart II: Learning Front-End Development\n    Part two identifies self-directed and direct resources for learning to become a front-end developer.\nPart III: Front-End Development Tools\n    Part three briefly explains and identifies tools of the trade.\n\nLink\n\nread online",
        "tags": []
    },
    {
        "uri": "/post/Front-End-Interview-Questions",
        "title": "Front End Interview Questions",
        "content": "\nTo rock the interview to achieve what you deserve and to improve your concepts about front end technologies, I have consolidated a list of questions and answers. It's a one stop solution for front end interview process.\n\n!--more--\n\nWeb Core\n\n JavaScript: basics\n\nTypes\n\n What are the differences between undeclared, undefined, and null?\n\nAnswer: JavaScript has two distinct values for nothing, null and undefined. Also there are undeclared variables which don’t even exist.\n\nExplanation: \n\nvar declaredVariable = 1;\n\n(function scoppedVariables() {\n  undeclaredVariable = 1;\n  var declaredVariable = 2;\n})();\n\nundeclaredVariable;\ndeclaredVariable;\n\nundeclared when it does not use the var keyword. It gets created on the global object, thus it operates in a different space as the declared variables.\nundefined means, value of the variable is not defined. JavaScript has a global variable undefined whose value is \"undefined\" and typeof undefined is also \"undefined\"\nnull means empty or non-existent value which is used by programmers to indicate “no value”. null is a primitive value and you can assign null to any variable. You cannot add properties to it. Sometimes people wrongly assume that it is an object, because typeof null returns \"object\".\n\n What are the differences between == and ===? To what type == operands will be converted to if they have \ndifferent types?\n\nAnswer: The simplest way of saying that, == will not check types and === will check whether both sides are of same type. So, == under the hood converts to number type if they have not the same type and then do the comparison.\n\n As [] is true, [] == true should also be true, right? Explain comparison algorithm.\n\nAnswer: Not.\n\nYou are right about first part, [], empty array is an object and object is always truths. \n\nHowever, special case about == (not-strict equal) is that it will do some implicit coercion.\n\nSince left and right side of the equality are two different types, JavaScript can't compare them directly.\nJavaScript implementation will try to convert [] by using toPrimitive (of JavaScript implementation). since [].valueOf is not primitive will use toString and will get \"\".\nNow you are comparing \"\" == 1 and still left and right is not same type. Hence left side will be converted again to a number and empty string will be 0.\nFinally, they are of same type, you are comparing 0 === 1 which will be false.\n\n Why typeof bar === object isn't right? How can this pitfall be avoided?\n\nAnswer: Use Object.prototype.toString.call(object) or use Duck Typing.\n\nExplanation: The surprising gotcha in JavaScript is that null is also considered an object!\n\n What is NaN? What is its type? How can you reliably test if a value is equal to NaN?\n\nAnswer: \"not a number\", \"number\", NaN compared to anything – even itself! to false. Use Number.isNaN\n\nExplanation: The NaN property represents a value that is “not a number”. This special value results from an operation that could not be performed either because one of the operands was non-numeric (e.g., \"abc\" / 4), or because the result of the operation is non-numeric (e.g., an attempt to divide by zero).\n\nES6 offers a new Number.isNaN() function, which is a different and more reliable than the old global isNaN() function.\n\n What is the significance, and what are the benefits, of including 'use strict' at the beginning of a JavaScript source file?\n\nAnswer: 'use strict' is a way to enforce stricter parsing and error handling on your code at runtime. Code errors that would otherwise have been ignored or would have failed silently will now generate errors or throw exceptions.\n\nExplanation: Some of the key benefits of strict mode include:\n\nMakes debugging easier. Code errors that would otherwise have been ignored or would have failed silently will now generate errors or throw exceptions, alerting you sooner to problems in your code and directing you more quickly to their source.\n\nPrevents accidental globals. Without strict mode, assigning a value to an undeclared variable automatically creates a global variable with that name. This is one of the most common errors in JavaScript. In strict mode, attempting to do so throws an error.\n\nEliminates this coercion. Without strict mode, a reference to a this value of undefined is automatically coerced to the global. This can cause many headfakes and pull-out-your-hair kind of bugs.\n\nDisallows duplicate property names or parameter values. Strict mode throws an error when it detects a duplicate named property in an object (e.g., var object = {foo: \"bar\", foo: \"baz\"};) or a duplicate named argument for a function (e.g., function foo(val1, val2, val1){}), thereby catching what is almost certainly a bug in your code that you might otherwise have wasted lots of time tracking down.\n\nThrows error on invalid usage of delete. The delete operator (used to remove properties from objects) cannot be used on non-configurable properties of the object. Non-strict code will fail silently when an attempt is made to delete a non-configurable property, whereas strict mode will throw an error in such a case.\n\n Scope and hoisting, closure and functions\n\n Example. What is the result will be an error?\n\nsay('World');\n\nconst phrase = 'Hello';\n\nfunction say(name) {\n  console.log(${name}, ${phrase}!);\n}\n\nAnswer: 'undefined, World!'\n\n Example. What is the result? What if to remove var value = false?\n\nvar value = 0;\n\nfunction f() {\n  if (1) {\n    value = true;\n  } else {\n    var value = false;\n  }\n\n  console.log(value);\n}\n\nf();\n\nAnswer: true, after remove line of code, will be changed global variable and the result will be the same.\n\n Example. What is the result? How to fix?\n\nfn1();\nfn2();\nfn3();\nfn4();\n\nfunction fn1() {\n  setTimeout(() = {\n    console.log('fn1')\n  })\n}\n\nfunction fn2() {\n  console.log('fn2');\n}\n\nfunction fn3() {\n  Promise.resolve().then(() = {\n    console.log('fn3');\n  })\n}\n\nconst fn4 = function () {\n  console.log('fn4');\n}\n\nAnswer: fn4 function expression isn't hoisted. Change to function declaration. The result should be fn2, fn4, fn3, fn1\n\n What is a closure? What is a practical use for a closure? Provide an example. \n\nAnswer: Closure is a function with all accessible variables in lexical environment. Main usage is encapsulating data from outer usage.\n\n Example. What is the result? How to make them independent?\n\nlet initCount = 1;\n\nfunction makeCounter() {\n  return () = initCount++\n}\n\nlet counter = makeCounter();\nlet counter2 = makeCounter();\n\nconsole.log( counter() ); // ?\nconsole.log( counter() ); // ?\n\nconsole.log( counter2() ); // ?\nconsole.log( counter2() ); // ?\n\n Closures Inside in loop with setTimeout.\n\nIf log the loop counter inside setTimeout, what will be logged?\n\nfor(var i = 0; i < 10; i++) {\n  setTimeout(function() {\n    console.log(i);  \n  }, 0);\n}\n\nAnswer: The above will not output the numbers 0 through 9, but will simply print the number 10 ten times.\n\nExplanation: \n\nThe console log is inside the anonymous function of setTimeout and setTimeout is executed when current call stack is over. \nSo, the loop finishes and before setTimeout get the chance to execute. However, anonymous functions keep a reference to i by creating a closure. \nSince, the loop is already finished, the value i has been set to 10.\n\nYou can fix it by avoiding closure. Just create a IIFE (Immediately Invoked Function Expression), it will create its own scope and you can pass i to the function. In that case i will be a local variable (will not refer to i in the closure) and value of the i in every loop will be preserved.\n\n// ES5\nfor(var i = 0; i < 10; i++) {\n    setTimeout((function(i) {\n      console.log(i);\n    })(i), 10)\n}\n\n//or\nfor(var i = 0; i < 10; i++) {\n  setTimeout(console.log.bind(console, i), 10);\n}\n\n// ES6\nfor(let i = 0; i < 10; i++) {\n  setTimeout(() = {\n    console.log(i);  \n  }, 10);\n}\n\n Write a simple function to tell whether 'foo' is passed as parameter or not?\n\nAnswer: First convert arguments to an array with rest operator, after that simply use Array.prototype.includes.\n\n// ES5\nfunction isFooPassed(){\n  return Array.prototype.indexOf.call(arguments, 'foo')  0;\n}\n\n// ES6\nfunction isFooPassed(...params) {\n  return params.includes('foo');\n}\n\n How could you use \"Math.max\" to find the max value in an array?\n\nMath.max(...arr);  \n\n//ES5 way\n//Math.max.apply(Math, arr);  \n\n How could you set a prefix before everything you log? for example, if you log('my message') it will log: (app) my message\n\nAnswer: Just get the arguments, convert it to an array and unshift whatever prefix you want to set. Finally, use apply to pass all the arguments to console.\n\n// ES5\nfunction log(){\n  var args = Array.prototype.slice.call(arguments);\n  args.unshift('(app)');\n  console.log.apply(console, args);\n}\n\n// ES6 \nfunction log(...params){\n  console.log(['(app)', ...params]);\n}\n\n Cashing / Memoization. How could you implement cache to save calculation time for a recursive fibonacci function?\n\nconst fibonacci = (() = {\n  const memo = {};\n\n  function f(n) {\n    let value;\n\n    if (memo[n]) {\n      value = memo[n];\n    } else {\n      if (n === 0 || n === 1)\n        value = n;\n      else\n        value = f(n - 1) + f(n - 2);\n\n      memo[n] = value;\n    }\n\n    return value;\n  }\n\n  return f;\n})();\n\nExplanation: \n\nMemoization is a programming technique which attempts to increase a function’s performance by caching its previously computed results. Because JavaScript objects behave like associative arrays, they are ideal candidates to act as caches. Each time a memoized function is called, its parameters are used to index the cache. If the data is present, then it can be returned, without executing the entire function.  However, if the data is not cached, then the function is executed, and the result is added to the cache.\n\nIn the following example, the original Fibonacci function is rewritten to include memoization. In the example, a self-executing anonymous function returns an inner function, f(), which is used as the Fibonacci function. When f() is returned, its closure allows it to continue to access the “memo” object, which stores all of its previous results. Each time f() is executed, it first checks to see if a result exists for the current value of “n”. If it does, then the cached value is returned. Otherwise, the original Fibonacci code is executed. Note that “memo” is defined outside of f() so that it can retain its value over multiple function calls. Recall that the original recursive function was called over 40 billion times to compute the 50th Fibonacci number. By implementing memoization, this number drops to 99.\n\n Why wrapping the entire content of a JavaScript source file in IIFE?\n\n(function($) { /.../ } )(jQuery);\n\nAnswer: This technique creates a closure around the entire contents of the file which, perhaps most importantly, creates a private namespace and thereby helps avoid potential name clashes between different JavaScript modules and libraries.\n\nExplanation: Another feature of this technique is to allow for an easily referenceable (presumably shorter) alias for a global variable.\n\n Explain why the following doesn't work as an IIFE: function foo(){ }();\n\nAnswer: Because foo isn’t being called! This is a function definition, it defines foo. But it’s not a function expression - that is, it’s not understood by the JS parser to actually call a function.\n\nFor the parser, things look like this:\n\nfunction foo(){\n} // ok, done with that function definition\n  // (silly human left off the semicolon, how embarrassing!)\n\n(); // Are they trying to call something? What’s the function’s name?\n    // PARSE ERROR\n\nIn order to prep the parser that we're actually dealing with a function expression we have to wrap things up in () like so:\n\n(\n  function foo(){\n  }()\n);\n\nAlso will work with ! and + operators:\n\n+function() {\n  \n}();\n\n!function() {\n\n}();\n\nObjects \n\n What the heck is this in JavaScript?\n\nAnswer: At the time of execution of every function, JavaScript engine sets a property to the function called this which refer to the current execution context. this is always refer to an object and depends on how function is called:\n\nIn the global context or inside a function this refers to the window/global object. In ES6 module or with use strict directive it's undefined\nWhile executing a method in the context of an object, the object becomes the value of this\nIf you use a constructor (by using new keyword) to create an object, the value of this will refer to the newly created object.\nSet the value of this to any arbitrary object by passing the object as the first parameter of bind, call or apply\nUse arrow function for use parent LexicalEnvironment.\n\n Why we need call or apply or bind. If you want to use an arbitrary object as value of this, how will you do that?\n\nAnswer: To use an arbitrary object as value of this.\n\nThere are at least four different ways to doing this by using bind, call, apply and arrow function.\n\ncall & apply VS bind, the simplest explanation\n\n How would you compare two objects?\n\nAnswer: JavaScript has two different approaches for testing equality. Primitives like strings and numbers are compared by their value, while objects like arrays, dates, and user defined objects are compared by their reference. This means it compares whether two objects are referring to the same location in memory.\n\nEquality check will check whether two objects have same value for same property. To check that, you can get the keys for both the objects. \n\nUse lodash or any npm equivalent.\n\nOr implement by own:\n\nfunction isEqual(a, b) {\n    var aProps = Object.getOwnPropertyNames(a),\n        bProps = Object.getOwnPropertyNames(b);\n\n    if (aProps.length !== bProps.length) {\n        return false;\n    }\n\n    for (var i = 0; i < aProps.length; i++) {\n        var propName = aProps[i];\n        \n        if (a[propName] !== b[propName]) {\n            return false;\n        }\n    }\n    return true;\n}\n\n Extend Core Object through prototype. Example 1. How could you write a method on instance of a date which will give you next day?\n\nAnswer: You need to declare a method on the prototype of Date object. To get access to the current value of the instance of the date use this\n\nDate.prototype.nextDay = function () {\n  return new Date(this.setDate(this.getDate() + 1));\n} \n\nconst date = new Date(); \ndate; //Fri May 16 2014 20:47:14 GMT-0500 (Central Daylight Time)\ndate.nextDay();//Sat May 17 2014 20:47:14 GMT-0500 (Central Daylight Time)\n\n Extend Core Object through prototype. Example 2. How could you make this work [1,2,3,4,5].duplicator() to return [1,2,3,4,5,1,2,3,4,5]?\n\nAnswer: We need to add a method in the prototype of Array object.\n\n// ES5\nArray.prototype.duplicator = function(){\n  return this.concat(this);\n}\n\nArray.prototype.duplicator = function() {\n  return [...this, ...this];\n} \n\n In what order are logging properties in the object?\n\nvar codes = {\n  // keys of country: name of country\n  '7': 'Russian Federation',\n  '38': 'Ukraine',\n  '1': 'USA',\n  '57': 'Norway'\n};\n\nfor (var code in codes) console.log(code); // ?\n\nAnswer: 1, 7, 38, 57\n\nExplanation:\nIf name of property is non-numeric string, such keys always moving in the order in which they assigned. On the other hand, if the name of the property - a number or a numeric string, then all modern browsers such properties are sorted for internal optimization.\n\n Why using for...in for Array iteration is wrong?\n\nAnswer: Array indexes are just enumerable properties with integer names and are otherwise identical to general Object properties. There is no guarantee that for...in will return the indexes in any particular order. The for...in loop statement will return all enumerable properties, including those with non–integer names and those that are inherited.\n\nAnother point is that for (var i = 0; i < arr.length; i++) is up to 10-100x time faster.\n\n OOP\n\n How prototype inheritance works? Are you aware of classical approach and with OOLO.\n\nAnswer: In most languages, there are classes and objects. Classes inherit from other classes. In JavaScript, the inheritance is prototype-based. That means that there are no classes. Instead, an object inherits from another object. The main point is that one object can be prototype of another object. That means if property isn’t found in the object - than it takes from prototype object. In JavaScript this implementation is at the language level.\n\nExplanation: OOP in prototype style\n\n Example. Make a subclass from parent class Animal\n\n// parent class or abstract class\nfunction Animal(name) {\n  this.name = name;\n  this.speed = 0;\n}\n\nAnimal.prototype.run = function() {\n  console.log(${this.name} run!);\n}\n\nfunction Rabbit() {\n  /.../\n}\n\n/.../\n\nAnswer:\n\nfunction Animal(name) {\n  this.name = name;\n  this.speed = 0;\n}\n\nAnimal.prototype.run = function() {\n  console.log(${this.name} run!);\n}\n\nfunction Rabbit() {\n  Animal.apply(this, arguments)\n}\n\nRabbit.prototype = Object.create(Animal.prototype);\n\n// optionally\nRabbit.prototype.constructor = Rabbit;\n\nRabbit.prototype.run = function() {\n  // optionally\n  Animal.prototype.run.apply(this);\n  console.log(${this.name} jumps!);\n};\n\nvar rabbit = new Rabbit('white rabbit');\nrabbit.run();\n\n Rewrite previous example to ES6 classes.\n\nAnswer:\n\nclass Animal {\n  constructor(name) {\n    this.name = name;\n    this.speed = 0;\n  }\n  run() {\n    console.log(${this.name} run!);\n  }\n}\n\nclass Rabbit extends Animal {\n  constructor(name) {\n    super(name)\n  }\n  run() {\n    super.run();\n    console.log(${this.name} jumps);\n  };\n}\n\nvar rabbit = new Rabbit('white rabbit');\nrabbit.run();\n\n Difference between: function Person(){}, var person = Person(), and var person = new Person()? What new operator do?\n\nAnswer: In the example below we define a new \"class\" called Person with an empty constructor. Invoke function Person() will return undefined. On the other hand invoking new Person will return an empty object {}.\n\nExplanation:\n\nJavaScript is a prototype-based language and contains no class statement, such as is found in C++ or Java. This is sometimes confusing for programmers accustomed to languages with a class statement. Instead, JavaScript uses functions as constructors for classes. Defining a class is as easy as defining a function. In the example below we define a new class called Person with an empty constructor.\n\nAnd the spec says, the new operator uses the internal [[Construct]] method, and it basically does the following:\n\nInitializes a new empty object (no properties)\nSets the prototype of the new object to the value of the prototype property of Person.\n  Note: The default value of prototype for a function is an object (automatically created when the function is declared) with its prototype set to Object.prototype and a constructor property pointing back to the function Person.\n  Note: The terminology can be confusing. The property named prototype is not the same as the prototype of the object. Only functions have the property named \"prototype\", but all objects have a prototype.\nCalls the function Person with this set to the new object, and with the supplied arguments.\nIf calling the function Person returns an object, this object is the result of the expression. Otherwise the newly created object is the result of the expression.\n\n new F vs Object.create\n\nAnswer: new F is Object.create(F.prototype) with additionally running the constructor function. And giving the constructor the chance to return the actual object that should be the result of the expression instead of this. So basically Object.create doesn't execute the constructor.\n\nExplanation:\n\nObject.create methods allows you to easily implement differential inheritance, where objects can directly inherit from other objects.\n\nvar userB = {\n  sayHello: function() {\n    console.log('Hello '+ this.name);\n  }\n};\n\nvar bob = Object.create(userB, { // object descriptor\n  'id' : {\n    value: MY_GLOBAL.nextId(),\n    enumerable:true // writable:false, configurable(deletable):false by default\n  },\n  'name': {\n    value: 'Bob',\n    enumerable: true\n  }\n});\n\nDOM\n\n Is there are a difference window VS document?\n\nAnswer:  Yes. JavaScript has a global window object and everything runs under it. document is a property of window object.\n\nExplanation: \n\n window is global object that holds global variables, global functions, location, history everything is under it. Besides, setTimeout, ajax call (XMLHttpRequest), console or localStorage are part of window.\n\ndocument is also under window. document represents the DOM,  the object oriented representation of the html markup. All the nodes are part of document. Hence you can use getElementById or addEventListener on document. These methods are not present in the window object.\n\n How could you make sure to run some javaScript when DOM is ready like $(document).ready?\n\nAnswer: There are four different ways:\n\nPut your script in the last tag of html body element. DOM would be ready by the time browser hits the script tag.\nPlace your code inside a DOMContentLoaded handler. This event will be fired when DOM is completely loaded.\nWatch changes in the readyState of the document. And the last state is \"complete\" state, you can put your code there.\nUse jQuery $(document).ready.\n\n window.onload VS document.onload VS document.addEventListener('DOMContentLoaded'). Do they fire at the same time?\n\nAnswer:\nwindow.onload is fired when all page is loaded, including all resources (images, styles, iframes)\ndocument.onload is fired when DOM (DOM tree built from markup code within the document) is ready which without external content.\nDOMContentLoaded means that DOM has already been built, we can use handlers or search through the nodes, but resources such as images, styles don't be loaded yet\n\n Is attribute similar to property?\n \nAnswer: We operate with DOM-properties via JS. Attributes are part of HTML markup.\n\nExplanation: \n\nWhat is a property?\n\nJS objects have DOM-properties. These properties are kind of like instance variables for the particular element. As such, a property can be different types (boolean, string, etc.). Properties can be accessed as object properties: a.href\n\nWhat is an attribute?\n\nAttributes are in the HTML itself, rather than in the DOM. They are very similar to properties, but not quite as good. When a property is available it’s recommended that you work with properties rather than attributes.\n\nelem.hasAttribute(name)\nelem.getAttribute(name)\nelem.setAttribute(name, value)\nelem.removeAttribute(name)\nelem.attributes\n\n What are the different ways to get an element from DOM?\n \nAnswer: You can use the following methods in document:\n\ngetElementById to get a element that has the provided Id.\ngetElementsByClassName to get a nodelist (nodelist is not an array, rather it is array-like object) by providing a class name.\ngetElementsByTagName to get a nodelist by the provided tag name.\ngetElementsByName to get a nodelist by name property\nquerySelector you will pass css style selector and this will return first matched element in the DOM.\nquerySelectorAll will return a non-live nodelist by using depth-first pre order traversal of all the matched elements. Non-live means, any changes after selecting the elements will not be reflected.\n\nThere are two more options but don't used frequently:\n\ngetElementsByName returns the list of elements by the provided name of the html tag\ngetElementsByTagNameNS returns elements with particular tag name within the provided namespace\n\n Fastest way to Query DOM: \n\nAnswer: If you have an ID of an element getElmentById is the fastest way to select an element. However, you should not have so many ID in you document to avoid style repetition. getElementsByClassName is the second quickest way to select an element.\n\nHere is the list. As we go downwards through the list, it takes more time to select elements.\n\nID (myID)\nClass (.myClass)\nTag (div, p)\nSibling (div+p, div~p)\nchild (divp)\nDescendant (div p)\nUniversal (*)\nAttribute (input[type=\"checkbox\"])\nPseudo (p:first-child)\n\n  Why querySelectorAll('.my-class') is slower than getElementsByClassName('my-class')?\n\nAnswer: querySlectorAll is a generic purpose method. It is optimized for different kinds of selectors. Hence it has to check whether you put a \"#\" or \".\" in front of the parameter you are passing. If you are just passing a class name with \".\", under the hood it uses getElementsByClassName (could vary based on browser implements). Whereas if you directly uses getElementsByClassName it directly uses this method and doesn't have to go through all the initial processing of querySelectorAll. Hence to search elements with a particular class name, getElementsByClassName is faster than querySelectorAll.  \n\n Why we can't use forEach or similar array methods on a NodeList? How could you solve this problem?\n\nAnswer: Both array and nodeList have length and you can loop through elements but they are not same object.\n\nBoth are inherited from Object. However array has different prototype object than nodeList. forEach, map, etc are on array.prototype which doesn't exist in the NodeList.prototype object:\n\nmyArray -- Array.prototype -- Object.prototype -- null\n\nmyNodeList -- NodeList.prototype -- Object.prototype -- null\n\nAnswer: Convert NodeList to an array. After that you will have access to all array.prototype methods.\n\n// ES5\nvar myNodeList = document.querySelectorAll('.my-class');\nvar nodesArray = Array.prototype.slice.call(myNodeList);\n\n//use array method on nodeList\nnodesArray.forEach(function(el, idx){\n  console.log(idx, el);\n});\n\n// ES6\nconst myNodeList = document.querySelectorAll('.my-class');\n\n// Spread operator\n[...myNodeList].forEach(cb);\n\n// Array.from()\nArray.from(myNodeList).forEach(cb);\n\n// for...of statement\nfor (var el of myNodeList) cb(el);\n\n  How would you add/remove/toggle a class to an element?\n\nAnswer:\n\nel.classList.remove('my-class'); //removing a class\nel.classList.toggle('my-class');  // toggling a class\nel.classList.contains('my-class'); // checking whether class exists\n\n How to check if element isn't empty, without children?\n \nif (!elem.childNodes.length) { ... }\n\nif (!elem.hasChildNodes()) { ... }\n\nif (!elem.firstChild) { ... }\n\nif (!elem.lastChild) { ... }\n\n How you would perform next operation: create element with content, add data-foo attribute, append newly created element to whatever you want, then move it before some element, change text of it, remove it from DOM. How to clone an element?\n \nAnswer: Use the next methods document.createElement(tag), el.innerHTML, parent.appendChild(el), parent.insertBefore(el, someEl), parent.removeChild(el)\n\nFor clone an element we can create function or use el.cloneNode(true) where true means deep cloning.\n\n How to delete all children of element?\n\nAnswer: \n\nfunction removeChildren(elem) {\n  try {\n    elem.innerHTML = ''; //dont work with table cells and etc.\n  } catch (e) {\n    while (elem.firstChild) {\n      elem.removeChild(elem.firstChild);\n    }\n  }\n}\n\n createTextNode vs innerHTML\n\nAnswer: It depends on content. innerHTML inserts content as HTML, but createTextNode inserts tags as text.\n\n What is the best way to create a DOM element? Set innherHTML or use createElement? Do you know about insertAdjacentHTML?\n\nAnswer: According to jsPerf option 1 is approximately 3 times slower than option 2.\n\nExplanation: \n\nappendChild does not cause a complete rebuild of the DOM or even all of the elements/nodes within the target.\n\ninnerHTML does cause a complete rebuild of the content of the target element, which if you're appending is unnecessary.\n\nAppending via innerHTML += content makes the browser run through all of the nodes in the element building an HTML string to give to the JavaScript layer. Your code then appends text to it and sets innerHTML, causing the browser to drop all of the old nodes in the target, re-parse all of that HTML, and build new nodes. So in that sense, it may not be efficient. (However, parsing HTML is what browsers do and they're really, really fast at it.)\n\nSetting innerHTML does indeed invalidate any references to elements within the target element you may be holding - because those elements don't exist anymore, you removed them and then put in new ones (that look very similar) when you set innerHTML.\n\nIn short, if you're appending, I'd use appendChild or insertAdjacentHTML. If you're replacing, there are very valid situations where using innerHTML is a better option than creating the tree yourself via the DOM API.\n\nFinally, it's worth mentioning insertAdjacentHTML, which is a function that you can use to insert nodes and elements into or next to an element using an HTML string. You can append to an element with it: theElement.insertAdjacentHTML(\"beforeend\", \"the HTML goes here\");\n\n What is createDocumentFragment and why you might use it?\n\nAnswer: If you are changing DOM that cause expensive reflow, you can avoid it by using documentFragment as it is managed in the memory.\n\nExplanation:\n\ndocumentFragment a very lightweight or minimal part of a DOM or a subtree of a DOM tree. It is very helpful when you are manipulating a part of DOM for multiple times. It becomes expensive to hit a certain portion of DOM for hundreds time. You might cause reflow for hundred times.\n\nA bad practice, you are hitting the DOM every single time:\n\n//\nvar list = ['foo', 'bar', 'baz', ... ],\n    el, text;\nfor (var i = 0; i < list.length; i++) {\n    el = document.createElement('li');\n    text = document.createTextNode(list[i]);\n    el.appendChild(text);\n    document.body.appendChild(el);\n}\n\nA good practice, you causing reflow one time:\n\nvar fragment = document.createDocumentFragment(),\n    list = ['foo', 'bar', 'baz', ...],\n    el, text;\nfor (var i = 0; i < list.length; i++) {\n    el = document.createElement('li');\n    text = document.createTextNode(list[i]);\n    el.appendChild(text);\n    fragment.appendChild(el);\n}\ndocument.body.appendChild(fragment);\n\n When would you use \"document.write()\" ?\n\nAnswer: In terms of vendors supplying third parties or analytics code (like Google Analytics) it's actually the easiest way for them to distribute such snippets.\n\nscript\n  var url = 'http://ads.com/buyme?screen=' + screen.width + \"x\" + screen.height;\n\n  document.write('script src=\"' + url + '\"/scr' + 'ipt');\n/script\n\nExplanation:\n\nIt keeps the scripts small\nThey don't have to worry about overriding already established onload events or including the necessary abstraction to add onload events safely\nIt's extremely compatible\n\ndocument.write only works while the page is loading; If you call it after the page is done loading, it will overwrite the whole page.\n\nThis effectively means you have to call it from an inline script block - And that will prevent the browser from processing parts of the page that follow. Scripts and Images will not be downloaded until the writing block is finished.\n\n What is reflow? What causes reflow? How could you reduce reflow?\n\nAnswer: When you change size or position of an element in the page, all the elements after it has to change their position according to the changes you made. For example, if you change height on an element, all the elements under it has to move down in the page to accomodate a change in height. Hence, flow of the elements in the page is changed and this is called reflow.\n\nRe-flows could be very expensive and it might have a performance hit specially in the smaller devices like phone. As it might causes changes in the portion (or whole) layout of the page.\n\nThe following cases causes reflow:\n\nchange layout (geometry of the page)\nresize the window\nchange height/width of any element\nchanging font\nchange font size\nmove DOM element (animation)\nadding or removing stylesheet\ncalculating offset height or offset width\ndisplay: none;\n\nHow to avoid: To avoid reflow, try to avoid doing things in the above list and some more in the below\n\navoid setting multiple inline style\napply animation to the elements that are positioned fixed or absolute\navoid tables for layout\n\nMore: reflow and repaint: css performance makes your JS slow\n\n What is repaint and when does this happen?\n\nAnswer: repaint happens when you change the look of an element without changing the size and shape. This doesn't cause reflow as geometry of the element didn't changed.\n\nHow it happens:\n\nchange background color\nchange text color\nvisibility hidden\n\n What is defer and async attribute does in a script tag?\n\nAnswer: HTML parser will ignore defer and async keyword for inline script (script that does not have a src attribute).\n\nwith script async src=\"...\" browser downloads the file during HTML parsing and will pause the HTML parser to execute it when it has finished downloading\nwith script defer src=\"...\" browser downloads the file during HTML parsing and will only execute it after the parser has completed. defer scripts are also guarenteed to execute in the order that they appear in the document.\n\nscript src=\"1.js\" async/script\nscript src=\"2.js\" async/script\n\nExamples: \n\n//1\nscript src=\"big.js\"/script\nscript src=\"small.js\"/script\n\n//2\nscript async src=\"big.js\"/script\nscript async src=\"small.js\"/script\n\n//3\nscript defer src=\"big.js\"/script\nscript defer src=\"small.js\"/script\n\nEvents\n\n What is event bubble? How does event flows (event phases)?\n\nAnswer: to understand event bubble, you have to understand what happen when you click on anything on a page.\n\nThe event flow model specified by DOM Level 2 Events has three phases to it:\n\nCapture: When you clicked, browser knows a click event occurred. It starts from the window (lowest level/root of your website), then goes to document, then html root tag, then body, then table... its trying to reach the the as lowest level of element as possible. This is called capture phase (phase -1).\nTarget: When browser reach the lowest level of element. In this case, you have clicked on a table cell (table data) hence target would be td tag. Then browser checks whether you have any click handler attached to this element. If there is any, browser executes that click hander. This is called target phase (phase -2).\nBubbling: After firing click hander attached to td, browser walks toward root. One level upward and check whether there is any click handler attached with table row tr element. If there is any it will execute that. Then it goes to tbody, table, body, html, document, window. In this stage its moving upward and this is called event bubbling or bubbling phase (phase-3).\n\nEvent handlers with oneventName doesn't know anything about capture phase.\n\nTo capture on capture phase need to addEventListener(eventName, cb, true), otherwise it will work by bubble phase.\n\n Explain event delegation\n\nAnswer: Event delegation allows you to avoid adding event listeners to specific nodes, instead, the event listener is added to one parent. That event listener analyzes bubbled events to find a match on child elements.\n\nExplanation: \n\nLet's say that we have a parent UL element with several child elements:\n\nul id=\"parent-list\"\n  li id=\"post-1\"Item 1/li\n  li id=\"post-2\"Item 2/li\n  li id=\"post-3\"Item 3/li\n  li id=\"post-4\"Item 4/li\n  li id=\"post-...\".../li\n  li id=\"post-1001\"Item 1001/li\n/ul\n\nLet's also say that something needs to happen when each child element is clicked.  You could add a separate event listener to each individual LI element, but what if LI elements are frequently added and removed from the list?  Adding and removing event listeners would be a nightmare, especially if addition and removal code is in different places within your app. The better solution is to add an event listener to the parent UL element. \n\nWhen the event bubbles up to the UL element, you check the event object's target property to gain a reference to the actual clicked node:\n\n// Get the element, add a click listener...\ndocument.getElementById(\"parent-list\").addEventListener(\"click\", function(e) {\n  // e.target is the clicked element!\n  // If it was a list item\n  if(e.target && e.target.nodeName == \"LI\") {\n    // List item found!  Output the ID!\n    console.log(\"List item \", e.target.id.replace(\"post-\", \"\"), \" was clicked!\");\n  }\n});\n\n Can you remove an event handler from an element?\n\nAnswer: target.removeEventListener('click', handledName)\n\n How could you prevent a click on an anchor from going to the link? How could you stop further propagation of an event?\n\nAnswer: preventDefault() inside event handler. However, this doesn't stop further propagation. To stop it event.stopPropagation();\n\n How to capture all click in a page?\n\nAnswer: You can leverage event bubble to get all the clicks. As all the clicks will be bubbled up to the body.\n\ndocument.querySelector('body').addEventListener('click', function(e){\n  console.log('body clicked', e.target);\n});\n\n//or\nwindow.onclick = function(e){\n  console.log('someone clicked', e.target)\n}\n\n AJAX\n  \n Explain AJAX in as much detail as possible\n\nAnswer: AJAX is a way to communicate to the server without reloading the page. Once we receive the data from the server, we can then manipulate those data and display unto certain parts of the page, this is why we don’t need to reload the page.\n\nExplanation: AJAX stands for Asynchronous JavaScript and XML. In a nutshell, it is the use of the XMLHttpRequest object to communicate with server-side scripts. It can send as well as receive information in a variety of formats, including JSON, XML, HTML, and even text files. AJAX’s most appealing characteristic, however, is its \"asynchronous\" nature, which means it can do all of this without having to refresh the page\n\nTypical example for GET request with XMLHttpRequest:\n\nscript src=\"https://gist.github.com/qetr1ck-op/f52380392d7f0afb4835f8257a483ff7.js\"/script\n\n What is COMET? How to achieve this technique?\n\nAnswer: he AJAX - is a \"request sent - get the result,\" and the COMET - is \"a continuous channel through which the data come.\"\n\nExplanation:\n\nComet is a Web application model that enables web servers to send data to the client without having to explicitly request it.\n\nExamples COMET-app:\n\nChat - man sitting and watching what others write. At the same time new messages arrive \"on their own\", he should not have to press a button to refresh the chat window.\nAuction - a person looks at the screen and sees renewed the current bid for the goods.\nEditing interface - when one editor is beginning to change the document, others see the information about it. Perhaps, and collaborative editing, editors when they see each other's changes.\n\nCOMET techniques overview:\n\nPolling: a simple method based on periodically polling the server.\nLong poll: A method by which a client opens a connection and doesn't close it up until the event occurs. In the event occurs, the client receives a notification and then opens a connection again.\n\"Infinite\" iframe: The method is based on html document download features. It creates an invisible iframe, which reads \"infinite\" file. When an event occurs, a new row is added to the file. The string can be a javascript snippet.\nHTML5 WebSockets: specification defines an API establishing \"socket\" connections between a web browser and a server. In plain words: There is an persistent connection between the client and the server and both parties can start sending data at any time.\n\n How to work with HTTP headers in AJAX. Do we have a restriction?\n\nAnswer: There are three methods setRequestHeader(name, value), getResponseHeader(name), getAllResponseHeaders()\n\n Send JSON Object with Ajax?\n\nAnswer: Use xhr.setRequestHeader(\"Content-Type\", \"application/x-www-form-urlencoded\") and JSON.stringify(object);\n\nvar jsonRequest = \"json_name=\" + JSON.stringify({name:\"John\", time:\"2pm\"});\nvar xhr = new XMLHttpRequest();\n\nxhr.open(\"POST\", \"/submit\");\nxhr.setRequestHeader(\"Content-Type\", \"application/x-www-form-urlencoded\");\nxhr.send(json_upload);\n\n Sending POST data using an XMLHttpRequest using different encoding patterns.\n\nAnswer: With XMLHttpRequest we don't need explicitly set header with Content-type.\n\nIn spec are 3 types for submitting body entity:\n\napplication/x-www-form-urlencoded\nmultipart/form-data\ntext-plain\n\nWith application/x-www-form-urlencoded:\n\nvar xhr = new XMLHttpRequest();\n\nvar body = 'name=' + encodeURIComponent(name) +\n  '&surname=' + encodeURIComponent(surname);\n\nxhr.open(\"POST\", '/submit', true)\nxhr.setRequestHeader('Content-Type', 'application/x-www-form-urlencoded')\n\nxhr.onreadystatechange = ...;\n\nxhr.send(body);\n\nWith multipart/form-data:\n\nform name=\"person\"\n  input name=\"name\" value=\"John\"\n  input name=\"surname\" value=\"Doe\"\n/form\n\nscript\n  var formData = new FormData(document.forms.person);\n\n  formData.append(\"foo\", \"bar\");\n\n  var xhr = new XMLHttpRequest();\n  xhr.open(\"POST\", \"/url\");\n  xhr.setRequestHeader('Content-Type', 'multipart/form-data')\n  xhr.send(formData);\n/script\n\n What is CORS? What techniques you know to avoid it?\n\nES6\n\n When standard was finalized?\n\nThe ES6 specification was finalized in June 2015, (hence ES2015).\n\nFuture versions of the specification will follow the ES[YYYY] pattern, e.g ES2016 for ES7.\n\n Tooling\n\nTo get ES6 working today, you need a JavaScript-to-JavaScript transpiler:\n\nThey allow you to compile code in the latest version into older versions of the language\nAs browser support gets better, we’ll transpile ES2016 and ES2017 into ES6 and beyond\nWe’ll need better source mapping functionality\nThey’re the most reliable way to run ES6 source code in production today (although browsers get ES5)\nUse babel to transpile ES6 into ES5 for static build\n\nUse babelify to incorporate babel into your Gulp, Grunt, or npm run build process\n\nUse Node.js v4.x.x or greater as they have decent ES6 support baked in, thanks to v8\n\nUse babel-node with any version of node, as it transpiles modules into ES5\n\n Assignment Destructing, the Rapid Table\n\n Spread Operator and Rest Parameters\n\n Arrow Functions\n\n Template Literals\n\n Object Literals\n\n Classes\n\n Let and Const\n\n Symbols\n\n Iterators\n\n Generators\n\n Promises\n\n Maps / WeakMaps\n\n Sets / WeakSets\n\n Modules\n\n Proxy\n\nTODO with https://ponyfoo.com/articles/es6\n\n JavaScript: advance\n\n What do you think of AMD vs CommonJS and ES6 modules?\n\nAnswer:\n\nFor many years JS had a single widely accepted module format, which is to say, there was none. Everything was a global variable petulantly hanging off the window object. \n\nDark Ages. Long ago an adhoc group formed to solve the global conflict. The fruits of this vigilante justice are known today as CommonJS. Multiple competing formats were proposed and implemented in the wild by these dashing radicals and two bright lights emerged with significant adherents: AMD and CJS.\n\nAsynchronous Module Design (AMD) accounts for the async nature of JS but some felt the aesthetics were harder to read with a wrapper function.\n\nCommonJS (CJS) is synchronous, thus blocking, but generally understood to be an easier read.\n\n// this is an AMD module\ndefine(function () {\n  return something\n})\n\n// and this is CommonJS\nmodule.exports = something\n\nJavaScript vendors and concerned citizens began formally standardizing modules into the language proper. After years of thrashing, a standard module format has finally emerged with ES6.\n\n What is asynchronous programming, and why is it important in JS? Non-blocking I/O in JS.\n\nSynchronous programming means that code is executed sequentially from top-to-bottom, blocking on long-running tasks such as network requests and disk I/O.\n\nAsynchronous programming means that the engine runs in an event loop. When a blocking operation is needed, the request is started, and the code keeps running without blocking for the result. When the response is ready, an interrupt is fired, which causes an event handler to be run, where the control flow continues. In this way, a single program thread can handle many concurrent operations.\n\nNode is asynchronous by default, meaning that the server works in much the same way, waiting in a loop for a network request, and accepting more incoming requests while the first one is being handled.\n\nIn JavaScript, almost all I/O is non-blocking. This includes:\nNetworking requests\nDB operations\nDisk reads and writes\nUser interfaces are asynchronous by nature, and spend most of their time waiting for user input to interrupt the event loop and trigger event handlers\n\nThe single thread of execution asks the runtime to perform an operation, providing a callback function and then moves on to do something else. When the operation has been completed, a message is enqueued along with the provided callback function. At some point in the future, the message is dequeued and the callback fired.\n\nLet’s compare two bits of code that make HTTP requests to www.google.com and output the response to console with Node.js and the Request:\n\nrequest('http://www.google.com', function(error, response, body) {\n  console.log(body);\n});\n\nconsole.log('Done!');\n\nThe request function is executed, passing an anonymous function as a callback to execute when a response is available sometime in the future.\n“Done!” is immediately output to the console\nSometime in the future, the response comes back and our callback is executed, outputting its body to the console\n\n Do request two parallel request to http://httpbin.org/ip and http://httpbin.org/user-agent.\n\nAnswer:\n\nPromise.all([fetch('http://httpbin.org/ip'), fetch('http://httpbin.org/user-agent')])\n  .then(resps = {\n    return Promise.all([resps[0].json(), resps[1].json()])\n  })\n  .then((jsons) = console.log(jsons))\n\n Resolve promises one after another (i.e. in sequence)?\n\nAnswer:\n\nfunction runSerial() {\n    return Promise.resolve()\n        .then(task1)\n        .then(task2)\n        .then(() = {\n            console.log(\" ---- done ----\");\n        });\n}\n\nWith dynamic length of tasks\"\n\nlet urls = ['guest.json', 'user.json'];\nlet results = [];\nlet chain = Promise.resolve();\n\nurls.forEach(function(url) {\n  chain = chain\n    .then(() = httpGet(url))\n    .then((result) = {\n      results.push(result);\n    });\n});\n\nchain.then(() = {\n  console.log(results);\n});\n\n// with reduce\nurls\n  .reduce((promise, url) = {\n    return promise.then(() = httpGet(url)).then((json) = results.push(json));\n  }, Promise.resolve())\n  .then(() = {\n    console.log(results);\n  });\n\n The Event Loop\n\nThe decoupling of the caller from the response allows for the JavaScript runtime to do other things while waiting for your asynchronous operation to complete and their callbacks to fire. But where in memory do these callbacks live – and in what order are they executed? What causes them to be called?\n\nJavaScript runtimes contain a message queue which stores a list of messages to be processed and their associated callback functions. These messages are queued in response to external events (such as a mouse being clicked or receiving the response to an HTTP request) given a callback function has been provided. If, for example a user were to click a button and no callback function was provided – no message would have been enqueued.\n\nIn a loop, the queue is polled for the next message (each poll referred to as a “tick”) and when a message is encountered, the callback for that message is executed.\n\n Macrotasks and Microtasks\n\nTake this little bit of JavaScript:\n\nconsole.log('script start')\n\nconst interval = setInterval(() = {  \n  console.log('setInterval')\n}, 0)\n\nsetTimeout(() = {  \n  console.log('setTimeout 1')\n  Promise.resolve().then(() = {\n    console.log('promise 3')\n  }).then(() = {\n    console.log('promise 4')\n  }).then(() = {\n    setTimeout(() = {\n      console.log('setTimeout 2')\n      Promise.resolve().then(() = {\n        console.log('promise 5')\n      }).then(() = {\n        console.log('promise 6')\n      }).then(() = {\n        clearInterval(interval)\n      })\n    }, 0)\n  })\n}, 0)\n\nPromise.resolve().then(() = {  \n  console.log('promise 1')\n}).then(() = {\n  console.log('promise 2')\n})\nconsole.log('script end')\n\nAnswer: \n\nscript start\nscript end\npromise 1  \npromise 2  \nsetInterval  \nsetTimeout 1  \npromise 3  \npromise 4  \nsetInterval  \nsetTimeout 2  \nsetInterval  \npromise 5  \npromise 6  \nTo understand this you need to know how the event loop handles macrotasks and microtasks.\n\nmacrotasks: setTimeout, setInterval, setImmediate, I/O, UI rendering\nmicrotasks: process.nextTick, Promises, Object.observe, MutationObserver\n\nA great post.\n\n What is the difference between \"classical inheritance\" and \"prototypal inheritance\"?\n\nClass Inheritance: instances inherit from classes (like a blueprint — a description of the class), and create sub-class relationships: hierarchical class taxonomies. Instances are typically instantiated via constructor functions with the new keyword. Class inheritance may or may not use the class keyword from ES6.\n\nPrototypal Inheritance: instances inherit directly from other objects. Instances are typically instantiated via factory functions or Object.create(). Instances may be composed from many different objects, allowing for easy selective inheritance.\n\nGood to hear:\nClasses: create tight coupling or hierarchies/taxonomies.\nPrototypes: mentions of concatenative inheritance, prototype delegation, functional inheritance, object composition.\n\n What are the pros and cons of functional programming vs object-oriented programming?\n\nOOP Pros: It’s easy to understand the basic concept of objects and easy to interpret the meaning of method calls. OOP tends to use an imperative style rather than a declarative style, which reads like a straight-forward set of instructions for the computer to follow.\n\nOOP Cons: OOP Typically depends on shared state. Objects and behaviors are typically tacked together on the same entity, which may be accessed at random by any number of functions with non-deterministic order, which may lead to undesirable behavior such as race conditions.\n\nFP Pros: Using the functional paradigm, programmers avoid any shared state or side-effects, which eliminates bugs caused by multiple functions competing for the same resources. With features such as the availability of point-free style (aka tacit programming), functions tend to be radically simplified and easily recomposed for more generally reusable code compared to OOP.\n\nFP Cons: Over exploitation of FP features such as point-free style and large compositions can potentially reduce readability because the resulting code is often more abstractly specified, more terse, and less concrete.\nMore people are familiar with OO and imperative programming than functional programming, so even common idioms in functional programming can be confusing to new team members.\n\n What does \"favor object composition over class inheritance\" mean?\n\nThis is a quote from \"Design Patterns: Elements of Reusable Object-Oriented Software\". \n\nObject composition is a way to combine simple objects or data types into more complex ones. It means that code reuse should be achieved by assembling smaller units of functionality into new objects instead of inheriting from classes and creating object taxonomies.\n\nimport { a, b, c } from 'components';\ncomposedObject = Object.assign({}, a, b, c);\n\nGood to hear:\n\nAvoid class hierarchies.\nAvoid brittle base class problem.\nAvoid tight coupling.\nAvoid rigid taxonomy (forced is-a relationships that are eventually wrong for new use cases).\nAvoid the gorilla banana problem (“what you wanted was a banana, what you got was a gorilla holding the banana, and the entire jungle”).\n\n What are two-way data binding and one-way data flow, and how are they different?\n\nTwo way data binding means that UI fields are bound to model data dynamically such that when a UI field changes, the model data changes with it and vice-versa.\n\nOne way data flow means that the model is the single source of truth. Changes in the UI trigger messages that signal user intent to the model (or “store” in React). Only the model has the access to change the app’s state. The effect is that data always flows in a single direction, which makes it easier to understand.\n\nOne way data flows are deterministic, whereas two-way binding can cause side-effects which are harder to follow and understand.\n\nGood to hear:\nReact is the new canonical example of one-way data flow, so mentions of React are a good signal. Cycle.js is another popular implementation of uni-directional data flow.\nAngular is a popular framework which uses two-way binding.\n\n What are the pros and cons of monolithic vs microservice architectures?\n\nA monolithic architecture means that your app is written as one cohesive unit of code whose components are designed to work together, sharing the same memory space and resources.\n\nA microservice architecture means that your app is made up of lots of smaller, independent applications capable of running in their own memory space and scaling independently from each other across potentially many separate machines.\n\nGood to hear:\n\nMonolithic Pros: The major advantage of the monolithic architecture is that most apps typically have a large number of cross-cutting concerns, such as logging, rate limiting, and security features such audit trails and DOS protection.\n\nWhen everything is running through the same app, it’s easy to hook up components to those cross-cutting concerns.\n\nMonolithic cons: Monolithic app services tend to get tightly coupled and entangled as the application evolves, making it difficult to isolate services for purposes such as independent scaling or code maintainability.\n\nMonolithic architectures are also much harder to understand, because there may be dependencies, side-effects, and magic which are not obvious when you’re looking at a particular service or controller.\n\nMicroservice pros: Microservice architectures are typically better organized, since each microservice has a very specific job, and is not concerned with the jobs of other components. Decoupled services are also easier to recompose and reconfigure to serve the purposes of different apps (for example, serving both the web clients and public API).\n\nThey can also have performance advantages depending on how they’re organized because it’s possible to isolate hot services and scale them independent of the rest of the app.\n\nMicroservice cons: As you’re building a new microservice architecture, you’re likely to discover lots of cross-cutting concerns that you did not anticipate at design time. A monolithic app could establish shared magic helpers or middleware to handle such cross-cutting concerns without much effort.\n\nMarkup\n\n HTML\n\n What is doctype? Why do u need it?\n\nAnswer: doctype is an instruction to the browser to inform about the version of html document and how browser should render it.\n\nExplanation: \n\nIt ensures how element should be displayed on the page by most of the browser. And it also makes browser's life easier. otherwise, browser will guess and will go to quirks mode. Moreover, doctype is required to validate markup.\n\n!DOCTYPE html\nmeta charset=\"UTF-8\"\n\n Difference between standard/strict mode and quirks mode?\n\nAnswer: quirks mode in browser allows u to render page for as old browsers. This is for backward compatibility.\n\n What is the use of data- attribute?\n\nAnswer: allow you to store extra information/data in the DOM and allows to write valid html with embedded private data. You can easily access data attribute by using JS.\n\ndiv id=\"myDiv\" data-user=\"jsDude\" data-list-size=\"5\" data-maxage=\"180\"/div\n\n What is the difference between span and div?\n\nAnswer: div is a block element, span is inline.\n\nThis means that to use them semantically, divs should be used to wrap sections of a document, while spans should be used to wrap small portions of text, images, etc.\n\n  When should you use section, div or article?\n\nAnswer: To decide which of these three elements is appropriate, choose the first suitable option:\n\nWould the enclosed content would make sense on it’s own in a feed reader? If so use article\nIs the enclosed content related? If so use section\nFinally if there’s no semantic relationship use div\n\n What is \"Semantic HTML?\"\n\nAnswer: Semantic HTML is a coding style where the tags embody what the text is meant to convey.\n\nExplanation: \n\nIn Semantic HTML, tags like b/b for bold, and i/i for italic should not be used, reason being they just represent formatting, and provide no indication of meaning or structure. The semantically correct thing to do is use strong/strong and em/em. These tags will have the same bold and italic effects, while demonstrating meaning and structure (emphasis in this case).\n\n What are some new HTML5 markup elements?\n\nAnswer:\n\nThere are several: article, aside, bdi, command, details, figure, figcaption, summary, header, footer, hgroup, mark, meter, nav, progress, ruby, rt, section, time, and wpr.\n\n What are the new media-related elements in HTML5?\n\nAnswer: \n\nHTML5 has strong support for media. There are now special audio and video tags. There are additional A/V support tags as well: embed is a container for 3rd party applications.\n\n What is the difference between SVG and Canvas?\n\nAnswer: \n\nSVG is a document format for scalable vector graphics.\nCanvas is a javascript API for drawing vector graphics to a bitmap of a specific size.\n\nExplanation: \n\nSVG is XML based, which means that every element is available within the SVG DOM. You can attach JavaScript event handlers for an element.\n\nWith SVG you can view, save and edit the file in many different tools.\n\nIn SVG, each drawn shape is remembered as an object. If attributes of an SVG object are changed, the browser can automatically re-render the shape.\n\nCanvas is rendered pixel by pixel. In canvas, once the graphic is drawn, it is forgotten by the browser. If its position should be changed, the entire scene needs to be redrawn, including any objects that might have been covered by the graphic.\n\nCanvas:\n\nPixel based\nSingle HTML element.(Inspect element in Developer tool. You can see only canvas tag)\nModified through script only\nEvent model/user interaction is granular (x,y)\nPerformance is better with smaller surface, a larger number of objects (10k), or both\n\nSVG:\n\nShape based\nMultiple graphical elements, which become part of the SVG DOM\nModified through script and CSS\nEvent model/user interaction is abstracted (rect, path)\nPerformance is better with smaller number of objects (<10k), a larger surface, or both\n\n Describe the difference between cookies, sessionStorage, and localStorage\n\nAnswer: localStorage, sessionStorage and cookies are all client storage solutions.\n\nCookies are small text files that websites place in a browser for tracking or login purposes. Meanwhile, localStorage and sessionStorage are new objects, both of which are storage specifications but vary in scope and duration. Of the two, localStorage is permanent and website-specific whereas sessionStorage only lasts as long as the duration of the longest open tab.\n\nYou can save to localStorage and sessionStorage only primitives, for object you need you use JSON.stringify1\n\nCSS\n\n General Website Optimization Questions\n\n How do you optimize a website’s assets?\n\nAnswer: There are a number of answers to this question: File concatenation, file compression, CDN Hosting, offloading assets, re-organizing and refining code, etc.\n\n What are ways to reduce page load time?\n\nAnswer: Again there are many answers here: Reduce image sizes, remove unnecessary widgets, HTTP compression, put CSS at the top and script references at the bottom or in external files, reduce lookups, minimize redirects, caching, etc.\n\n What kind of things must you be wary of when design or developing for multilingual sites?\n\nAnswer: Another problem with many solutions: setting the default language, using Unicode encoding, using the lang attribute, being aware of standard font sizes and text direction, and language word length (may affect layout).\n\nTechnologies\n\n JS Framework\n\nAngularJS \n\n List at least three ways to communicate between modules of your application using core AngularJS functionality.\n\nAnswer: There are at least three idiomatic way to achieve this:\n\nUsing services\nUsing events\nDirectly between controllers, using ControllerAs, or other forms of inheritance\nBy assigning models on $rootScope\nDirectly between controllers, using $parent, $$childHead, $$nextSibling, etc.\n\n Which means of communication between modules of your application are easily testable?\n\nAnswer: The big deal is in DI pattern.\n\nUsing a service is definitely easy to test. Services are injected, and in a test either a real service can be used or it can be mocked.\n\nEvents can be tested. In unit testing controllers, they usually are instantiated. For testing events on $rootScope, it must be injected into the test.\n\nFor testing direct communication between controllers, the expected results should probably be mocked. Otherwise, controllers would need to be manually instantiated to have the right context.\n\n The most popular e2e testing tool for AngularJS is Protractor. Describe how e2e testing of AngularJS applications work?\n\nThe e2e tests are executed against a running app, that is a fully initialized system. They most often spawn a browser instance and involve the actual input of commands through the user interface. The written code is evaluated by an automation program, such as a Selenium server (webdriver). That program sends commands to a browser instance, then evaluates the visible results and reports back to the user.\n\nThe assertions are handled by another library, for Protractor (end-to-end) / Karma (unit tests) the default is Jasmine.\n\n What are the basic steps to unit test an AngularJS filter?\n\nInject the module that contains the filter.\nProvide any mocks that the filter relies on.\nGet an instance of the filter using $filter('yourFilterName').\nAssert your expectations.\n\ndescribe('Filter: myFltr', function () {\n  var myFltr;\n\n  beforeEach(function () {\n    // Load the filters's module\n    module('myApp');\n\n    // Provide any mocks needed\n    module(function ($provide) {\n      //$provide.value('Name', new MockName());\n    });\n\n    // Inject in angular constructs otherwise,\n    // you would need to inject these into each test\n    inject(function ($filter) {\n      myFltr = $filter('myFltr');\n    });\n  });\n\n  it('should exist', function () {\n    expect(!!myFltr).toBe(true);\n  });\n\n  describe('when evaluating an expression', function () {\n    it('should return the expected output', function () {\n      var text = 'AngularJS';\n      expect(myFltr(text)).toBe('my filter: ' + text);\n    });\n  });\n});\n\n When a scope is terminated, “destroy” events are fired. What are they used for, and why are there two?\n\nThe first one is an AngularJS event, “$destroy” can be used by AngularJS scopes where they are accessible, such as in controllers or link functions.\n\nscope.$on(‘$destroy’, function () {\n  // handle the destroy, i.e. clean up.\n});\n\n// in 1.5.x\n$onDestroy() {...}\n\nThe jqLite / jQuery event is called whenever a node is removed, which may just happen without scope teardown:\n\nelement.on(‘$destroy’, function () {\n  // respectful jQuery plugins already have this handler.\n  // angular.element(document.body).off(‘someCustomEvent’);\n});\n\n How do you reset a $timeout, and disable a $watch()?\n\nAnswer: The key to both is assigning the result of the function to a variable.\n\nTo cleanup the timeout, just .cancel() it:\n\nvar customTimeout = $timeout(function () {\n  // arbitrary code\n}, 55);\n\n$timeout.cancel(customTimeout);\n\nThe same applies to $interval(). To disable a watch, just call it:\n\nvar deregisterWatchFn = $rootScope.$watch(‘someGloballyAvailableProperty’, function (newVal) {\n  if (newVal) {\n    // we invoke that deregistration function, to disable the watch\n    deregisterWatchFn();\n    ...\n  }\n});\n\n Name and describe the phases of a directive definition function execution, or describe how directives are instantiated.\n\nEach directive undergoes something similar to a life cycle as AngularJS compiles and links the DOM. The directive lifecycle begins and ends within the AngularJS bootstrapping process, before the page is rendered. \n\nIn a directive’s life cycle, there are four distinct functions that can execute if they are defined. Each enables the developer to control and customize the directive at different points of the life cycle.\n\nThe compile function allows the directive to manipulate the DOM before it is compiled and linked thereby allowing it to add/remove/change directives, as well as, add/remove/change other DOM elements.\nThe controller function facilitates directive communication. Sibling and child directives can request the controller of their siblings and parents to communicate information.\nThe pre-link function allows for private $scope manipulation before the post-link process begins.\nThe post-link method is the primary workhorse method of the directive.\n\n.directive(\"directiveName\",function () {\n  return {\n    controller: function() {\n      // controller code here...\n    },\n    compile: {\n      // compile code here...\n      return {\n        pre: function() {\n          // pre-link code here...\n        },\n        post: function() {\n          // post-link code here...\n        }\n      };\n    }\n  }\n})\n\nCommonly, not all of the functions are needed. In most circumstances, developers will simply create a controller and link (which refers to post-link) function following the pattern below.\n\n.directive(\"directiveName\",function () {\n  return {\n    controller: function() {\n      // controller code here...\n    },\n\n    link: function() {\n      // post-link code here...\n    }\n  }\n})\n\nMore here.\n\n How does interpolation, e.g. {% raw %}{{ someModel }}{% endraw %}, actually works?\n\nDuring the compilation process the compiler uses the $interpolate service to see if text nodes and element attributes contain interpolation markup with embedded expressions.\n\nIf that is the case, the compiler adds watches on the computed interpolation function, which will update the corresponding text nodes or attribute values as part of the normal digest cycle.\n\n How does the digest phase work?\n\nIn a nutshell, on every digest cycle all scope models are compared against their previous values. That is dirty checking. If change is detected, the watches set on that model are fired. Then another digest cycle executes, and so on until all models are stable.\n\nAs long as core directives are used, we don’t need to worry, but when external code changes models the digest cycle needs to be called manually. Usually to do that, $apply(), $digest(), $timeout(), $evalAsync().\n\n List a few ways to improve performance in an AngularJS app\n\nThe first one can be enabled through the $compileProvider:\n\n.config(function ($compileProvider) {\n  $compileProvider.debugInfoEnabled(false);\n});\n\nCall this method to enable/disable various debug runtime information in the compiler such as adding binding information and a reference to the current scope on to DOM elements. If enabled, the compiler will add the following to DOM elements that have been bound to the scope\n\nng-binding CSS class\n$binding data property containing an array of the binding expressions\n\nUsing one-time binding where possible. Those bindings are set, e.g. in { { ::someModel } } interpolations by prefixing the model with two colons. In such a case, no watch is set and the model is ignored during digest.\n\nMaking $httpProvider use applyAsync:\nmyApp.config(function ($httpProvider) {\n  $httpProvider.useApplyAsync(true);\n});\n\nThat’s it! If the application now receives multiple $http responses at around the same time, this is what happens (a bit simplified though):\n\nThe call’s promise is pushed into a queue\nAn asynchronous $apply is scheduled in case there’s no one scheduled yet, by telling the browser to execute setTimeout()\nOnce timed out, the queue is flushed and the actual $apply is triggered\n\nThe setTimeout() is called with a 0 delay which causes an actual delay of around 10 milliseconds depending on the browser. That means, if our three asynchronous calls return at around the same time (somewhere inside that particular timeout delay), they get resolve with a single $digest cycle instead of three which speeds up our application.\n\n What is $rootScope and how does it relate to $scope?\n\n$rootScope is the parent object of all $scope Angular objects created in a web page.\n\n What is the difference between \"ng-show\"/\"ng-hide\" and \"ng-if\" directives?\n\nng-show/ng-hide will always insert the DOM element, but will display/hide it based on the condition. \n\nng-if will not insert the DOM element until the condition is not fulfilled.\n\nng-if is better when we needed the DOM to be loaded conditionally, as it will help load page bit faster compared to ng-show/ng-hide\n\n Where should we implement the DOM manipulation in AngularJS?\n\nIn the directives. DOM Manipulations should not exist in controllers, services or anywhere else but in directives.\n\nOtherwise it's:\nIt is not reusable\nIt is not testable\nIt include css hard coded selectors dependencies\n\n Is it a good or bad practice to use AngularJS together with jQuery?\n\njQuery takes a traditional imperative approach to manipulating the DOM. In an imperative approach, it is up to the programmer to express the individual steps leading up to the desired outcome. What do I mean by this? So if we want an action to occur when a user types say 150 characters into an input, in jQuery we would say, \"every time the user hits a key, check how many characters are in the input, if it exceeds 150 characters, do the action.\" Every step is addressed along the way.\n\nAngularJS however takes a declarative approach to DOM manipulation. Here instead of worrying about all of the step by step details regarding how to do the desired outcome, AngularJS abstracts that and allows you to just say what you want done, in this case, \"AngularJS, when the state of the input is at 150 characters, do this.\" We are just declaring what we want and AngularJS worries about the rest, taking care of everything for us.\n\nIt might seem like I'm just splitting hairs here, but it's really an important distinction. AngularJS wants you basing your actions around the data models you create. It's how the entire framework works and how your applications will be structured. \n\nTo simply begin writing side scripts in jQuery where you are plucking out elements and setting up side event listeners just goes against the AngularJS approach in my opinion.\n\n If you were to migrate from Angular 1.4 to Angular 1.5, what is the main thing that would need refactoring?\n\nChanging .directive to .component to adapt to the new Angular 1.5 components. More about .component approach\n\n Lifecycle hooks in Angular 1.5\n\n$onInit\n$postLink\n$onChanges\n$onDestroy\n\nMore in awesome post.\n\n How would you specify that a scope variable should have one-time binding only?\n\nBy using ::model.property in front of it. This allows the check if the candidate is aware of the available variable bindings in AngularJS.\n\n What is the difference between one-way binding and two-way binding?\n\nOne way binding implies that the scope variable in the html will be set to the first value its model is bound to (i.e. assigned to).\n\nTwo way binding implies that the scope variable will change it’s value everytime its model is assigned to a different value\n\n What is the role of services in AngularJS and name any services made available by default?\n\nServices are objects that provide separation of concerns to an AngularJS app.\nServices can be created using a factory method or a service method.\nServices are singleton components. All components of the application (into which the service is injected) will work with single instance of the service.\nAllows developing of business logic without depending on the View logic which will work with it.\nA typical service can be injected into another service or into an Controller.\n\nFew of the inbuilt services in AngularJS are:\n– the $http service: The $http service is a core Angular service that facilitates communication with the remote HTTP servers via the browser’s XMLHttpRequest object or via JSONP\n– the $log service: Simple service for logging. Default implementation safely writes the message into the browser’s console\n– the $anchorScroll: it scrolls to the element related to the specified hash or (if omitted) to the current value of $location.hash()\n\n What are Providers and when to use them?\n\nEach web application you build is composed of objects that collaborate to get stuff done. These objects need to be instantiated and wired together for the app to work. In Angular apps most of these objects are instantiated and wired together automatically by the $injector service.\n\nThe $injector creates two types of objects, services and specialized objects.\n\nServices are objects whose API is defined by the developer writing the service.\nSpecialized objects conform to a specific Angular framework API. These objects are one of controllers, directives, filters or animations.\n\nThe injector needs to know how to create these objects. You tell it by registering a \"recipe\" for creating your object with the injector. There are five recipe types.\n\nThe most verbose, but also the most comprehensive one is a Provider recipe. The remaining four recipe types — Value, Factory, Service and Constant — are just syntactic sugar on top of a provider recipe.\n\nThe Provider recipe is the core recipe type and all the other recipe types are just syntactic sugar on top of it. It is the most verbose recipe with the most abilities, but for most services it's overkill.\n\nWhen to use?\n\nYou should use the Provider recipe only when you want to expose an API for application-wide configuration that must be made before the application starts. This is usually interesting only for reusable services whose behavior might need to vary slightly between applications.\n\nThe Provider recipe is syntactically defined as a custom type that implements a $get method. This method is a factory function just like the one we use in the Factory recipe. In fact, if you define a Factory recipe, an empty Provider type with the $get method set to your factory function is automatically created under the hood.\n\nMore in official docs.\n\n Fundamentals\n\nData Structure and algorithm\n\n Binary search\n\nA binary search tree is a great place to store data in an ordered way to allow for an easy search for specific information.\nIt works by comparing the target value to the midpoint of the array; if they are not equal, the lower or upper half of the array is eliminated depending on the result and the search is repeated until the position of the target value is found.\n\nThe basic algorithm, then, can be described as:\n\nIf currentValue equals value, you’re done.\nIf value is less than currentValue, go left. Go to step 1.\nIf value is greater than currentValue, go right. Go to step 1.\n\nBinary search is intuitively recursive; however, it can be done iteratively by keeping track of the bounds of the search with two pointers. Binary search is efficient for sorted arrays that are stored contiguously (close together) in memory, making O(log n) comparisons, where n is the number of elements in the array.\n\nfunction binarySearch(items, value){\n\n    var startIndex  = 0,\n        stopIndex   = items.length - 1,\n        middle      = Math.floor((stopIndex + startIndex)/2);\n\n    while(items[middle] != value && startIndex < stopIndex){\n\n        //adjust search area\n        if (value < items[middle]){\n            stopIndex = middle - 1;\n        } else if (value  items[middle]){\n            startIndex = middle + 1;\n        }\n\n        //recalculate middle\n        middle = Math.floor((stopIndex + startIndex)/2);\n    }\n\n    //make sure it's the right value\n    return (items[middle] != value) ? -1 : middle;\n}\n\n The fastest method to create unique items in array\n\nWith primitive values:\n\nnew Set([1, 2, 2, 1, 5]); // [1, 2, 5]\n\nWith objects: \n\nArray.prototype.unique = function() {\n    var o = {}, i, l = this.length, r = [];\n    for(i=0; i<l;i+=1) o[this[i]] = this[i];\n    for(i in o) r.push(o[i]);\n    return r;\n};\n\nThis is somewhat classified  as “Hash Sorting Algorithm” where every item in the array is a hash value and a hash function inserts item into a bucket, replacing existing values in case of hash collision. As such, this can be applied to any programming language for faster sieving of very large arrays.\n\nThis algorithm has a linear time complexity of O(2n) in worst case scenario. This is way better than what we will observe for the classic method as described below.\n\nThe classic (worst and most popular) method of finding unique items in an array runs two loops in a nested order to compare each element with rest of the elements. Consequently, the time complexity of the classic method to find the unique items in an array is around quadratic O(n²).\n\nvar a = [], l = this.length;\n  for(var i=0; i<l; i++) {\n    for(var j=i+1; j<l; j++)\n          if (this[i] === this[j]) j = ++i;\n    a.push(this[i]);\n  }\n  return a;\n\n The fastest method to find items in array\n\nCreate a classical hash table with complexity of O(n):\n\nvar result = arr.reduce(function(map, obj) {\n  map[obj.id] = obj;\n  return map;\n}, {});\n\nAnd search in the structure is O(1);\n\n Big-O Complexity Chart\n\nAn awesome cheat sheet\n\nSave my day:\n\n10 Interview Questions Every JavaScript Developer Should Know\n",
        "tags": []
    },
    {
        "uri": "/post/Full-screen-scrolling-page-effects-with-fullPage-js",
        "title": "Full-screen scrolling page effects with fullPage.js",
        "content": "\nA simple and easy to use jQuery plugin to create full-screen effects.\n\n!--more--\n\nPlugin is capable of:\n\nScroll within sections using they mouse wheel scroll\nScroll within sections and within sliders using the arrow keys and the pageUp and pageDown keys\nUse multiple callbacks\nUse touch events for mobile and tablet devices\nAdd a menu linked to to the sections\nSupport for CSS3 animations with jQuery fallback\nUse of anchor links (#) for each section and slides\nSupport for scrolling inside each section\nResize the sections size as well as the text when resizing the browser’s window\nAutoadjust itself to fit the current section/slide when resizing the browser’s window\nAdmit some options such as the scrolling easing, the background color of the slides, the scrolling speed, loop options, callbacks and the vertical align of the text within the sections\n\nFor more investigation follow Live Demo or another demo or visit https://github.com/alvarotrigo/fullPage.js#fullpagejs",
        "tags": []
    },
    {
        "uri": "/post/Function-Invocation-Patterns-Scope-of-this-and-Function-Object-Literal-in-JavaScript",
        "title": "Function Invocation Patterns in JavaScript",
        "content": "\nDescribe different approaches to define and call functions\n\n!--more--\n\nFunction object are created with function literals:\n\n// Create function declaration\n// in it that adds two numbers\n\nfunction add(a, b) {\n    return a + b;\n};\n\nFunction literal has four parts.\n\nThe first part is the reserved word function.\nThe optional second part is the function’s name. The function can use its name to call itself recursively. The name can also be used by debuggers and development tools to identify the function. If a function is not given a name it is said to be anonymous.\nThe third part is the set of parameters of the function, wrapped in parentheses. Within the parentheses is a set of zero or more parameter names, separated by commas. These names will be defined as variables in the function. Unlike ordinary variables, instead of being initialized to undefined, they will be initialized to the arguments supplied when the function is invoked.\nThe fourth part is a set of statements wrapped in curly braces. These statements are the body of the function. They are executed when the function is invoked.\n\nIn addition to the declared parameters, every\nfunction receives two additional parameters: this and arguments. The this parameter is very important in object oriented programming, and its value is determined by\nthe invocation pattern.\n\nThere are four patterns of invocation in JavaScript:\n\nmethod invocation pattern\nfunction invocation pattern\nconstructor invocation pattern\napply, binding invocation pattern\n\nThe patterns differ how this will initialize.\n\n Method invocation pattern\n\nWhen a function is stored as a property of an object, we call it a method. When a method is invoked, this is bound to that object. If an invocation expression contains a refinement (that is, a . dot expression or[subscript] expression), it is\ninvoked as a method:\n\nvar myObject = {\n    value: 0,\n    increment: function (inc) {\n        this.value += typeof inc === 'number' ? inc : 1;\n    }\n};\nmyObject.increment( );\nconsole.log(myObject.value); // 1\nmyObject.increment(2);\nconsole.log(myObject.value); // 3\n\nThe binding of this to the object happens at invocation\ntime. This very late binding makes functions that use this highly reusable. Methods\nthat get their object context from this are called public methods.\n\nFunction invocation pattern\n\nWhen a function is invoked with this pattern, this is bound to the global object or undefined`.\nThis was a mistake in the design of the language. Had the language been designed correctly, when the inner function is invoked, this would still be bound to the this variable of the outer function. \n\nfunction outer() {\n    console.log('outer context ' + this);\n    function inner() {\n        console.log('inner context ' + this);\n    }\n    inner();\n}\n\nouter();\n//outer context[object Window]\n//inner context[object Window]\n\nfunction func() { \n  \"use strict\";\n  console.log(this); \n}\n\nfunc();// undefined (expect IE<10)\n\nA consequence of this error is that a method cannot use an inner function to help it do its work because the inner function does not share the method access to the object as its this is bound to the wrong value. Fortunately, there is an easy workaround. If the method defines a variable and assigns it the value of this, the inner function will have access to this through that variable. By convention, the name of that variable is that\n\n Constructor invocation pattern\n\nJavaScript is a prototype inheritance language. That means that objects can inherit properties directly from other objects.\n\nConstructor can be any function, which is called with directive new\n\nfunction Animal(name) {\n  this.name = name;\n  this.canWalk = true;\n  //public method\n  this.sayHi = function() {\n    console.log(this.name + ', says Hi!');\n  }\n}\n\nvar animal = new Animal('bambi');\n\nHow it works:\n\nAutomatically is creating new, empty object\nSpecial keyword this gets a reference to ^- object\nFunction is invoking. Usually, it modifies this, adds methods and properties\nReturn this, if return object, than will be return object rather than this\n\nThe Apply/Call Invocation Pattern\n\nThe apply method lets us choose the value of this. The apply method takes two parameters. The first is the value that should be bound to this. The second is an array of\nparameters.\n\nCall func.apply(context, [a, b ...]) or func.call(context, (a, b ...)) - the same as a normal call func(a, b ...), but with an another context.\n\nvar user = { \n  firstName: \"Bobby\",\n  surname: \"Singler\"\n};\n\nfunction getName(a, b) { \n  console.log( this[a] + ' ' + this[b] );\n}\n\ngetName.apply(user, ['firstName', 'surname'])  // \"Bobby Singler\", this - our context\n\ngetName('firstName', 'surname')  // undefined undefined, this, will be window\n\nInvoke apply/call with null or undefined:\n\nfunction f() {\n  console.log(this);\n}\n\n//if call with null or undefined, this = window \nf.call(null); // window\n\nfunction f() {\n  \"use strict\"\n  console.log(this);\n}\n\n//in strict mode, this = null \nf.call(null); // null\n\nSave My Day:\n\nlearn.javascript.ru\nCrockfords JavaScript: The Good Parts",
        "tags": []
    },
    {
        "uri": "/post/git-pull-versus-git-pull-rebase",
        "title": "git pull VS git pull --rebase",
        "content": "\n!--more--\n\nShort answer\n\ngit pull = git fetch + git merge\n\ngit pull --rebase = git fetch + git rebase\n\nFor more detail info how git pull and git rabase differs continue reading.\n\n  Long answer: \"git merge\" and \"git rebase\"\n\nSuppose originally there were a 3 commits, A, B, C:\n\nThen developer Dan create commit D, and developer Ed created commit E:\n\nObviously, this conflict should be resolve somehow. For this are 2 ways:\n\ngit merge\n\nBoth commits D and E are still here, but git create merge commit M that inherits changes from both D and E. However, this create diamond shape, which many people find confusing.\n\n\tgit rebase\n\nGit create commit R which is identical to merge commit M. But, we get rid of commit E, like it have never existed (shown by dots). Because of this, E should be local to developer Ed and should have never pushed to any repository.\n\nAdvantage of rebase is that it's avoided, and history stays nice straight line - most developers love that!\n\nMake my day:\nDetailed article",
        "tags": []
    },
    {
        "uri": "/post/git-pull-vs-git-fetch",
        "title": "git pull vs git fetch",
        "content": "\nWhat is the differences between \"git pull\" and \"git fetch\"?\n\n!--more--\n\nWhen you use git pull, Git tries to automaticaly do your work with for you. Git will do git merge any new pulled commits into to the branch you are currently working in. git pull is what you should to do to bring a local-branch up-to-date with its remote version, while also updating your other remote-tracking branches.\n\nWhen you use git fetch, Git gather any commits from the target branch that do not exist in your current branch and stores them in your local repository. However, it does not merge them with your current branch.\n\nYou can do git fetch in any time to update your remote-tracking branches under refs/remote/s/heads. This operation never changes any of your own local branches under refs/heads",
        "tags": []
    },
    {
        "uri": "/post/git-vs-github",
        "title": "Git and GitHub, Git versus Subversion",
        "content": "\nHow GitHub is connected to Git and basic difference Git and Svn.\n\n!--more--\n\nGit and GiHub\n\nSo Git and GitHub are parts of one complex system, which complement each other:\n\nGit is the name of VCS (version control system) wrote by Linus Torvalds. There are always series of commits(snapshots). You see a path of this snapshots, in which order they were created. You create branch for new features and use snapshot for revert changes.\nGitHub is website on which you can publish your Git repositories and collaborate with other people.\n\n The difference\n\nGit is not better than Subversion. But is also not worst. It's different:\n\nThe key difference is that Git is a decentralized. With Git you can do practically anything off-line, cause everyone has their own repository. For example: I have a server at home and a Laptop on the road. SVN simply doesn't work well here. With SVN, I can't have local source control if I'm not connected to the repository (Yes, I know about SVK or about ways to copy the repo). With Git, that's the default mode anyway. With command git commit you commit locally, whereas git push origin master - you push the master branch to the remote branch named origin.\nMaking branches and merging between branches is Git way. Everybody who likes your changes can pull them into their project, including the official maintainers. It's trivial to fork a project, modify it, and still keep merging in the bug-fixes from the HEAD branch.\nGit is perfectly suited for Open Source projects: just fork it, commit your changes to your own Fork, and then ask the original project maintainer to pull your changes.\nOn the other hand Git adds complexity. Two modes of creating repositories, checkout vs. clone, commit vs. push... You have to know which commands work locally and which work with \"the server\".\n\nMake my day:\n\nunderstanding-the-basics-of-git-and-github\nDiscussion on StackOverflow",
        "tags": []
    },
    {
        "uri": "/post/Got-15-minutes-and-want-to-learn-Git",
        "title": "Got 15 minutes and want to learn Git?",
        "content": "\n!--more--\n\nInitialize a Git\n\nGit allows groups of people to work on the same documents (often code) at the same time, and without stepping on each other's toes. It's a distributed version control system.\n\nOur terminal prompt below is currently in directory we decided to name \"octobox\". To initialize a Git repository here, type the following command: \n\ngit init\n  \n  Checking the Status\n\nGood job! As Git just told us, our \"octobox\" directory now has an empty repository in /.git/. The repository is a hidden directory where Git operates.\nNext up, let's type the git status command to see what the current state of our project is:\n\ngit status\n\nTip:\nIt's healthy to run git status often. Sometimes things change and you don't notice it.\n\nAdding Changes\n\nGood, it looks like our Git repository is working properly. Notice how Git says octocat.txt is \"untracked\"? That means Git sees that octocat.txt is a new file.\n\nTo tell Git to start tracking changes made to octocat.txt, we first need to add it to the staging area by using git add.\n\ngit add octocat.txt\ngit add *.txt\ngit add --all\ngit add docs/*.txt\ngit add docs/\ngit add .\ndl\n  dtstaged:/dt\n  ddFiles are ready to be committed./dd\n  dtunstaged:/dt\n  ddFiles with changes that have not been prepared to be commited./dd\n  dtuntracked:/dt\n  ddFiles aren't tracked by Git yet. This usually indicates a newly created file./dd\n  dtdeleted:/dt\n  ddFile has been deleted and is waiting to be removed from Git./dd\n/dl\n\n  Checking for Changes\n\nGood job! Git is now tracking our octocat.txt file. Let's run git status again to see where we stand:\n\ngit status\n\nYou can use git reset filename to remove a file or files from the staging area.\n\nCommitting\n\nNotice how Git says changes to be committed? The files listed here are in the Staging Area, and they are not in our repository yet. We could add or remove files from the stage before we store them in the repository.\n\nTo store our staged changes we run the commit command with a message describing what we've changed. Let's do that now by typing:\n\ngit commit -m \"Add new file\"\n\nStaging Area:\nA place where we can group files together before we commit them to Git.\n\nCommit\nA commit is a snapshot of our repository. This way if we ever need to look back at the changes we've made (or if someone else does), we will see a nice timeline of all changes.\n\n  History\n\nSo we've made a few commits. Now let's browse them to see what we changed.\n\nFortunately for us, there's git log. Think of Git's log as a journal that remembers all the changes we've committed so far, in the order we committed them. Try running it now:\n\ngit log\n\nUse git log --summary to see more information for each commit.\n\nRemote Repositories\n\nTo push our local repo to the GitHub server we'll need to add a remote repository.\n\nThis command takes a remote name and a repository URL, which in your case is https://github.com/try-git/try_git.git.\n\ngit remote add origin url\n\nGit doesn't care what you name your remotes, but it's typical to name your main one origin.\n\n  Pushing Remotely\n\nThe push command tells Git where to put our commits when we're ready, and boy we're ready. So let's push our local changes to our origin repo (on GitHub).\n\nThe name of our remote is origin and the default local branch name is master. The -u tells Git to remember the parameters, so that next time we can simply run git push and Git will know what to do. Go ahead and push it!\n\ngit push -u origin master\n\nPulling Remotely\n\nLet's pretend some time has passed. We've invited other people to our github project who have pulled your changes, made their own commits, and pushed them.\n\nWe can check for changes on our GitHub repository and pull down any new changes by running:\n\ngit pull origin master\n\n  Differences\n\nUh oh, looks like there has been some additions and changes to the octocat family. Let's take a look at what is different from our last commit by using the git diff command.\n\nIn this case we want the diff of our most recent commit, which we can refer to using the HEAD pointer.\n\ngit diff HEAD\n\nThe HEAD is a pointer that holds your position within all your different commits. By default HEAD points to your most recent commit.\n\nStaged Differences\n\nAnother great use for diff is looking at changes within files that have already been staged. Remember, staged files are files we have told git that are ready to be committed.\n\nGood, now go ahead and run git diff with the --staged option to see the changes you just staged. You should see that octodog.txt was created.\n\ngit diff --staged\n\nUsing 'git diff' gives you a good overview of changes you have made and lets you add files or directories one at a time and commit them separately.\n\n  Resetting the Stage\n\nSo now that octodog is part of the family, octocat is all depressed. Since we love octocat more than octodog, we'll turn his frown around by removing octodog.txt.\n\nYou can unstage files by using the git reset command. Go ahead and remove octofamily/octodog.txt.\n\ngit reset octofamily/octodog.txt\n\nUndo\n\nFiles can be changed back to how they were at the last commit by using the command: git checkout -- target. Go ahead and get rid of all the changes since the last commit for octocat.txt\n\ngit checkout -- octocat.txt\n\nSo you may be wondering, why do I have to use this '--' thing?  This way if you happen to have a branch named octocat.txt, it will still revert the file, instead of switching to the branch of the same name.\n\n  Branching Out\n\nWhen developers are working on a feature or bug they'll often create a copy (aka. branch) of their code they can make separate commits to. Then when they're done they can merge this branch back into their main master branch.\n\nWe want to remove all these pesky octocats, so let's create a branch called clean_up, where we'll do all the work:\n\ngit branch clean_up\n\nSwitching Branches\n\nGreat! Now if you type git branch you'll see two local branches: a main branch named master and your new branch named clean_up.\n\nYou can switch branches using the git checkout branch command. Try it now to switch to the clean_up branch:\n\ngit checkout clean_up\n\nBranches are what naturally happens when you want to work on multiple features at the same time. You wouldn't want to end up with a master branch which has Feature A half done and Feature B half done.\n\n  Removing All The Things\n\nOk, so you're in the clean_up branch. You can finally remove all those pesky octocats by using the git rm command which will not only remove the actual files from disk, but will also stage the removal of the files for us:\n\ngit rm '*.txt'\n\nThis will recursively remove all folders and files from the given directory:\n\nCommiting Branch Changes\n\nNow that you've removed all the cats you'll need to commit your changes.\n\nFeel free to run git status to check the changes you're about to commit.\n\ngit commit -m 'Remove all cats'\n\n  Switching Back to master\n\nGreat, you're almost finished with the cat... er the bug fix, you just need to switch back to the master branch so you can copy (or merge) your changes from the clean_up branch back into the master branch.\n\nGo ahead and checkout the master branch:\n\ngit checkout master\n\nPreparing to Merge\n\nAlrighty, the moment has come when you have to merge your changes from the clean_up branch into the master branch. Take a deep breath, it's not that scary.\n\nWe're already on the master branch, so we just need to tell Git to merge the clean_up branch into it:\n\ngit merge clean_up\n\nMerge Conflicts can occur when changes are made to a file at the same time. A lot of people get really scared when a conflict happens, but fear not! They aren't that scary, you just need to decide which code to keep how conflicts are presented.\n\n  Keeping Things Clean\n\nCongratulations! You just accomplished your first successful bugfix and merge. All that's left to do is clean up after yourself. Since you're done with the clean_up branch you don't need it anymore.\n\nYou can use git branch -d branch name to delete a branch. Go ahead and delete the clean_up branch now:\n\ngit branch -d clean_up\n\nWhat if you have been working on a feature branch and you decide you really don't want this feature anymore? You might decide to delete the branch since you're scrapping the idea. You'll notice that git branch -d bad_feature doesn't work. This is because -d won't let you delete something that hasn't been merged.\nYou can either add the --force (-f)\n\nThe Final Push\n\nHere we are, at the last step. I'm proud that you've made it this far, and it's been great learning Git with you. All that's left for you to do now is to push everything you've been working on to your remote repository, and you're done!\n\nSave My Day:\nTry Git",
        "tags": []
    },
    {
        "uri": "/post/Gulp-screencast-overview",
        "title": "Gulp screencast overview",
        "content": "\nDepth table of contents of one of the most popular screencast about utility for managing tasks.\n\n!--more--\n\nWhat is Gulp? Compare with Webpack.\n\nWhat is Gulp?\n\nGulp as a \"streaming build system\", and moreover, it's a utility for declaring tasks 0:10\nExample gruntfile.js0:53\nComparing with Grunt. 2:50\n  gruntfile.js vs gruntfile.js\n  More compact config\n  Virtual File System - Vinyl FS. No temp folders\n  Power of streams, streams parallelism\nComparing with Webpack 10:10\n  Deps: CommonJS, AMD, ES2015\n  Dynamic loading\n  CommonsChungPlugin\n  APIs\nWebpack + Gulp = 💕 16:45\n  Tasks: Gulp\n  JS Build: Webpack \n\n Install and task running\n\nInstalling strategies: local vs global 0:22\nInstalling v4 npm i -D gulpjs/gulp.git#4.0\nFirst task 3:49\n  Callback for finish async operation \n  Task name as function name\n  Separate tasks with namespace deploy:production\n  Strategies for finish async operations\n  gulp.series and gulp.parallel\n\nHave to install v4 before it's officially released\nCode examples\n\nStreams Vinyl-FS\n\nExample streams with coping files 0:45\ngulp.src and gulp.dest output as readable/writable streams of instance Vinyl-FS 1:05\nLog working files .on('data', (file) = file) 1:48\nFile getter properties 3:10\nControl gulp.dest output 4:45\nModule minimatch and popular pattens 6:48\nPerformance issue with globs 9:13\nSummary 11:50\n\nCode examples\n\n Basic build for styles\n\nApp structure 0:25\nDeclaring task for stylus 1:13\nChange destination directory 5.40\nConcat files 7:10\nLog info with gulp-debug 7:50\nCreate main.styl 10:31\nAdd source maps 11:30\nGenerate source maps only in dev mode 15:05\nUsing gulp-if 17:05\n10. Create clean task with del 19:05\n11. Create copy task with gulp.parallel 20:24\n12. Result in browser with node-static 21:55\n12. Summary 23:18\n\nCode examples\n\nIncremental build, watch\n\nCreate gulp.watch for styles 0:30\nWhat does \"incremental build\" actually mean? Caching 1:55\nCreate gulp.watch for assets with caching with { since: gulp.lastRun('taskName') } 3:55\nModule chokidar and deleting files with watch 6:49\nDecoupling watch-es into separate task 8:32\nSummary 9:32\n\nCode examples\n\n Incremental and performance\n\nFilter new files for first task run with gulp-newer 0:36\nProblem with gulp-remember on example with gulp-autoprefixer 3:57\nProblem with returning deleted files from IDE, using gulp-cached as alternative of since 10:10\nSummary 15:20\n\nCode examples 1\nCode examples 2\n\nBrowser auto-reloading, browser-sync\n\nWe don't want to every time hit F5! Flow overview 0:14\nCreate sync task with browser-sync 1:34\n\nCode examples\n\n Error handling\n\nMake an error 0:20\nWas error couched? 1:25\nNotification for an error with gulp-notify 2:51\nCatch all errors on task with gulp-plumber 6:30\nSolution with multipipe 9:50\n\nCode examples 1\nCode examples 2\n\nCreating plugins with \"through2\"\n\nWhat we need to start 0:29\nA real example 3:41\n\nCode examples 1\nCode examples 2\n\n More complex stream with \"eslint\", \"gulp-if\", \"stream-combiner2\"\n\nExample with pre-commit 1:55\nOptimize repeatable checks 4:08\nPerformance summary 14:50\n\nCode examples\n\nHow we know Node.JS streams?\n\nA small test 0:20\nWhy it isn't work? 1:05\nFix the \"pause\" problem 4:00\n \nCode examples\n\n Structure of \"gulpfile.js\"\n\nWe have problems, don't we? 0:20\nA solution is task decomposition 1:50\nAdding gulp-load-plugins 5:05\nResult after refactoring 6:50\n \nCode examples\n\nA real example: styles, assets, sprites, production\n\nGoal and app structure 0:15\nImproving build of styles and assets 1:55\nA typical problem with preprocessors with src and fixing with resolver 4:03\nWorking with sprites using gulp-svg-sprites 6:20\nAdd production mode: minify with gulp-cssnano, resource hash with gulp-rev and gulp-rev-replace  15:13\nDo we need to use long-term hashing for images?  22:17\nSummary 25:35\n \nCode examples\n\n Integration with Webpack\n\nSummary 27:16\n \nCode examples 1\nCode examples 2\n",
        "tags": []
    },
    {
        "uri": "/post/How-to-copy-object-in-Javascript",
        "title": "How to copy object in Javascript",
        "content": "\nThere are many ways to copy object in Javascript but most of the time such operation doesn't do what we expected.\n\nAre all properties copied by reference? \nAre sub-properties merged or replaced? \nAre accessor, like getter and setters, preserved? \nAnd what about Sumbols and other non-enumerable properties?\n\n!--more--\n\nShallow VS Deep copy\n\nWhen we copied reference nor a value, we are doing shallow copy.\n \nWhenever we do an operation like a.prop = b.prop we are performing a shallow copy, meaning that modifying the object property a.prop it will reflect changes in b.prop too.\n \nconst a = { \n    obj: {\n        test: 'Foo'\n    }\n};\n\nconst b = {};\nb.obj = a.obj;\n\n//if we modify it\nb.obj.test = 'Bar';\n\n//it will be reflected in a \na.obj.test;\n\nIn order to perform deep copy of a.prop:\n\nconst a = { \n    obj: {\n        test: 'Foo'\n    }\n};\n\nconst b = {};\nb.obj = {};\n\n//not reflected in a\nb.obj.test = 'Bar';\na.obj.test;\n\n Object.assign(target, [, sourceN])\n\nObject.assign performs a shallow copy it merges enumerable properties with priority right to left:\n\nconst a = {\n    obj: {\n        foo: true\n    },\n    bar: 2\n};\nconst b = {\n    obj: {\n        foz: true\n    },\n    baz: 3\n};\n//shallow merge\nconst c = Object.assign({}, a, b);\n\n//which 'obj' property was copied?\n//the priority is right to left\nc.obj === b.obj; //true\nc.obj === a.obj; //false\n\nc.bar; // 2\nc.baz; // 3\n\n//change will reflect by reference\nc.obj.foz = false;\nb.obj.foz; // false\n\nObject.assign side effects\n\nThere are at least two main subtle problems most developers are not aware of:\n\nall accessors, those properties with getter or setter, will be copied as a simple data, invoking the getter \nduring the copy\nall Symbol keys will be copied too, making Symbol less private or protected than we thing\n\nconst uid = Symbol('uid');\nconst special = {\n    get next() {\n        return ++this.counter;\n    },\n    counter: 0\n};\nspecial[uid] = Math.random;\n\n//what could be possible wrong here?!\nconst notSpecial = Object.assign({}, special);\n\n// if 'next' is declared (and copied) before 'counter'\nnotSpecial.counter; // 1\nnotSpecial.next; // 1 in any case\n\nnotSpecial[uid] === special[uid]; // same as special[uid]\n\n \"If you want a advice -  use Object.assign for simple shallow copy or merge with data that you are sure \ndoesn't contain accessors.\"\n\n Use one of the simple npm package or lodash/underscore/rambda\n\nclone is one a popular package for deep copying:\n\nconst clone = require('clone');\n \nlet a, b;\n \na = { foo: { bar: 'baz' } };  // initial value of a \n \nb = clone(a);                 // clone a - b \na.foo.bar = 'foo';            // changes not modify 'b'\n\nAchieve the same result with _.deepCopy:\n\nconst objects = [{ 'a': 1 }, { 'b': 2 }];\n\nconst deep = _.cloneDeep(objects);\nconsole.log(deep[0] === objects[0]);\n// → false\n\nJSON.parse(JSON.stringify(object))\n\nIf you don't have function within your object, a very simple:\n\nconst cloneOfA = JSON.parse(JSON.stringify(a));\n\nThis works with for all kinds of objects contain: object, array, string, boolean, numbers;\n\nSave my day:\n\nwww.webreflection.co.uk\nstackoverflow.com",
        "tags": []
    },
    {
        "uri": "/post/Huston-do-we-have-a-problem-with-promises",
        "title": "Huston, do we have a problem with promises?",
        "content": "\nMany of us are using promises without really understanding them.\n\n!--more--\n\nWherefore promises?\n\nIf you read the literature on promises, you'll often find references to the pyramid of doom, with some horrible callback-y code that steadily stretches toward the right side of the screen.\n\nThe whole point of promises is to give us back the language fundamentals we lost when we went async: return, throw, and the stack. But you have to know how to use promises correctly in order to take advantage of them.\n\n Rookie mistakes\n\nI'm only going to talk about the official spec, as exposed in modern browsers as window.Promise. Not all browsers have window.Promise though, so for a good polyfill, check out the cheekily-named Lie, which is about the smallest spec-compliant library out there.\n\nRookie mistake 1: the promises pyramid of doom\n\nThe most common bad practice is this one:\n\nremotedb.allDocs({\n  include_docs: true,\n  attachments: true\n}).then(function (result) {\n  var docs = result.rows;\n  docs.forEach(function(element) {\n    localdb.put(element.doc).then(function(response) {\n      alert(\"Pulled doc with id \" + element.doc._id + \" and added to local db.\");\n    }).catch(function (err) {\n      if (err.status == 409) {\n        localdb.get(element.doc._id).then(function (resp) {\n          localdb.remove(resp.id, resp.rev).then(function (resp) {\n// et cetera...\n\nYes, it turns out you can use promises as if they were callbacks, and yes, it's a lot like using a power sander to file your nails, but you can do it.\n\nA better style is this one:\n\nremotedb.allDocs(...).then(function (resultOfAllDocs) {\n  return localdb.put(...);\n}).then(function (resultOfPut) {\n  return localdb.get(...);\n}).then(function (resultOfGet) {\n  return localdb.put(...);\n}).catch(function (err) {\n  console.log(err);\n});\n\nThis is called composing promises, and it's one of the great superpowers of promises. Each function will only be called when the previous promise has resolved, and it'll wbe called with that promise's output. More on that later.\n\nRookie mistake 2: WTF, how do I use forEach() with promises?\n\nThis is where most people's understanding of promises starts to break down. As soon as they reach for their familiar forEach() loop (or for loop, or while loop), they have no idea how to make it work with promises. So they write something like this:\n\n// I want to remove() all docs\ndb.allDocs({include_docs: true}).then(function (result) {\n  result.rows.forEach(function (row) {\n    db.remove(row.doc);  \n  });\n}).then(function () {\n  // I naively believe all docs have been removed() now!\n});\n\nWhat's the problem with this code? The problem is that the first function is actually returning undefined, meaning that the second function isn't waiting for db.remove() to be called on all the documents. In fact, it isn't waiting on anything, and can execute when any number of docs have been removed!\n\nThe TLDR of all this is that forEach()/for/while are not the constructs you're looking for. You want Promise.all():\n\ndb.allDocs({include_docs: true}).then(function (result) {\n  return Promise.all(result.rows.map(function (row) {\n    return db.remove(row.doc);\n  }));\n}).then(function (arrayOfResults) {\n  // All docs have really been removed() now!\n});\n\nWhat's going on here? Basically Promise.all() takes an array of promises as input, and then it gives you another promise that only resolves when every one of those other promises has resolved. It is the asynchronous equivalent of a for-loop.\n\nRookie mistake 3: forgetting to add .catch()\n\nMany developers forget to add a .catch() anywhere in their code. Unfortunately this means that any thrown errors will be swallowed, and you won't even see them in your console. This can be a real pain to debug.\n\nsomePromise().then(function () {\n  return anotherPromise();\n}).then(function () {\n  return yetAnotherPromise();\n}).catch(console.log.bind(console)); // <-- this is badass\n\nRookie mistake 4: using \"deferred\"\n\nIf you are writing that word in your code you are doing something wrong. Here's how to avoid it.\n\nFirst off, most promise libraries give you a way to import promises from third-party libraries. For instance, Angular's $q module allows you to wrap non-$q promises using $q.when(). So Angular users can wrap PouchDB promises this way:\n\n$q.when(db.put(doc)).then(/* ... */); // <-- this is all the code you need\n\nAnother strategy is to use the revealing constructor pattern, which is useful for wrapping non-promise APIs. For instance, to wrap a callback-based API like Node's fs.readFile(), you can simply do:\n\nnew Promise(function (resolve, reject) {\n  fs.readFile('myfile.txt', function (err, file) {\n    if (err) {\n      return reject(err);\n    }\n    resolve(file);\n  });\n}).then(/* ... */)\n\nRookie mistake 5: using side effects instead of returning\n\nWhat's wrong with this code?\n\nsomePromise().then(function () {\n  someOtherPromise();\n}).then(function () {\n  // Gee, I hope someOtherPromise() has resolved!\n  // Spoiler alert: it hasn't.\n});\n\nSeriously, this is the one weird trick that, once you understand it, will prevent all of the errors I've been talking about. \n\nAs I said before, the magic of promises is that they give us back our precious return and throw. But what does this actually look like in practice?\n\nWhat can we do here? There are three things:\n\n1.return another promise\n2.return a synchronous value (or undefined)\n3.throw a synchronous error\n\nReturn another promise\n\nThis is a common pattern you see in the promise literature, as in the composing promises example above:\n\ngetUserByName('nolan').then(function (user) {\n  return getUserAccountById(user.id);\n}).then(function (userAccount) {\n  // I got a user account!\n});\n\nNotice that I'm returning the second promise – that return is crucial. If I didn't say return, then the getUserAccountById() would actually be a side effect, and the next function would receive undefined instead of the userAccount.\n\n Return a synchronous value (or undefined)\n\nReturning undefined is often a mistake, but returning a synchronous value is actually an awesome way to convert synchronous code into promisey code. For instance, let's say we have an in-memory cache of users. We can do:\n\ngetUserByName('nolan').then(function (user) {\n  if (inMemoryCache[user.id]) {\n    return inMemoryCache[user.id];    // returning a synchronous value!\n  }\n  return getUserAccountById(user.id); // returning a promise!\n}).then(function (userAccount) {\n  // I got a user account!\n});\n\nFor this reason, I make it a personal habit to always return or throw from inside a then() function. I'd recommend you do the same.\n\nThrow a synchronous error\n\nLet's say we want to throw a synchronous error in case the user is logged out. It's quite easy:\n\ngetUserByName('nolan').then(function (user) {\n  if (user.isLoggedOut()) {\n    throw new Error('user logged out!'); // throwing a synchronous error!\n  }\n  if (inMemoryCache[user.id]) {\n    return inMemoryCache[user.id];       // returning a synchronous value!\n  }\n  return getUserAccountById(user.id);    // returning a promise!\n}).then(function (userAccount) {\n  // I got a user account!\n}).catch(function (err) {\n  // Boo, I got an error!\n});\n\n Advanced mistake #1: don't know about Promise.resolve\n\nAs I showed above, promises are very useful for wrapping synchronous code as asynchronous code. However, if you find yourself typing this a lot:\n\nnew Promise(function (resolve, reject) {\n  resolve(someSynchronousValue);\n}).then(/* ... */);\n\nYou can express this more succinctly using Promise.resolve():\n\nPromise.resolve(someSynchronousValue).then(/* ... */);\n\n//more verbose exapmle\nfunction somePromiseAPI() {\n  return Promise.resolve().then(function () {\n    return 'foo';\n  }).then(/* ... */);\n}\n\nAdvanced mistake 2: catch() isn't exactly like then(null, cb)\n\nIf you're wondering why they're not equivalent, consider what happens if the first function throws an error:\n\nsomePromise().then(function () {\n  throw new Error('oh noes');\n}).catch(function (err) {\n  // I caught your error! :)\n});\n\nsomePromise().then(function () {\n  throw new Error('oh noes');\n}, function (err) {\n  // I didn't catch your error! :(\n});\n\nAs it turns out, when you use the then(resolveHandler, rejectHandler) format, the rejectHandler won't actually catch an error if it's thrown by the resolveHandler itself.\n\nAdvanced mistake 3: use promise in parallel or promises vs promise factories\n\nThat is, you want something like Promise.all(), but which doesn't execute the promises in parallel.\n\nYou might naïvely write something like this:\n\nfunction executeSequentially(promises) {\n  var result = Promise.resolve();\n  promises.forEach(function (promise) {\n    result = result.then(promise);\n  });\n  return result;\n}\n\nThe promises you pass in to executeSequentially() will still execute in parallel.\n\nThe reason this happens is that you don't want to operate over an array of promises at all. Per the promise spec, as soon as a promise is created, it begins executing. So what you really want is an array of promise factories.\n\nA promise factory is very simple, though – it's just a function that returns a promise:\n\nfunction myPromiseFactory() {\n  return somethingThatCreatesAPromise();\n}\nfunction executeSequentially(promiseFactories) {\n  var result = Promise.resolve();\n  promiseFactories.forEach(function (promiseFactory) {\n    result = result.then(promiseFactory);\n  });\n  return result;\n}\n\nWhy does this work? It works because a promise factory doesn't create the promise until it's asked to. It works the same way as a then function – in fact, it's the same thing!\n\nAnother task, create code which will download recurses from array URLs in sequence:\n\nlet urls = [\n  'user.json',\n  'guest.json'\n];\n\n// begin of the chain\nlet chain = Promise.resolve();\n\nlet results = [];\n\n// in loop add tasks in chain\nurls.forEach(function(url) {\n  // task are added in sequence\n  chain = chain\n    .then(() = httpGet(url))\n    .then((result) = {\n      results.push(result);\n    });\n});\n\n// result of promises\nchain.then(console.log.bind(console));\n\nThe same approach with parallel:\n\nPromise.all( urls.map(httpGet) )\n  .then(console.log.bind(console));\n\nAdvanced mistake 4: okay, what if I want the result of two promises?\n\nOften times, one promise will depend on another, but we'll want the output of both promises. For instance:\n\ngetUserByName('nolan').then(function (user) {\n  return getUserAccountById(user.id);\n}).then(function (userAccount) {\n  // dangit, I need the \"user\" object too!\n});\n\nWanting to be good JavaScript developers and avoid the pyramid of doom, we might just store the user object in a higher-scoped variable:\n\nvar user;\ngetUserByName('nolan').then(function (result) {\n  user = result;\n  return getUserAccountById(user.id);\n}).then(function (userAccount) {\n  // okay, I have both the \"user\" and the \"userAccount\"\n});\n\nMy recommended strategy: just let go of your preconceptions and embrace the pyramid:\n\ngetUserByName('nolan').then(function (user) {\n  return getUserAccountById(user.id).then(function (userAccount) {\n    // okay, I have both the \"user\" and the \"userAccount\"\n  });\n});\n\nIf the indentation ever becomes an issue, then you can do what JavaScript developers have been doing since time immemorial, and extract the function into a named function:\n\nfunction onGetUserAndUserAccount(user, userAccount) {\n  return doSomething(user, userAccount);\n}\n\nfunction onGetUser(user) {\n  return getUserAccountById(user.id).then(function (userAccount) {\n    return onGetUserAndUserAccount(user, userAccount);\n  });\n}\n\ngetUserByName('nolan')\n  .then(onGetUser)\n  .then(function () {\n  // at this point, doSomething() is done, and we are back to indentation 0\n});\n\nAs your promise code starts to get more complex, you may find yourself extracting more and more functions into named functions. I find this leads to very aesthetically-pleasing code, which might look like this:\n\nputYourRightFootIn()\n  .then(putYourRightFootOut)\n  .then(putYourRightFootIn)  \n  .then(shakeItAllAbout);\n\nSave my day:\n\tWe have a problem with promises",
        "tags": []
    },
    {
        "uri": "/post/improve-web-performance-using-google-pageSpeed",
        "title": "Improve web performance using Google PageSpeed",
        "content": "\nThis course covers how to analyze your web pages to make sure they are following known performance best practices.\n\n!--more--\n\nDescription\n\nDevelopers today have access to multiple tools that can quickly analyze a web page for performance best practices and give specific suggestions on what items should be addressed. This course first covers the different analysis tools that are available. It then uses one of these tools, the Performance Scorecard Chrome extension to analyze a sample website. Then, the course walks through each of the important recommendations given by the extension and shows how to fix them. By the end of this course, you will have a firm grasp of the most important web performance issues and how to address them.\n\n Link\n\ncourse on pluralsight",
        "tags": []
    },
    {
        "uri": "/post/JavaScript-Promises",
        "title": "JavaScript Promises",
        "content": "\n!--more--\n\nPromises arrive in JavaScript!\n\nHere's how you create a promise:\n\nvar promise = new Promise(function(resolve, reject) {\n  // do a thing, possibly async, then…\n\n  if (/* everything turned out fine */) {\n    resolve(\"Stuff worked!\");\n  }\n  else {\n    reject(Error(\"It broke\"));\n  }\n});\n\nThe promise constructor takes one argument, a callback with two parameters, resolve and reject. Do something within the callback, perhaps async, then call resolve if everything worked, otherwise call reject.\n\nHere's how you use that promise:\n\npromise.then(function(res) {\n\tconsole.log(res) //Stuff worked!\n}, function(err) {\n\tconsole.log(err) //Error!\n});\n\nthen takes two arguments, a callback for a success case, and another for the failure case. Both are optional, so you can add a callback for the success or failure case only.\n\n  Promisifying XMLHttpRequest\n\nOld APIs will be updated to use promises, if it's possible in a backwards compatible way. XMLHttpRequest is a prime candidate, but in the mean time let's write a simple function to make a GET request:\n\nfunction get(url) {\n  // Return a new promise.\n  return new Promise(function(resolve, reject) {\n    // Do the usual XHR stuff\n    var req = new XMLHttpRequest();\n    req.open('GET', url);\n\n    req.onload = function() {\n      // This is called even on 404 etc\n      // so check the status\n      if (req.status == 200) {\n        // Resolve the promise with the response text\n        resolve(req.response);\n      }\n      else {\n        // Otherwise reject with the status text\n        // which will hopefully be a meaningful error\n        reject(Error(req.statusText));\n      }\n    };\n\n    // Handle network errors\n    req.onerror = function() {\n      reject(Error(\"Network Error\"));\n    };\n\n    // Make the request\n    req.send();\n  });\n}\n\nNow let's use it:\n\nget('story.json').then(function(response) {\n  console.log(\"Success!\", response);\n}, function(error) {\n  console.error(\"Failed!\", error);\n});\n\nChaining\n\nthen isn't the end of the story, you can chain then\"s together to transform values or run additional async actions one after another:\n\nvar promise = new Promise(function(resolve, reject) {\n  resolve(1);\n}\n\npromise.then(function(val) {\n  console.log(val); // 1\n  return val + 2;\n}).then(function(val) {\n  console.log(val); // 3\n});\n\nAs a practical example, let's go back to:\n\nget('story.json').then(function(response) {\n  return JSON.parse(response);\n}).then(function(response) {\n  console.log(\"Yey JSON!\", response);\n});\n\ngetJSON still returns a promise, one that fetches a url then parses the response as JSON.\n\nfunction getJSON(url) {\n  return get(url).then(JSON.parse);\n}\n\n  Error handling\n\nAs we saw earlier, then takes two arguments, one for success, one for failure (or fulfill and reject, in promises-speak):\n\nget('story.json').then(function(response) {\n  console.log(\"Success!\", response);\n}, function(error) {\n  console.log(\"Failed!\", error);\n});\n\nYou can also use catch:\n\nget('story.json').then(function(response) {\n  console.log(\"Success!\", response);\n}).catch(function(error) {\n  console.log(\"Failed!\", error);\n});\n\nWith our story and chapters, we can use catch to display an error to the user:\n\ngetJSON('story.json').then(function(story) {\n  return getJSON(story.chapterUrls[0]);\n}).then(function(chapter1) {\n  addHtmlToPage(chapter1.html);\n}).catch(function() {\n  addTextToPage(\"Failed to show chapter\");\n}).then(function() {\n  document.querySelector('.spinner').style.display = 'none';\n});\n\nCreating a sequence\n\nBut how can we loop through the story.chapter urls and fetch them in order?\n\ngetJSON('story.json').then(function(story) {\n  addHtmlToPage(story.heading);\n  // TODO: for each url in story.chapterUrls, fetch & display\n}).then(function() {\n  // And we're all done!\n  addTextToPage(\"All done\");\n}).catch(function(err) {\n  // Catch any error that happened along the way\n  addTextToPage(\"Argh, broken: \" + err.message);\n}).then(function() {\n  // Always hide the spinner\n  document.querySelector('.spinner').style.display = 'none';\n});\n\nThis doesn't work:\n\nstory.chapterUrls.forEach(function(chapterUrl) {\n  // Fetch chapter\n  getJSON(chapterUrl).then(function(chapter) {\n    // and add it to the page\n    addHtmlToPage(chapter.html);\n  });\n});\n\nWe want to turn our chapterUrls array into a sequence of promises. We can do that using then:\n\n// Start off with a promise that always resolves\nvar sequence = Promise.resolve();\n\n// Loop through our chapter urls\nstory.chapterUrls.forEach(function(chapterUrl) {\n  // Add these actions to the end of the sequence\n  sequence = sequence.then(function() {\n    return getJSON(chapterUrl);\n  }).then(function(chapter) {\n    addHtmlToPage(chapter.html);\n  });\n});\n\nWe can tidy up the above code using array.reduce:\n\n// Loop through our chapter urls\nstory.chapterUrls.reduce(function(sequence, chapterUrl) {\n  // Add these actions to the end of the sequence\n  return sequence.then(function() {\n    return getJSON(chapterUrl);\n  }).then(function(chapter) {\n    addHtmlToPage(chapter.html);\n  });\n}, Promise.resolve());\n\nLet's put it all together…\n\ngetJSON('story.json').then(function(story) {\n  addHtmlToPage(story.heading);\n\n  return story.chapterUrls.reduce(function(sequence, chapterUrl) {\n    // Once the last chapter's promise is done…\n    return sequence.then(function() {\n      // …fetch the next chapter\n      return getJSON(chapterUrl);\n    }).then(function(chapter) {\n      // and add it to the page\n      addHtmlToPage(chapter.html);\n    });\n  }, Promise.resolve());\n}).then(function() {\n  // And we're all done!\n  addTextToPage(\"All done\");\n}).catch(function(err) {\n  // Catch any error that happened along the way\n  addTextToPage(\"Argh, broken: \" + err.message);\n}).then(function() {\n  // Always hide the spinner\n  document.querySelector('.spinner').style.display = 'none';\n});\n\nBut we can do better. At the moment our page is downloading like this:\n\nBrowsers aren't pretty good at downloading multiple things at once, so we're losing performance by downloading chapters one after the other. What we want to do is download them all at the same time, then process them when they've all arrived. Thankfully there's an API for this:\n\nPromise.all(arrayOfPromises).then(function(arrayOfResults) {\n  //...\n});\n\nPromise.all takes an array of promises and creates a promise that fulfills when all of them successfully complete. You get an array of results (whatever the promises fulfilled to) in the same order as the promises you passed in.\n\ngetJSON('story.json').then(function(story) {\n  addHtmlToPage(story.heading);\n\n  // Take an array of promises and wait on them all\n  return Promise.all(\n    // Map our array of chapter urls to\n    // an array of chapter json promises\n    story.chapterUrls.map(getJSON)\n  );\n}).then(function(chapters) {\n  // Now we have the chapters jsons in order! Loop through…\n  chapters.forEach(function(chapter) {\n    // …and add to the page\n    addHtmlToPage(chapter.html);\n  });\n  addTextToPage(\"All done\");\n}).catch(function(err) {\n  // catch any error that happened so far\n  addTextToPage(\"Argh, broken: \" + err.message);\n}).then(function() {\n  document.querySelector('.spinner').style.display = 'none';\n});\n\nDepending on connection, this can be seconds faster than loading one-by-one:\n\n",
        "tags": []
    },
    {
        "uri": "/post/Js-30",
        "title": "JS 30",
        "content": "\nTo fresh memory with 30 day vanilla js coding challenge. Build 30 things in 30 days with 30 tutorials. No Frameworks, No Compilers, No Libraries, No Boilerplate!\n\n!--more--\n\nDescription\n\nHow do you get better?\n\nBuild things. Lots of things. Build 1,000 things. Keep it up and don't stop. Seriously.\n\nThis has always been my advice. Just put in the work and you will get better.\n\nBut Wes, what should I build? I have no ideas! Please don't make me do another todo app.\n\nIdeas, Eh? I've got lots! This is JavaScript30 — let's build 30 things together.\n\n Done challenges\n\n01 - Drum kit\n02 - CSS + JS clock, SVG + JS\n03 - CSS variables\n04 - Array Cardio Day 1\n05 - Flex panel gallery\n06 - AJAX Type Ahead\n07 - Array Cardio Day 2\n08 - Fun with HTML5 Canvas\n09 - Dev Tools Domination\n10 - Hold Shift and Check Checkboxes, With Ctrl example\n11 - Custom Video Player\n12 - Key Sequence Detection\n\nGithub original source",
        "tags": []
    },
    {
        "uri": "/post/JSONP",
        "title": "JSONP",
        "content": "\nJSONP is really simple trick to overcome XMLHttpRequest same origin domain policy - you can't send AJAX (XMLHttpRequest) request (not a simple) to different domain.\n\n!--more--\n\nSo instead of using XMLHttpRequest we have to use script HTML tag to get data from another domain. And yes, it's sound weird. Example:\n\n(function() {\n\tvar script = document.createElement('script');\n\tscript.type = 'text/javascript'\n\tscript.src = 'http://www.someWebApiServer.com/some-data?callback=my_callback';\n\tdocument.getElementsByTagName('head')[0].appendChild(elem)\n})()\n\nNotice the my_callback function over here? So when when server receives request and finds callback parameter - instead of returning plain JSON object :\n\n{foo: bar}\n\nIt will return callback: \n\nmy_callback({foo: bar}) // 'Response from another domain: with {foo: bar}\n\n//it's already implemented\nfunction my_callback(resp) {\n\tconsole.log('Response from another domain: ' + resp);\n}\n\nThe profit is that we get automatic callback my_callback that will be triggered once we get the data.\n\nSo JSONP is callback and script tags.\n\nBasic JavaScript example (simple Twitter feed using JSONP):\n\ndiv id = 'twitterFeed'/div\nscript\nfunction myCallback(dataWeGotViaJsonp){\n    var text = '';\n    var len = dataWeGotViaJsonp.length;\n    for(var i=0;i<len;i++){\n        twitterEntry = dataWeGotViaJsonp[i];\n        text += ' + twitterEntry['text']';\n    }\n    document.getElementById('twitterFeed').innerHTML = text;\n}\n`",
        "tags": []
    },
    {
        "uri": "/post/Kangax-ES6-quiz-expained",
        "title": "Kangax ES2015 quiz, expained",
        "content": "\n@kangax've created a quiz, it's very interesting, the solution explains a tricky moment of spec.\n\n!--more--\n\nQuestion 1\n\n(function(x, f = () = x) {\n  var x;\n  var y = x;\n  x = 2;\n  return [x, y, f()];\n})(1);\n\n[2, 1, 1]\n[2, undefined, 1]\n[2, 1, 2]\n[2, undefined, 2]\n\nAs we know, parameters create extra scope in case of using default values.\n\nLocal variable x shadows the parameter with the same name, var x\nIt's hoisted and assigned to default value, to undefined?\nUsually yes, but not in this case.\nIf there is a parameter with the same name, then the local binding is initialize not to undefined but with value of that parameter, that is 1\nThe variable y gets the the value 1 as well, because var y = x;\nx is assigned to 2, x = 2;\nNow it's tricky f(). It is created in the scope of parameters, so x refers to the parameter x, which is 1.\nFinal values are [2, 1, 1]\n\n Question 2\n\n(function() {\n  return [\n    ( () = this.x ).bind({ x: 'inner' }),\n    ( () = this.x )()\n  ];\n})().call({ x: 'outer' });\n\n['inner', 'outer']\n['outer', 'outer']\n[undefined, undefined]\nError\n\nArrow function have lexical this value. This means that, it inherits this value from the context they are defined.\nAnd later it stays unchangeable, even if explicitly bound or called with different context.\n\nIn this case both arrow function are created within the context of {x: 'outer'}, and bind({x: 'inner'}) applied on the first arrow function doesn't make a difference.\n\nQuestion 3\n\nlet x, { x: y = 1} = { x }; y;\n\nundefined\n*1*\n{ x: 1}\nError\n\nlet x defines x  with value undefined\nDestructive assignment { x: y = 1} = { x }, on the right side has a short notation for an object literal - { x } which is equalent to { x: x }, that is in our case an object { x: undefined }\nOnce it destucted the pattern{ x: y = 1}, we extract variable y, which correspond to the propery x. Since propery x is undefined, the default value 1 is assigned to it.\n\n Question 4\n\n(function() {\n  let f = this ? class g {} : class h {};\n  return [\n    typeof f,\n    typeof h\n  ] \n})()\n\n['function', undefined]\n['function', 'function']\n['function', 'function']\n['undefined', 'undefined']\nError\n\nThe IIFE is executed with no explicit this value. In ES6 or with use strict directive it means it will be undefined;\nSo variable f is a reference to class h {}. It's type is a function because essentially classes in ES6 are syntactic sugar on top of contructor function.\nHowever, the class h {} is created in expression position, that means h isn't added to to the environment, and return undefined.\n\nQuestion 5\n\n(typeof (new (class { class () {} })))\n\n'function'\n'object'\n'undefined'\nError\n\nThis is an obfuscated syntax playing, let's try to figure it out!\n\nThe ES6 allow concise method definition, that allows dropping the : function part. So class () {} is a method inside in https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Operators/classExamples.\nNow instead of assigning it to variable, we can instantiate it directly: new class { class() { } }\nThe result of default class is always an object. So typeof should return object.\n\nQuestion 6\n\ntypeof (new (class F extends (String, Array) { })).substring\n\n'function'\n'object'\n'undefined'\nError\n\nAgain an obfuscated syntax.\n\nThe grouping operator always return the last argument, so the result of (String, Array) is actually just Array\nSo we get class F extends Array {}\nWe can image as it's assigning operation let f = new F\nObviously that typeof f.substring is undefined\n\n Question 7\n\n[...[...'...']].length\n\n1\n*3*\n6\nError\n\nThe spread operator allows to spread all the elements to the array. It works with any iterable object.\n\nString are iterable, meaning that we can iterate char by char. So inner [...'...'] results to an array ['.', '.', '.']\nArray is iterable as well, so outer array spreads into new array.\nResult of ['.', '.', '.'].length is 3\n\nQuestion 8\n\ntypeof (function* f() { yield f })().next().next()\n\nGenerator object has next method, that returns the next value at the yield position. The returned value has signature: { value: returned value, done: boolean}\nFirst g.next() has result {value: function f, done: false}\nThe returned value value itself doesn't have next() method, so trying to chain methods is an error.\n\n Question 9\n\ntypeof (new class f() { f { }, f: { } })[${f}]\n\n'function'\n'undefined'\n'object'\nError\n\nSince the syntax of class isn't correct class f(), the result is an error.\n\nQuestion 10\n\ntypeof ${{Object}}.prototype\n\n\"function\"\n\"undefined\"\n\"object\"\nError\n\nThat one is very tricky!\n\nWe have something that looks a bit strange: it isn't ${Object} how it \"should be\", but the ${{Object}}. It isn't a special syntax it is still a value {Object} in template string ${}.\n\nWhat is ${Object}? ES6 has short notation for object literal, so in fact it's just: {Object: Object}, a simple object with the property named 'Object', and the value Object (the built in constructor).\nSo ${ {Object: Object} }, become '[object Object]'. Because the ${x} is roughly equivalent to the x + '' or x.toString()\nNow the '[object Object]'.prototype is undefined\n\nSave my day:\nDmitrySoshnikov\n\n",
        "tags": []
    },
    {
        "uri": "/post/Kata-Array-RegExp-Filter-through-name-email",
        "title": "Kata: Filter through name/email",
        "content": "\nHe has troubles with users ending or starting in a ., and his user-array is a flat array of user-email-pairs, like so:\n\n!--more--\n\n[ \"foo\", \"foo@bar.com\", \"bar\", \"bar@foo.com\", \".foo\", \"food@bar.com\" ]\n\nHe is only interested in e-mailing the users and ask them to sign up again, so no need to keep the user-name, only e-mail addresses for the user-names that start or end with a . should be returned. For the above array, the correct return-array would be [ \"food@bar.com\" ].\n\nTest:\n\ndescribe( \"Testing a list\", function(){\n  it( \"Basic list\", function(){\n    var a = [ \"foo\", \"foo@foo.com\", \"bar.\", \"bar@bar.com\" ],\n    b = [ \"bar@bar.com\" ];    \n    Test.assertSimilar( searchNames( a ), b,\n      \"not correct \" + Test.inspect(a) + \" given\" );\n  } );\n} );\n\nResult:\nconst searchNames = logins = {\n  return logins.filter(\n        ( login, i, ary) = i % 2 === 1 && ary[i - 1].match(/^\\.|\\.$/);\n    )\n};\n`",
        "tags": []
    },
    {
        "uri": "/post/Kata-Arrays-Are-they-square",
        "title": "Kata: Are they square?",
        "content": "\nWrite a function that checks whether all elements in an array are square numbers. The function should be able to take any number of array elements.\n\n!--more--\n\nYour function should return true if all elements in the array are square numbers and false if not.\n\nAn empty array should return undefined. You can assume that all array elements will be positive integers.\n\n// test\nTest.describe(\"isSquare\",function() {\n    Test.it(\"Basic tests\",function() {    \n        Test.assertEquals(isSquare([1, 4, 9, 16, 25, 36]), true);\n        Test.assertEquals(isSquare([1, 2, 3, 4, 5, 6]), false);\n        Test.assertEquals(isSquare([]), undefined);\n        Test.assertEquals(isSquare([1, 2, 4, 15]), false); \n    })\n});\n\n// implementation\nvar isSquare = function(arr){\n  return arr.length ? arr.every(x = Math.sqrt(x) % 1 === 0) : undefined;\n}\n`",
        "tags": []
    },
    {
        "uri": "/post/Kata-Functions-Function-cache",
        "title": "Kata: Function cache",
        "content": "\nIf you are calculating complex things or execute time-consuming API calls, you sometimes want to cache the results. In this case we want you to create a function wrapper, which takes a function and caches its results depending on the arguments, that were applied to the function.\n\n!--more--\n\nUsage example:\n\nconst complexFunction = (arg1, arg2) = { /* complex calculation in here */ };\nconst cachedFunction = cache(complexFunction);\n\ncachedFunction('foo', 'bar'); // complex function should be executed\ncachedFunction('foo', 'bar'); // complex function should not be invoked again, instead the cached result should be returned\ncachedFunction('foo', 'baz'); // should be executed, because the method wasn't invoked before with these arguments\n\nResult:\n\nconst cache = fn = {\n  const calls = {};\n  \n  return function(...args) {\n    if (!calls[args]) {\n      calls[args] = fn(...args);\n    }\n    return calls[args];\n  }\n}\n`",
        "tags": []
    },
    {
        "uri": "/post/Kata-Fundamentals-Arrays-All-None-Any",
        "title": "Kata: All, None & Any",
        "content": "\nAs a part of this Kata, you need to create three functions that one needs to be able to call upon an array:\n\n!--more--\n\nall\n\nThis function returns true only if the predicate supplied returns true for all the items in the array\n\n[1, 2, 3].all(isGreaterThanZero) = true\n[-1, 0, 2].all(isGreaterThanZero) = false\n\nnone\n\nThis function returns true only if the predicate supplied returns false for all the items in the array\n\n[-1, 2, 3].none(isLessThanZero) = false\n[-1, -2, -3].none(isGreaterThanZero) = true\nany\n\nThis function returns true if at least one of the items in the array returns true for the predicate supplied\n\n[-1, 2, 3].any(isGreaterThanZero) = true\n[-1, -2, -3].any(isGreaterThanZero) = false\n\nYou do not need to worry about the data supplied, it will be an array at all times.\n\nfunction isGreaterThanZero (num) {\n  return num  0;\n}\n\nfunction isLessThanZero (num) {\n  return num < 0;\n}\n\nTest.expect([1, 2, 3].all(isGreaterThanZero), 'All are greater than zero');\nTest.expect(![-1, 0, 2].all(isLessThanZero), 'All is less than zero');\n\nTest.expect(![1, 2, 3].none(isGreaterThanZero), 'None is greater than zero');\nTest.expect([3, 0, 2].none(isLessThanZero), 'None is less than zero');\n\nTest.expect([1, 2, 3].any(isGreaterThanZero), 'None is greater than zero');\nTest.expect([-1, 0, 2].any(isLessThanZero), 'None is less than zero');\n\nArray.prototype.all = function (p) {\n return this.filter(p).length === this.length;\n};\n\nArray.prototype.none = function (p) {\n   return this.filter(p).length === 0;\n};\n\nArray.prototype.any = function (p) {\n  return this.filter(p).length  0;\n};\n`",
        "tags": []
    },
    {
        "uri": "/post/Kata-String-Format-a-string-of-names-like-Bart-Lisa-Maggie",
        "title": "Kata: Format a string of names like 'Bart, Lisa & Maggie'",
        "content": "\nGiven: an array containing hashes of names\n\nReturn: a string formatted as a list of names separated by commas except for the last two names, which should be separated by an ampersand.\n!--more--\n\nlist([ {name: 'Bart'}, {name: 'Lisa'}, {name: 'Maggie'} ])\n// returns 'Bart, Lisa & Maggie'\n\nlist([ {name: 'Bart'}, {name: 'Lisa'} ])\n// returns 'Bart & Lisa'\n\nlist([ {name: 'Bart'} ])\n// returns 'Bart'\n\nlist([])\n// returns ''\n\nTests:\n\nTest.assertEquals(list([{name: 'Bart'},{name: 'Lisa'},{name: 'Maggie'},{name: 'Homer'},{name: 'Marge'}]), 'Bart, Lisa, Maggie, Homer & Marge',\n\"Must work with many names\")\nTest.assertEquals(list([{name: 'Bart'},{name: 'Lisa'},{name: 'Maggie'}]), 'Bart, Lisa & Maggie',\n\"Must work with many names\")\nTest.assertEquals(list([{name: 'Bart'},{name: 'Lisa'}]), 'Bart & Lisa', \n\"Must work with two names\")\nTest.assertEquals(list([{name: 'Bart'}]), 'Bart', \"Wrong output for a single name\")\nTest.assertEquals(list([]), '', \"Must work with no names\")\n\nResult:\n\nconst list = names = {\n  return names.reduce( (prev, current, index, array) = {\n    if (index === 0){\n      return current.name;\n    }\n    else if (index === array.length - 1){\n      return ${prev} & ${current.name};\n    } \n    else {\n      return ${prev}, ${current.name};\n    }\n  }, '');\n }\n`",
        "tags": []
    },
    {
        "uri": "/post/Kata-String-Reverse-words",
        "title": "Kata: Reverse words",
        "content": "\nWrite a reverseWords function that accepts a string a parameter, and reverses each word in the string. Every space should stay, so you cannot use words from Prelude.\n\n!--more--\n\nconst reverseWords = str = {\n  return str\n    .split(' ')\n    .map( word = word.split('').reverse().join('') )\n    .join(' ');\n}\n\nreverseWords(\"This is an example!\"); // \"sihT si na !elpmaxe\"\n\nTest:\n\nTest.assertEquals(reverseWords(\"This is an example!\"), \"sihT si na !elpmaxe\")\n",
        "tags": []
    },
    {
        "uri": "/post/Lifecycle-hooks-in-AngularJS-1-5",
        "title": "Lifecycle hooks in AngularJS 1.5",
        "content": "\nLifecycle hooks are simple functions that are called at specific points of a component's life in Angular apps. They landed in AngularJS 1.5 and are used with .component() method and they were inspired of Angular 2 hooks.\n\n!--more--\n\n\"$onInit\" + \"require\"\n\nLet's create tabs component that uses $onInit and require. Full working exapmle:\n\niframe width=\"100%\" height=\"300\" src=\"//jsfiddle.net/vshmyfe8/embedded/\" allowfullscreen=\"allowfullscreen\" frameborder=\"0\"/iframe\n\n \"$postLing\" \n\nThe $postLink gives as non-hacky-looking way to control link method. \n\nWe can actually use the it to set an initial value for active tab:\n\niframe width=\"100%\" height=\"300\" src=\"//jsfiddle.net/jm0b38ma/embedded/\" allowfullscreen=\"allowfullscreen\" frameborder=\"0\"/iframe\n\n\"$onChanges\"\n\nThis is the most important one, and allow use component architecture with one-way data flow!\n\nThe $onChanges method is called for a few reasons. The first is on component in initialization - component gets initial changes object. The second reason it gets called is only when changes occur to < (one-way databinding) and @ (for evaluating DOM attribute values) that are being bound the parent component.\n\nOnce the $onChenges gets called, you get special changes object back:\n\nvar childComponent = {\n  bindings: { user: '<' },\n  controller: function () {\n    this.$onChanges = function (changes) {\n      // changes is a special instance of a constructor Object,\n      // it contains a hash of a change Object and\n      // also contains a function called isFirstChange()\n      // it's implemented in the source code using a constructor Object\n      // and prototype method to create the function isFirstChange()\n    };\n  }\n};\n\nangular\n  .module('app')\n  .component('childComponent', childComponent);\n\nIn example we're using bindings: { user: '<' } which means we receive he data through one-way databinding under the alias of user:\n\niframe width=\"100%\" height=\"300\" src=\"//jsfiddle.net/8cj1t4n7/embedded/\" allowfullscreen=\"allowfullscreen\" frameborder=\"0\"/iframe\n\n Cloning \"changes\" for \"immutable\" bindings\n\nData passed through one-way databinding are not $watched by Angular, however they are passed by reference. It means that any changes we make with object (primitives are not passed by reference) it affects the parent object, which acts as two-way databinding. We can clone data which are passed for non polluting changes from child to parent:\n\niframe width=\"100%\" height=\"300\" src=\"//jsfiddle.net/Lf4y3oad/embedded/\" allowfullscreen=\"allowfullscreen\" frameborder=\"0\"/iframe\n\nOne-way data-flow + events\n\nTo get data back up to our parentComponent, we need to delegate a function to be used as an event callback, let’s add a function called updateUser, which expects an event back as an argument:\n\nvar parentComponent = {\n  ...\n  controller: function () {\n    ...\n    this.updateUser = function (event) {\n      this.user = event.user;\n    };\n  }\n};\n\nInstead of just passig back this.user into the function, we’re going to fake an $event object, which complies with how Angular 2 does this (using EventEmitter), and also provides global consistency between your templates to fetch data back through the $ctrl.updateUser($event); call we delegate down into the child component. The $event argument is a real thing in Angular, you can use it with ng-submit and so on:\n\nvar childComponent = {\n  ...\n  controller: function () {\n    ...\n    this.saveUser = function () {\n      this.onUpdate({\n        $event: {\n          user: this.user\n        }\n      });\n    };\n  }\n};\n\nThe full example with delegating update of object:\n\niframe width=\"100%\" height=\"300\" src=\"//jsfiddle.net/0rb4nsma/embedded/\" allowfullscreen=\"allowfullscreen\" frameborder=\"0\"/iframe\n\n Is two-way databinding via syntax \"=\" is dead?\n\nYes. One-way bindings establishes as the best approach for data flow. React, Angular 2 and other all use it.\n\n\"$onDestroy\"\n\nIf you're using $postLink to set DOM event listener or any non-native Angular logic, $onDestroy is the place to clean up everything.\n\nThe old $scope way was kind of this:\n\nfunction SomeController($scope) {\n  $scope.$on('$destroy', function () {\n    // destroy event\n  });\n}\n\nWith new school it looks like this:\n\nvar childComponent = {\n  bindings: {\n    user: '<'\n  },\n  controller: function () {\n    this.$onDestroy = function () {\n      // component scope is destroyed\n    };\n  }\n};\n\nangular\n  .module('app')\n  .component('childComponent', childComponent);\n\n \"$doCheck\"\n\nIn version 1.5.8 a new hook is introduced: $doCheck. And this is the equivalent of the angular 2 ngDoCheck implementation. It also serves the same purpose as the $onChanges, allow to act on changes made to the bindable fields of a component. As $onChanges uses the built-in change detection of angular, the $doCheck implementation is totally up to you. The hook is called for every digest cycle of the component and just let’s you know you should check your bindings on changes so you can act on it.\n\nOne of the case this could be useful is when you make use of the one-way (<) binding for passing objects. In this case the $onChanges hook will be called if the reference of the object changes and not when fields on the object it self change. So currently you had 2 possibilities to solve this:\n\nAlways make sure you are passing a new object. This way $onChanges hook will be called for every change because the reference of the object will change from time to time.\n\n// the following won't trigger $onChanges.\n\nfunction get() { \n  api.getData().then( (data) = {\n    ctrl.someModel.data = data\n  }\n}\n\n// pass new object every time after changes\nfunction get() { \n  api.getData().then( (data='42') = {\n    const updatedModel = Object.assign(ctrl.someModel, data);\n    ctrl.someModel = updatedModel\n  }\n}\n\n// And in the child component (assuming the model as been binded as 'data'):\n\nthis.$onInit = function(bindings) {\n  if (bindings.data && bindings.data.currentValue) {\n    console.log(bindings.data.currentValue) // '42' \n  }\n}\n\nAdd a watch on the object to keep track of the changes. This also means you need to destroy and recreate the the watch every the reference of the object changes and you have an (unwanted) dependency on $scope inside your component:\n\nmodule.component(\"component\",{\n    template: \"div{{$ctrl.item}}/div\",\n    bindings: {\n        inputItem: \"<item\"\n    },\n    controller: [\"$scope\", function($scope){\n        var $ctrl = this;\n        var destroyWatch;\n        this.$onChanges = function(changeObj){\n            if(changeObj.inputItem){\n                this.item = \n                  angular.copy(changeObj.inputItem.currentValue);\n                if(destroyWatch) destroyWatch();\n                destroyWatch = $scope.watch(function (){ \n                    return changeObj.inputItem.currentValue \n                }, function (){ /* handle Changes */ })\n            }\n        }\n    }\n}]);\n\nThe $doCheck hook now adds a third possibility to solve this issue. By checking manually if the object has changed you can act on it. This can be done by storing the passed value into a local variable, so it can be used in the next call as previous value for comparison:\n\nmodule.component(\"component\",{\n    template: \"div{{$ctrl.item}}/div\",\n    bindings: {\n        inputItem: \"<item\"\n    },\n    controller: function(){\n        var $ctrl = this;\n        var previousInputItem;\n        this.$doCheck = function(){\n            if(!angular.equals(previousInputItem, this.inputItem)){\n                previousInputItem = this.inputItem;\n                this.item = angular.copy(this.inputItem);\n            }\n        }\n    }\n});\n\nChange detection in angular 1.x is done using digest cycles and for every cycle the $doCheck hook will be called. This means this will be called a lot. This is why you have the be careful using this hook so it doesn’t cause any performance issues. Also keep in mind that any change made to the model inside the $doCheck hook will trigger a new digest cycle. If implemented wrong this can result into a loop of digest cycles.\n\nIn angular 2 the change is implemented on a different (more performant) way and this will result in less calls of the ngDoCheck. It will also throw an error if you trigger changes outside of the component in prod mode.\n\nSave my day:\n\nTodd Motto\n$doCheck\nOff docs",
        "tags": []
    },
    {
        "uri": "/post/Maybe-you-don-t-need-jQuery",
        "title": "Maybe, you don't need jQuery?",
        "content": "\nDo you really need to use jQuery methods instead of vanilla Javascript?\n\n!--more--\n\nWhen should I use jQuery\n\nDo you need a quick prototype or proof of concept?\nDo you use jQuety plugin?\n    2.1   jQuery Plugins, jQuery Widgets, Twitter Bootstrap, etc...\nDo you use a Library or Fremework than depends on jQuery?\n    3.1   Backbone.js, Ember.js, etc...\nDo any of your browser not \"Cut the mustard\" (come up to expectations, reach the required standard) ?\nFeatured not supported Netievly in <= IE8\n\n    Alternative Libraries\n\nZepto.js\nMin.js\n\nNative Selectors\n\n//jQuery:\n$('datepicker');\n$('input');\n$('.date');\n$('input.date');\n\n//Native :\ndocument.getElementById('datepicker');\ndocument.getElementsByTagName('input');\ndocument.getElementsByClassName('.date');\ndocument.querySelectorAll('input.date');\ndocument.querySelector('input.date');\n\nEach\n\n//Each jQuery:\n$('input.date').each(function(el, i) {\n    $(el).text('Hello ' + i);\n})\n\n//Native 1: \nvar nodes = document.querySelectorAll('input.date');\n\nfor (var i = 0; i < nodes.length; i++) {\n    nodes[i].innerText = 'Hello ' + i;\n}\n\n//Each Native #2: \nvar nodes = document.querySelectorAll('input.date'),\n    elems = [].slice.call(nodes);\n\nelems.forEach(function(el, i) {\n    el.innerText('Hello ' + i);\n});\n\n//Each Native #3:\nvar nodes = document.querySelectorAll('input.date');\n\n[].forEach.call(nodes, function(el, i) {\n    el.innerText('Hello ' + i);\n});\n\n//Each Native #4: \nfunction $$(selector) {\n    return [].slice.call(selector)\n}\n\n$$('input.date').forEach(function(el, i) {\n    el.innerText('Hello ' + i);\n});\nIndex(eq)\n\n//Index(eq) jQuery:\n$(div.date).eq(3);    //return $ object\n$(div.date).get(3);\n$(div.date)[3];\n\n//Index Native:\ndocument.querySelectorAll('input.date')[3]\n\n  First, Last\n\n//First, Last jQuery:\n\nvar $dates = $('.dates');\n\n$dates.first();    //return $ object\n$dates.eq(0);      //return $ object\n$dates.get(0);\n$dates[0];\n\n$dates.last();    //return $ object\n$dates.eq(-1);    //return $ object\n$dates.get(-1);\n$dates[$dates.length - 1];\n\n//First, Last Native:\nvar dates = document.querySelectorAll('.dates');\n\ndates.firstElementChild;\ndates[0];\ndocument.querySelector('.dates');\n\ndates.lastChild\ndate[date.length - 1];\n[].pop.call(date);\n\nIs/Matches\n\n//jQuery \"is\":\n$('widget').is('.active');\n\n//Native \"match\":\ndocument.getElentById('widget').matches('.active');\n\n//matches polyfil;\nif (Element && !Element.prototype.matches) {\n    var proto = Element.prototype;\n    proto.matches = proto.matchesSelector ||\n        proto.mozMatchesSelector || proto.msMatchesSelector ||\n        proto.oMatchesSelector || proto.webkitMatchesSelector;\n}\n\nFilter\n\n//Filter jQuery:\nvar dates = $(.dates);\n\ndates.filter('[pattern]');\ndates.filter('.active');\n\n//Filter Native:\nvar dates = [].slice.call(document.querySelectorAll('.dates'));\n\ndates = dates.filter(function(el, i) {\n    el.matches('.active')\n});\n\n Find\n\n//Find jQuery:\n$('#widget').find('.favorites');\n$('ul').find('.favorites');\n\n//Find Native:\ndocument.getElementById('widget').querySelectorAll('.favorites');\n   \nNext, Prev\n\n//Next, Prev jQuery:\nvar elem = $('widget'),\n    prev = elem.prev(),\n    next = elem.next();\n\n//Next, Prev Native:\nvar elem = document.getElementById('widget'),\n    prev = elem.previousElementSibling,\n    next = elem.nextElementSibling;\n\nClosest\n\n$('widget').closest('.active');\n\n//Closest Native:\nclosest(document.getElementById('widget'), '.active');\n\nfunction closest(elem, selector) {\n\n   var matchesSelector = elem.matches || elem.webkitMatchesSelector || elem.mozMatchesSelector || elem.msMatchesSelector;\n\n    while (elem) {\n        if (matchesSelector.bind(elem)(selector)) {\n            return elem;\n        } else {\n            elem = elem.parentElement;\n        }\n    }\n    return false;\n}\n\nClasses\n\nClass manipulation in <=IE9\n\ndocument.querySelector('.widget').className += ' active';\ndocument.querySelector('.widget').className = ' ';\n\nFor polyfill ClassList use this one.\n\n HTML text\n\n//jQuery:\nvar $widget = $('#widget');\n\n$widget.html('bHello from jQuery!/b'); //Setter\n$widget.html();                            //Getter\n$widget.text('Bye from jQuery!');           \n$widget.text();\n\n//Native:\nvar widget = document.getElementById('widget');\n\nwidget.innerHTML = 'Hello from Native!' //Setter\nwidget.innerHTML;                           //Getter\nwidget.textContent = 'Bye from Native!';\nwidget.textContent;\n\nAppend & Prepend\n\n//jQuery:\n$('widget').append('divHello from jQuery!/div');\n$('#widget').append('divBye from jQuery!/div');\n\n//Native:\nvar widget = document.getElementById('widget'),\n    appendEl = document.createElement('div'),\n    prependdEl = document.createElement('div');\n\nwidget.appendChild(appendEl);\nwidget.insertBefore(prependEl, appendEl.children[0]);\n\nOr you can use polifil for modern methods like prepend, append, etc...\nscript src=\"https://cdn.polyfill.io/v1/polyfill.js?features=Element.prototype.append,Element.prototype.after\"/script\n\nRemove\n\n//jQuery:\nvar $widget = $('widget');\n\n$widget.empty();\n$widget.html('');\n$widget.remove();\n\n//Native:\nvar widget = document.getElementById('widget');\n\nwidget.innerHTML = '';\nwidget.parentNode.removeChild(widget);\nwhile (widget.lastChild)\n    widget.removeChild(widget.lastChild);\n\nCSS\n\n//jQuery:\nvar $widget = $('widget');\n\n$widget.css('color', 'aquamarine');\n$widget.css({\n    fontSize: '2em',\n    '-webkit-transform': 'rotate(45deg)',\n    'transition': 'all .5s easy-in'\n    });\n\n//Native:\nvar widget = document.getElementById('widget');\n\nwidget.css.color = 'aquamarine';\nwidget.css[fontSize varible] = '2em';\n\nAttributes and Property\n\n//jQuery:\nvar $widget = $('search-main'),\n    $toggle = $('#toogle-checkbox'),\n    $link = $('#link-awesome');\n\n$widget.attr('placeholder', 'Search Here ...');\n$widget.attr('placeholder');\n\n$toggle.prop('checked', true);\n$toggle.prop('checked');\n\n$link.attr('href'); // .pages/about.html\n$link.prop('href'); // http://domain.com/pages/about.html\n\n//Native:\nvar widget = document.getElementById('widget'),\n    toogle = document.getElementById('toogle-checkbox'),\n    link = document.getElementById('toogle-checkbox');\n\nwidget.setAttribute('placeholder', 'Search Here ...');\nwidget.setAttribute();\n\ntoogle.checked = true;\ntoogle.checked;\n\nlink.getAttribute('href'); // .pages/about.html\nlink.href;                 // http://domain.com/pages/about.html\n    \nValue\n\n//jQuery:\nvar $widget = $('search-main');\n\n$widget.val('Hello, new value!');\n$widget.val();\n\n//Native:\nvar widget = document.getElementById('search-main');\n\nwidget.value = 'Hello, new value!'\nwidget.value;\n\nHeight & Width\n\n//jQuery:\nvar $container = $('container');\n\n$container.width();\n$container.innerWidth();\n$container.outerWidth();\n\n//Native:\nvar container = document.getElementById('search-main');\n\ncontainer.clientWidth;\ncontainer.offsetWidth;\nbox.getBoundingClientRect().width;\n\nBind and Unbind\n\n//jQuery:\n$('foo-btn').click(function() {});\n$('#foo-btn').on('click', function() {});\n$('#foo-btn').bind('click', function() {});\n\n$(.btn-active).on('click', function() {});\n\n//unbind\nvar el = $('#bar-btn');\n\nel.off();\nel.off('click');\nel.off('click', nameOfCallback);\n\n//Native:\nvar btn = document.getElementById('foo-btn');\n    btnsActive = document.querySelectorAll('.foo-active'),\n    cachingCallback = function(){};\n\nbtn.addEventListener('click', function() {});\n\n[].forEach.call(btnsActive, function(el) {\n    el.addEventListener('click', cachingCallback);\n})\n\n//unbind\nbtn.removeEventListener('click', nameOfCallback);\n\n[].forEach.call(btnsActive, function(el) {\n    el.removeEventListener('click', nameOfCallback);\n})\n\nDelegation\n\n//jQuery:\n$('menu').on('click', 'li' function() {});\n\n//Native:\ndocument.getElementById('menu').addEventListener('click', function(ev) {\n    if (ev.target.tagName != 'LI') return;\n\n    //or\n    if (ev.target.matches(.active)) {\n        //...\n    }\n});\n    \nPrevent Default & Stop Propation\n\n//jQuery:\n$('submit-form').on('click', function(ev) {\n    ev.preventDefault();\n    ev.stopPropation();\n});\n\n//Native:\ndocument.getElementById('#submit-form').addEventListener('click', function(ev) {\n    ev.preventDefault();\n    ev.stopPropation();\n});\n\nTrigger\n\n//jQuery:\n$('menu').on('click', function(ev, arg1, arg2) {\n    console.log(ev, arg1, arg2);\n});\n\n$('menu').trigger('click');\n$('menu').trigger('click', ['arg1', 'arg2']);\n\n//Native:\ndocument.getElementById('menu').addEventListener('click', function(ev, arg1, arg2) {\n    console.log(ev, arg1, arg2)\n});\n\nvar event = new Event('click');\ndocument.getElementById('#menu').dispatchEvent(event);\n\nvar event = new CustomEvent('click', {\n    detail: ['arg1', 'arg2']\n});\ndocument.getElementById('#menu').dispatchEvent(event);\n\nDOM Ready\n\n//jQuery:\n$(document).ready(function() {\n    //DOM is ready\n});\n\n$(function() {\n    //DOM is ready\n})\n\n!--Native 1:--\n\n!DOCTYPE html\nhtml lang=\"en\"\nhead\n    meta charset=\"UTF-8\"\n    titleDocument/title\n/head\nbody\n\n    script\n        //DOM is ready\n    /script\n/body\n/html\n[/html]\n\n//Native #2:\ndocument.addEventListener('DOMContentLoaded', function() {\n    //DOM is ready\n})\n\nAjax Get\n\n//jQuery 1:\n$.get('url', function(data) {\n    console.log(data);\n});\n\n$.get(\n    'url',\n    {name: 'foo'},\n    function(data) {\n        console.log(date);\n    }\n)\n\n//jQuery #2:\n$.ajax({\n    type: 'GET',\n    url: 'url',\n    data: {name: 'foo'},\n    success: function(data) {\n        console.log(date);\n    }\n})\n\n//Native:\nvar xhr = new XMLHttRequest();\n\nxhr.open('GET', 'url' + 'name=foo', true);\nxhr.onload = function() {\n    if (this.status === 200)\n        console.log(this.responseText);\n};\nxhr.send();\n\nAjax Post\n\njQuery 1:\n$.post('url', function(data) {\n    console.log(data);\n});\n\n$.post(\n    'url',\n    {name: 'foo'},\n    function(data) {\n        console.log(date);\n )\n\n//jQuery #2:\n$.ajax({\n    type: 'POST',\n    url: 'url',\n    data: {name: 'foo'},\n    success: function(data) {\n        console.log(date);\n    }\n})\n\n//Native #1:\nvar xhr = new XMLHttRequest();\n\nxhr.open('POST', 'url', true);\nxhr.setRequestHeader('Content-type', 'application/x-www-form-urlencoded')\nxhr.onload = function() {\n    if (this.status === 200)\n        console.log(this.responseText);\n};\nxhr.send('name=bob&age=26');\n\n!--Native #2:--\n\nform enctype=\"multipart/form-data\" method=\"post\" name=\"fileinfo\"\n  labelYour email address:/label\n  input type=\"email\" autocomplete=\"on\" autofocus name=\"userid\" placeholder=\"email\" required size=\"32\" maxlength=\"64\" /\n\n  labelCustom file label:/label\n  input type=\"text\" name=\"filelabel\" size=\"12\" maxlength=\"32\" /\n\n  labelFile to stash:/label\n  input type=\"file\" name=\"file\" required /\n  input type=\"submit\" value=\"Stash the file!\" /\n/form\ndiv id=\"output\"/div\n\nscript\nvar form = document.forms.namedItem(\"fileinfo\");\nform.addEventListener('submit', function(ev) {\n\n  var oOutput = document.getElementById(\"output\"),\n    oData = new FormData(document.forms.namedItem(\"fileinfo\"));\n\n  oData.append(\"CustomField\", \"This is some extra data\");\n\n  var oReq = new XMLHttpRequest();\n  oReq.open(\"POST\", \"stash.php\", true);\n  oReq.onload = function(oEvent) {\n    if (oReq.status == 200) {\n      oOutput.innerHTML = \"Uploaded!\";\n    } else {\n      oOutput.innerHTML = \"Error \" + oReq.status + \" occurred uploading your file.\";\n    }\n  };\n\n  oReq.send(oData);\n  ev.preventDefault();\n}, false);\n/script\n\nJSONP\n\n//jQuery 1:\n\n$.getJSON('http://domain.io/jsonp?callback=?',\n function(data) {\n    console.log(data);\n});\n\n//jQuery #2:\n$.ajax({\n    url: 'url',\n    dataTepe: 'jsonp',\n    success: function(data) {\n        console.log(date);\n    }\n})\n\n//Native:\nfunction jsonpCallback(data) {\n    console.log(data)\n}\n\nvar script = document.creatElement('script');\nscript.src = 'http://exampleDomain.io/jsonp?callback=jsonpCallback';\ndocument.head.appendChils(script);\n\nMicro-Library\n\nReqwest on link\n\n Each, Grep, Map\n\n//jQuery:\n$.each(arr, function(el) {\n    console.log(el.name + ' ' + el.id);\n})\n\narr = $.grep(arr.function(el) {\n    return el.matches('Script')\n})\n\narr = $.map(arr, function(el) {\n    return {\n        nickname: el.name,\n        secretCode: el.age,\n        age: Date.now()\n    };\n});\n\n//Native:\narr.forEach(function(el) {\n    console.log(el.name + ' ' + el.id);\n});\n\narr = arr.filter(function(el) {\n    return el.matches('Script')\n});\n\narr = arr.map(function(el) {\n    return {\n        nickname: el.name,\n        secretCode: el.age,\n        age: Date.now()\n    };\n});\n\nOr you can use Undersore or Low-Dash _.each.\n\nin Array\n\nvar arr = ['foo', 'bar', 'baz'];\n\nconsole.log('Found Bar: ' + !!~arr.inArray('bar'));\n\n//Native:\nconsole.log('Found Bar: ' + !!~arr.indexOf('bar'));\n\n Trim\n\n//jQuery:\n$.trim('   look at me, I\"m padded!   ');\n\n//Native:\n'   look at me, I\"m padded!   '.trim();\n\nSave my day:\nYOU MIGHT NOT NEED JQUERY",
        "tags": []
    },
    {
        "uri": "/post/Medium-Style-Page-Transition",
        "title": "Medium-Style Page Transition",
        "content": "\nAn article on how to achieve Medium’s next page transition effect—an effect that can be seen by clicking anywhere on the “Read Next” footer at the bottom of the page. This effect is characterized by the lower article easing upward as the current article fades up and out.\n\n!--more--\n\nThe page makes Ajax request to static json files. Page state is managed by using the PushState API and location.hash. All photos are from Unsplash.\n\nIn this article, I will outline how to achieve Medium’s page transition effect—an effect that can be seen by clicking anywhere on the “Read Next” footer at the bottom of the page. This effect is characterized by the lower article easing upward as the current article fades up and out. See the animation below for an illustration of this effect.\n\nHTML\n\nIn this demo, the page first loads with barebones HTML, which we’ll use as a template that will be filled in later with Ajax’d-in data. Below is what our body looks like on initial page load. One main article tag. Pretty simple, eh?\n\nbody\n  article class='page hidden'\n    div class='big-image'/div\n    div class='content'/div\n  /article\n/body\n\nOnce the content is Ajax’d-in, the body looks something like so:\n\nbody\n  article class='page current'!--other HTML --/article\n  article class='page next '!--other HTML --/article\nbody\n\nThe page currently being viewed has a class of current, and the next article has a class of next. The next article only has its large image being shown at the bottom of the page, which, when clicked on, brings it into focus.\n\n    CSS\n\nThe styles in this demo which control the article transitions are both applied dynamically via jQuery’s css() method, as well as by applying classes to the article elements using jQuery’s addClass() method:\n\narticle.page.hidden { \n    display: none\n}\n\narticle.page.content-hidden .content { \n    display: none\n}\n\narticle.fade-up-out {\n    opacity: 0;\n    transform: scale(0.8) translate3d(0, -10%, 0);\n    transition: all 450ms cubic-bezier(0.165, 0.840, 0.440, 1.000);\n}\n\narticle.easing-upward {\n    transition: all 450ms cubic-bezier(0.165, 0.840, 0.440, 1.000);\n}\n\nJavaScript\n\nBefore getting into the Javascript code, I want to first outline the algorithm used to transition the next article upward, and transition the current article up and away.\n\nSo, when user click on next article:\n\nDisable scroll on the page\nFade current article to opacity of 0, a scale of .8 and move it upward by 10%\nShow the article content, give it smooth transition, then move it upward to the top of the window\nAfter 500ms:\n\nNon-Closure Example:\n\nfunction nonClosure() {\n    //encapsulation\n    var date = new Date(); //Varible lost after function returns\n\n    return date.getMilliseconds();\n}\n\nClosure function:\nfunction trueClosure() {\n    //encapsulation\n    var date = new Date(); //Varible stays around even after function returns\n\n    //nested function (!)\n    return function() {\n        return date.getMilliseconds();\n    }\n}\n\nClosure function example2:\n\nfunction trueClosure() {\n    //encapsulation\n    var date = new Date(); //Varible stays around even after function returns\n    //nested function (!)\n    function getTime() {\n        return date.getMilliseconds();\n    }\n\n    return {\n        getTime: getTime\n    }\n}\n\n    Animation Code\n\n ArticleAnimator.animatePage = function(callback){\n  var self              = this;\n  var translationValue  = this.$next.get(0).getBoundingClientRect().top;\n  this.canScroll        = false;\n\n  this.$current.addClass('fade-up-out');\n\n  this.$next.removeClass('content-hidden next')\n       .addClass('easing-upward')\n       .css({ \"transform\": \"translate3d(0, -\"+ translationValue +\"px, 0)\" });\n\n  setTimeout(function(){\n      self.scrollTop();\n      self.$next.removeClass('easing-upward')\n          self.$current.remove();\n\n      self.$next.css({ \"transform\": \"\" });\n          self.$current = self.$next.addClass('current');\n\n      self.canScroll = true;\n      self.currentPostIndex = self.nextPostIndex( self.currentPostIndex );\n\n      callback();\n  }, self.animationDuration + 300 );\n}\n\nThroughout the CSS and JavaScript code in order to achieve fluid animation I'm using transform: translate3d(x, y, z) to move DOM elements. By doing this, we hardware accelarate the DOM elements movement. This method is preferred over animating an element using top / left or transform: translateX(x) / translateY(y), which are not hardware accelarated by default.",
        "tags": []
    },
    {
        "uri": "/post/Misconceptions-About-Inheritance-in-JavaScript",
        "title": "Misconceptions About Inheritance in JS",
        "content": "\nWhat’s the Difference Between Class & Prototype Inheritance?\n\nThis can be a tricky question, and you’ll probably need to defend your answer with follow-up Q&A, so pay special attention to learning the differences, and how to apply the knowledge to write better code.\n\n!--more--\n\nAren’t classical and prototype inheritance really the same thing, just a stylistic preference?\n\nNo.\n\nClassical and prototype inheritance are fundamentally and semantically distinct.\n\nIn class inheritance, instances inherit from a blueprint (the class), and create sub-class relationships. In other words, you can’t use the class like you would use an instance. You can’t invoke instance methods on a class definition itself. You must first create an instance and then invoke methods on that instance.\n\nIn prototype inheritance, instances inherit from other instances. Using delegate prototypes (setting the prototype of one instance to refer to an exemplar object), it’s literally Objects Linking to Other Objects, or OLOO. Using concatenative inheritance, you just copy properties from an exemplar object to a new instance.\n\n Aren’t classes the right way to create objects in JavaScript?\n\nNo.\n\nThere are several right ways to create objects in JavaScript. The first and most common is an object literal:\n\nlet mouse = {\n  furColor: 'brown',\n  legs: 4,\n  tail: 'long, skinny',\n  describe () {\n    return `A mouse with ${this.furColor} fur,\n      ${this.legs} legs, and a ${this.tail} tail.`;\n  }\n};\n\nYou can attach delegate prototypes with Object.create():\n\nlet animal = {\n  animalType: 'animal',\n  \n  describe () {\n    return `An ${this.animalType}, with ${this.furColor} fur, \n      ${this.legs} legs, and a ${this.tail} tail.`;\n  }\n};\n\nlet mouse = Object.assign(Object.create(animal), {\n  animalType: 'mouse',\n  furColor: 'brown',\n  legs: 4,\n  tail: 'long, skinny'\n});\n\nLet’s break this one down a little:\n\nanimal is a delegate prototype. \nmouse is an instance. \nWhen you try to access a property on mouse that isn’t there, the JavaScript runtime will look for the property on animal (the delegate).\n\nI’m skipping the constructor function example because I can’t recommend them.\n\nDon’t you need a constructor function to specify object instantiation behavior and handle object initialization?\n\nNo.\n\nAny function can create and return objects. When it’s not a constructor function, it’s called a factory function.\n\nFactory function:\n\nlet animal = {\n  animalType: 'animal',\n \n  describe () {\n    return `An ${this.animalType} with ${this.furColor} fur, \n      ${this.legs} legs, and a ${this.tail} tail.`;\n  }\n};\n \nlet mouseFactory = mouseFactory () = {\n  return Object.assign(Object.create(animal), {\n    animalType: 'mouse',\n    furColor: 'brown',\n    legs: 4,\n    tail: 'long, skinny'\n  });\n};\n\nlet mickey = mouseFactory();\n\n Don’t you need constructor functions for privacy in JavaScript?\n\nNo.\n\nIn JavaScript, any time you export a function, that function has access to the outer function’s variables. When you use them, the JS engine creates a closure.\n\nClosures are not unique to constructor functions. Any function can create a closure for data privacy:\n\nlet animal = {\n  animalType: 'animal',\n \n  describe () {\n    return `An ${this.animalType} with ${this.furColor} fur, \n      ${this.legs} legs, and a ${this.tail} tail.`;\n  }\n};\n \nlet mouseFactory = function mouseFactory () {\n  let secret = 'secret agent';\n\n  return Object.assign(Object.create(animal), {\n    animalType: 'mouse',\n    furColor: 'brown',\n    legs: 4,\n    tail: 'long, skinny',\n    profession () {\n      return secret;\n    }\n  });\n};\n \nlet james = mouseFactory();\n\nDoes new mean that code is using classical inheritance?\n\nNo.\n\nThe new keyword is used to invoke a constructor. What it actually does is:\n\nCreate a new instance\nBind this to the new instance\nReference the new object’s delegate [[Prototype]] to the object referenced by the constructor function’s prototype property.\nNames the object type after the constructor, which you’ll notice mostly in the debugging console. You’ll see [Object Foo], for example, instead of [Object object].\nAllows instanceof to check whether or not an object’s prototype reference is the same object referenced by the .prototype property of the constructor.\n\n Is There a Big Performance Difference Between Classical and Prototypal Inheritance?\n\nNo.\n\nCan you tell the difference between .0000000001 seconds and .000000001 seconds? Neither can I, but I sure can tell the difference between loading 10 small icons or loading one web font, instead!\n\nThe Native APIs use Constructors. Aren’t they More Idiomatic than Factories?\n\nFactories are extremely common in JavaScript. For instance, the most popular JavaScript library of all time, jQuery exposes a factory to users. \n\nWhat else exposes factories?\n\nReact React.createClass() is a factory.\nAngular uses classes & factories, but wraps them all with a factory in the Dependency Injection container. All providers are sugar that use the .provider() factory. There’s even a .factory() provider, and even the .service() provider wraps normal constructors and exposes … you guessed it: A factory for DI consumers.\nEmber Ember.Application.create(); is a factory that produces the app. Rather than creating constructors to call with new, the .extend() methods augment the app.\nNode core services like http.createServer() and net.createServer() are factory functions.\nExpress is a factory that creates an express app.\n\nThe only object instantiation pattern more common than factories in JS is the object literal.\n\nJavaScript built-ins started out using constructors because Brendan Eich was told to make it look like Java. JavaScript continues to use constructors for self-consistency. It would be awkward to try to change everything to factories and deprecate constructors now.\n\n Doesn’t the Choice Between Classical and Prototype Inheritance Depend on the Use Case?\n\nNo.\n\nI recommend that you follow the Gang of Four’s advice on this point:\n\n “Favor object composition over class inheritance.”\n\nIn Java, that was harder than class inheritance because you actually had to use classes to achieve it.\n\nIn JavaScript, we don’t have that excuse. It’s actually much easier in JavaScript to simply create the object that you need by assembling various prototypes together than it is to manage object hierarchies.\n\nYou don’t have to extend a class. JavaScript has dynamic object extension, and jQuery exposes its own prototype so you can just extend that:\n\n/*\nHow to extend the jQuery prototype:\nSo difficult.\nBrain hurts.\nouch.\n*/\n\njQuery.fn.megaCalendarWidget = megaCalendarWidget;\n\n// omg I'm so glad that's over.\n\nThe next time you call the jQuery factory, you’ll get an instance that can make your date inputs mega awesome.\n\nSimilarly, you can use Object.assign() to compose any number of objects together with last-in priority:\n\nimport ninja from 'ninja';\nimport mouse from 'mouse';\n\nlet ninjamouse = Object.assign({}, mouse, ninja);\n\nNo, really — any number of objects:\n\n// I'm not sure Object.assign() is available (ES6)\n// so this time I'll use Lodash.\nvar assign = require('lodash/object/assign');\n\nvar skydiving = require('skydiving');\nvar ninja = require('ninja');\nvar mouse = require('mouse');\nvar wingsuit = require('wingsuit');\n\n// The amount of awesome in this next bit might be too much\n// for seniors with heart conditions or young children.\nvar skydivingNinjaMouseWithWingsuit = assign({}, // create a new object\n  skydiving, ninja, mouse, wingsuit); // copy all the awesome to it.\n\nThis technique is called concatenative inheritance, and the prototypes you inherit from are sometimes referred to as exemplar prototypes, which differ from delegate prototypes in that you copy from them, rather than delegate to them.\n\nWhy Does this Matter?\n\nInheritance is fundamentally a code reuse mechanism: A way for different kinds of objects to share code. The way that you share code matters because if you get it wrong, it can create a lot of problems.\n\nIn fact, class inheritance causes many well known problems in OO design:\n\nClass inheritance creates parent/child object taxonomies as a side-effect.\nThe tight coupling problem (class inheritance is the tightest coupling available in oo design), which leads to the next one…\nThe fragile base class problem\nInflexible hierarchy problem (eventually, all evolving hierarchies are wrong for new uses)\nThe duplication by necessity problem (due to inflexible hierarchies, new use cases are often shoe-horned in by duplicating, rather than adapting existing code)\nThe Gorilla/banana problem (What you wanted was a banana, but what you got was a gorilla holding the banana, and the entire jungle)\n\nThe solution to all of these problems is to favor object composition over class inheritance.\n\nSave my day - Eric Elliott on Medium",
        "tags": []
    },
    {
        "uri": "/post/Moving-from-ngModel-parsers-ng-if-to-ngModel-validators-ngMessages",
        "title": "Moving from \"ngModel.$parsers\"/\"ng-if\" to \"ngModel.$validators\"/\"ngMessages\"",
        "content": "\nImplementation custom Model validation is typically done by extending the built-in $error object to ngForm models.\n\nPrior to AngularJS 1.3 custom validation was done by injecting a function into the ngModel.$parsers array pipeline and manually setting validation states using $setValidity('visa', true) if the Model value matched a Visa credit card expression format, for example.\n\nAngularJS 1.3+ has the $validators pipeline object, which requires no manual setting of validation states.\n\nLet's take a look of old school way then we can shift to ngModel.$validators technique.\n\n!--more--\n\nOld school \"$parsers\"\n\nLet’s take some basic form markup, binding name=\"myForm\" to the form element so Angular takes control of our form and validation states. Next we’ll add an input with the name creditCard, which builds up the Model Object internally so we can access myForm.creditCard and handle our validation. I’ve added a validate-visa attribute, which will serve as the Directive bound to the input, so we can capture the Model and validate it.\n\nform name=\"myForm\"\n  h3Visa validation ($parsers)/h3\n  input type=\"text\" name=\"creditCard\" ng-model=\"creditCardModel\" validate-visa\n  {{ myForm.creditCard | json }}\n/form\n\nThe result is something like this: \n\n{\n  \"$validators\": {},\n  \"$asyncValidators\": {},\n  \"$parsers\": [],\n  \"$formatters\": [\n    null\n  ],\n  \"$viewChangeListeners\": [],\n  \"$untouched\": true,\n  \"$touched\": false,\n  \"$pristine\": true,\n  \"$dirty\": false,\n  \"$valid\": false,\n  \"$invalid\": true,\n  \"$error\": {},\n  \"$name\": \"creditCard\",\n  \"$options\": null\n}\n\nThe generated ngModel.creditCard.$error object it the place where we need to hook into. At this point we want conditionally toggle DOM based on the boolean value of this property. \n\nIf myForm.creditCard.$error.visa is true create the element, otherwise false framework will remove it from DOM.\n\nform name=\"myForm\"\n  h3Visa validation ($parsers)/h3\n  input type=\"text\" name=\"creditCard\" ng-model=\"creditCardModel\" validate-visa\n  p ng-if=\"myForm.creditCard.$error.visa\" class=\"invalid\"\n    Not a valid Visa format\n  /p\n/form\n\nNow we need to write logic for validate-visa directive to tie in to the ngModel and set states. Typically it's done by using ngMode.$parsers:\n\n// create a validateVisa function\nfunction validateVisa() {\n\n  // link function\n  function link($scope, $element, $attrs, $ctrl) {\n    // Some basic Visa Regular Expression\n    const VISA_REGEXP = /^4[0-9]{12}(?:[0-9]{3})?$/;\n    // visaParser function, passing in the current viewValue\n    function visaParser(viewValue) {\n      // a Boolean variable evaluated by RegExp.test(String)\n      const isValid = VISA_REGEXP.test(viewValue);\n      // Manually set the validity of the \"visa\" property on \n      // the \"$error\" Object bound to the Model.\n      // Note: $ctrl is the fourth argument in the \"link\" function\n      // as we're requiring \"ngModel\" (see below in the return {} statement)\n      $ctrl.$setValidity('visa', isValid);\n      // return the \"viewValue\" if it's valid or undefined \n      // so Angular doesn't set the value\n      return isValid ? viewValue : undefined; \n    }\n    // push the \"visaParser\" function into the \"$parsers\" Array\n    $ctrl.$parsers.push(visaParser);\n  }\n\n  // export the Directive Object\n  // which requires the \"ngModel\" Controller and\n  // binds the above \"link\" function\n  return {\n    require: 'ngModel',\n    link: link\n  };\n  \n}\n\nangular\n  .module('app')\n  .directive('validateVisa', validateVisa);\n\nThe syntax of pushing a function into $parsers array isn't very slick and we also manually set the validation state passing in string or boolean, which seems a very procedural way to do a thing.\n\nAt this point $error object which is bounded to the input looks like this:\n\n{\n  ...\n  \"$error\": {\n    \"visa\": true\n  },\n  ...\n}\n\n New school \"$validators\"\n\nIn AngularJS 1.3+ we've a much better way of doing things! \n\nJust like before we require: 'ngModel' into directive but instead of using $parsers we can bind a function straight to $validators object:\n\nfunction validateVisa() {\n\n  function link($scope, $element, $attrs, $ctrl) {\n    var VISA_REGEXP = /^4[0-9]{12}(?:[0-9]{3})?$/;\n    $ctrl.$validators.visa = function visaParser(modelValue, viewValue) {\n      var value = modelValue || viewValue;\n      return (VISA_REGEXP.test(value));\n    };\n  }\n\n  return {\n    require: 'ngModel',\n    link: link\n  };\n  \n}\n\nangular\n  .module('app')\n  .directive('validateVisa', validateVisa);\n\nThe above doesn’t even need annotating, any $validator property we add becomes the property name bound to $error, and we just need to return a boolean. Super simple and much clearer to read. Usage as the Directive from an HTML perspective is identical, it’s just the difference of how we implement the validation that changes\n\nOld school \"ng-if\"\n\nUsing ng-if is super simple, we tell to conditionally swap element based on property state bound to the $error object:\n\nform name=\"myForm\"\n  h3Visa validation (ngIf)/h3\n  <input \n    type=\"text\" \n    name=\"creditCard\" \n    ng-model=\"creditCardModel\" \n    required=\"\"\n    ng-minlength=\"13\"\n    ng-maxlength=\"16\"\n    validate-visa\n  p ng-if=\"myForm.creditCard.$error.required\" class=\"invalid\"\n    This field is required\n  /p\n  p ng-if=\"myForm.creditCard.$error.visa\" class=\"invalid\"\n    Not a valid Visa format\n  /p\n  p ng-if=\"myForm.creditCard.$error.minlength\" class=\"invalid\"\n    Minimum of 13 characters\n  /p\n  p ng-if=\"myForm.creditCard.$error.maxlength\" class=\"invalid\"\n    Maximum of 16 characters\n  /p\n/form\n\nIt's a very manual and repetitive process dealing with each $error property.\n\n New school \"ngMassages\"\n\nUnlike ng-if approach we're passing myForm.creditCard.$error only once into ngMassages. The directive will look of $error object and the corresponding massage will be rendered:\n\nform name=\"myForm\"\n  h3Visa validation (ngMessages)/h3\n  <input \n    type=\"text\" \n    name=\"creditCard\" \n    ng-model=\"creditCardModel\" \n    required=\"\"\n    ng-minlength=\"13\"\n    ng-maxlength=\"16\"\n    validate-visa\n  div ng-messages=\"myForm.creditCard.$error\"\n    p ng-message=\"required\" class=\"invalid\"\n      This field is required\n    /p\n    p ng-message=\"visa\" class=\"invalid\"\n      Not a valid Visa format\n    /p\n    p ng-message=\"minlength\" class=\"invalid\"\n      Minimum of 13 characters\n    /p\n    p ng-message=\"maxlength\" class=\"invalid\"\n      Maximum of 16 characters\n    /p\n  /div\n/form\n\nFor reusable/generic validation states we can use ngMassagesIncule:\n\nscript type=\"text/ng-template\" id=\"generic-messages\"\n  div ng-message=\"required\"This field is required/div\n  div ng-message=\"minlength\"This field is too short/div\n/script\n\nAnd ramp up it with an existing ngMassages:\n\ndiv ng-messages=\"myForm.creditCard.$error\"\n  div ng-messages-include=\"generic-messages\"/div\n  p ng-message=\"visa\" class=\"invalid\"\n    Not a valid Visa format\n  /p\n  p ng-message=\"minlength\" class=\"invalid\"\n    Minimum of 13 characters\n  /p\n  p ng-message=\"maxlength\" class=\"invalid\"\n    Maximum of 16 characters\n  /p\n/div\n\nThere are some other powerful features well worth checking out inside ngMessages, see the documentation for more.\n\nSave my day:\n\nTodd Motto",
        "tags": []
    },
    {
        "uri": "/post/NG6-starter-for-new-Angular-projects",
        "title": "NG6 starter for new Angular projects",
        "content": "\nThe de-facto starter repo for building scalable apps with AngularJS ^1.5, ES6, Gulp and Webpack\n\n!--more--\n\nGithub repo",
        "tags": []
    },
    {
        "uri": "/post/Node-js-design-pattern-book-review",
        "title": "Book: 'Node.js design pattern'",
        "content": "\n\"How could I organize my code?\", \"What is the best way to design this?\", \"How can I make my application more modular?\", \"How do I handle a set of asynchronous call effectively?\", \"How can I make sure that my application will not collapse while it grows?\".\n\nIf you have such questions without answers, that book is definitely for you!\n\nThe aim of this book is to guide you through this emerging world of patterns, techniques and practices, showing proven solution to the common problem.\n\n!--more--\n\nLink\n\nChapter 1: Welcome to the Node.js platform\n The Node.js philosophy\n\nSome of these principles arise from the technology itself, some of them are enabled by its ecosystem, some are just trends in community, some directly comes from its creator, another are influenced by the Unix culture.\n\nSmall core\nSmall modules\nSmall surface area\nSimplicity and pragmatism\n\nI/O is slow\n\nI/O is definitely the slowest among the fundamental operations of a computer. Accessing to RAM is in the order of nanoseconds, while accessing data on disk the network is in order of milliseconds. For the bandwidth is the same story. RAM has a transfer rate consistently in the order of GB/s, while disk and network varies from MB/s to, optimistically, GB/s.\n\nOn the top of that, we also have to consider the human factor. Often input of an application comes from a real person, so the speed or frequency of I/O doesn't only depend on technical aspects.\n\n Blocking I/O\n\nIn traditional blocking I/O programming the function call corresponding to an I/O request will block the execution of the thread until the operation completes.\n\n// block the thread until the data is available\ndata = socket.read()\n// data is available\nprint(data)\n\nIt's trivial to notice how web-server which is busing blocking I/O will not be able to handle multiple connection in the same thread. Each operation will block the processing of any other connection:\n\n{% image fancybox center images/blocking-input-output.png %}\n\nThe preceding image emphasis on the amount of time each thread is idle, waiting for new data to be received from associated connection. Also we need to consider how much time of I/O can possibly block a request, for example, while interacting with database or with filesystem.\n\nNon-blocking I/O with \"busy-waiting\"\n\nIn this operation mode, the system call always returns immediately without waiting for data to be read or written. If no result are available at the moment of call, the function will simply return a predefined constant, indicating that there is no data available to return at the moment.\n\nThe most basic pattern for accessing this kind of non-blocking I/O is busy-waiting - it actively poll the resource within a loop until some actual data is returned.\n\nresource = [socketA, socketB, pipeA]\n\nwhile(!resources.isEmpty()) {\n  foreach resource in resources {\n    // try to read\n    let data = resource.read()\n\n    if (data === NODATAAVAILABLE) {\n      // there is no data to read at the moment\n      continue\n    }\n    if (data === RESOUCE_CLOSED) {\n      // there was closed, remove it from list\n      resources.remove(resource)\n    } else {\n      // data was received, proceed it\n      consumeData(data)\n    }\n  }\n}\n\nWith this technique it's already possible to achieve handling different resources in the same thread, but still it isn't efficient.\n\n Event demultiplexing\n\nLuckily, most modern operation systems provide a mechanism to handle concurrent, non-blocking resources in efficient way. It's a synchronous event demultiplexing or event notification interface - it's collect and queues I/O events that come from set of watched resources, and block until new events are available for process.\n\nwatchedList.add(socketA, FOR_READ)\nwatchedList.add(socketB, FOR_READ)\nwatchedList.add(pipeA, FOR_READ) // [1]\n\nwhile(events = demultiplexer.watch(watchedList)) { // [2]\n  // event loop\n  foreach (event in events) { // [3]\n    // this read operation won't never block\n    // and we will always return data\n    data = event.resource.read()\n    if (data === RESOUCE_CLOSED) {\n      // remove from watched list\n      demultiplexer.unwatch(event.resource)\n    } else {\n      // data was received, proceed it\n      consumeData(data)\n    }\n  }\n}\n\nThe resources was added to a data structure, associated with specific operation\nThe event notifier is set up with the group of resources to be watched. This call is synchronous and blocks until any of watched resource is ready for read operation. When the resource is ready for an operation the event demultiplexer returns from the call new set of events.\nEach event is proceed. At this point, the resource associated with each event is guaranteed to be ready to processing and not to block during the operation. When all events are processed, the flow will be blocked again on the event demultiplexer until new events are again available to be proceed.\n\n This is called the event loop\n\nIt's interesting that with this pattern, we can now handle several I/O operation inside a single thread. How web-server will handle multiple requests using synchronous event demultiplexer with single thread:\n\n{% image fancybox center images/webserver-event-demultiplexer.png %}\n\nThe reactor pattern\n\nThe main idea behind it is to have a handler (which in Node.js is represented by callback function) associated with each I/O operation, which will be invoked as soon as an event is produces and processed by event loop:\n\n{% image fancybox center images/reactor-pattern.png %}\n\nWhat's happen when application use the reactor patter:\n\nThe application generates a new I/O operation by submitting a request to event demultiplexer. Also application specified a handler, which will be invoked when the operation is completes. Submitting a new request is non-blocking call and it immediately returns control to the application\nWhen set of I/O operation completes, the event demultiplexer pushes the new events into the event loop\nAt this point, event loop iterates over the items of the event queue\nFor each event, the associated handler is invoked\n* (a) The handler which is a part of application code, will give control to event loop when it's execution completes.\n  (b) However, new asynchronous operation might be requested during the execution of handler, causing new operation to registered in the event demultiplexer, before control is given back to event loop\nWhen all items are processed in event queue, the loop will blocked again on event demultiplexer which will trigger another cycle of when a new events are available\n\nA Node.js application will exit automatically when there are no more pending operation in event demultiplexer and no more events to be processed in event queue\n\n Pattern Reactor handles I/O by blocking until new events are available from a set of observable resources and then reacts by dispatching each event with associated handler.\n\n The non-blocking I/O engine of Node.js-libuv\n\nEach operation system has its own interface for the event demultiplexer. Besides that, each I/O operation can behave quite differently depending on type of resource, even within the same OS. All this inconsistencies required a higher abstraction for event demultiplexer.\n\nThis is exactly why Node.js core created a C library called libuv with objective to make Node.js compatible with all the major platform and normalize the non-blocking behavior of the different types of resource.\n\nThe building blocks of Node.js platform\n\nThe reactor pattern and libuv are the basic building blocks but we need the following three other components to build the full platform:\n\na set of bindings responsible for wrapping and expose libuv and other low-level functionality to Javascript\nV8 the Javascript engine, this one of the reason why Node.js is so fast and efficient\na node-core that implements the high-level Node.js API\n\n{% image fancybox center images/building-nodejs-blocks.png %}\n\n Chapter 2: Node.js essential patterns\n\nIn this chapter, we'll use two of the most important asynchronous patterns: callback and event-emitter\n\nThe callback pattern\n\nCallbacks are materialization of the handlers of the reactor pattern. Callback is a function that is invoked to propagate the result of an operation and this is exactly what we need when we dealing with asynchronous operation. Another ideal construct for implementing callbacks is closure\n\n The continue-passing style\n\n In Javascript, a callback is a function that is passed as an argument to another function and is invoked with the result when operation is complete.\n\nMeanwhile,\n\n in function programming, this way of propagating the result is called continuation-passing style (CPS)\n\nTo clarify the concept lets see a direct style:\n\nfunction add(a, b) {\n  return a + b;\n}\n\nThe equivalent continue-passing style would be as follow:\n\nfunction add(a, b, callback) {\n  callback(a + b);\n}\n\nSince add() is a synchronous CPS function the result will be:\n\nconsole.log('before');\nadd(1, 2, result = console.log(Result ${result}));\nconsole.log('after');\n\n// before\n// Result 3\n// after\n\nAsynchronous continue-passing style\n\nLets consider a case where the add() function is asynchronous:\n\nfunction addAsync(a, b, callback) {\n  setTimeout(callback(a + b));\n}\n\nconsole.log('before');\naddAsync(1, 2, result = console.log(Result ${result}));\nconsole.log('after');\n\n// before\n// after\n// Result 3\n\nSince setTimeout() triggers an asynchronous operation, it won't wait for the callback to be executed, but instead, it returns immediately, giving control back to addAsync() and then back to its caller. This is crucial and following image shows how it works:\n\n{% image fancybox center images/async-cps-in-action.png %}\n\nThe execution will start from the event loop so it will have a fresh stack. Thanks to closure it's trivial to maintain the context of the caller in asynchronous function.\n\n Synchronous or asynchronous? \n \nThe following is an analysis of these two paradigms and their pitfalls.\n\nAn unpredictable function\n\nOne of the most dangerous situation is to have API that behaves synchronously under certain conditions and asynchronous under others:\n\nconst fs = require('fs');\nconst cache = {};\n\nfunction inconsistentRead(filename, callback) {\n  if (cache[filename]) {\n    // invoked synchronously\n    callback(cache[filename]);\n  } else {\n    // async call\n    fs.readFile(filename, 'utf8', (err, data) = {\n      cache[filename] = data;\n      callback(data);\n    })\n  }\n}\n\n Unleashing Zalgo\n\nNow lets see how to use an unpredictable function, such as to easily break an application:\n\nfunction createFileReader(filename) {\n  const listeners = [];\n\n  incosistentRead(filename, value = {\n    listeners.forEach(listener = listener(value));\n  })\n\n  return {\n    onDateReady: listener = listeners.push(listener)\n  }\n}\n\nWhen the preceding function is invoked, it creates a new object that acts as notifier, allowing us to set multiple listeners for a file read operation. All listeners will be invoked at once when the read operation completes and the data is available:\n\nconst reader1 = createFileReader('data.txt');\n\nreader1.onDateReady(data = {\n  console.log(First data call ready: ${data});\n\n  // same time letter we try to read the same file again\n  const reader2 = createFileReader('data.txt');\n\n  reader2.onDateReady(data = {\n    console.log(Second data call ready: ${data});\n  })\n})\n\nThe result output is: \n\nFirst data call ready: foo bar here!\n\nYou can see the callback of the second operation is never invoked. Lets see why:\n\nDuring the creation of reader1, our inconsistentRead() function behaves asynchronously, because there isn't cached result. Therefore, we have all time in the world to register our listener, as it will invoked later in another cycle of event loop, when the read operation is complete.\nThen the reader2 is created when requested file is in the cache. In this case the inner call of inconsistentRead() will be synchronous. So its call back will be invoked immediately, which mean that listener of reader2 will be invoked synchronously as well. However, we registering the listeners after creation of reader2, so they will never be invoked!\n\nUsing synchronous APIs\n\nOne suitable fix for our inconsistentRead() function is to make it totally synchronous:\n\nconst fs = require('fs');\nconst cache = {};\n\nfunction consistentRead(filename) {\n  if (cache[filename]) {\n    return cache[filename];\n  }\n  cache[filename] = fs.readFileSync(filename, 'utf8');\n  return cache[filename];\n}\n\nThere is no reason for a function to have a continue-passing style it's synchronous. In fact, it's always a best practice to implement synchronous API using a direct style.\n\n Pattern:\n Prefer direct style for purely synchronous function\n\nBear in mind, that changing an API from CPS to a direct style (from asynchronous to synchronous or vice versa) require a change of style of all code using:\n\nfunction createFileReader(filename) {\n  const listeners = [];\n  const fileData = consistentRead(filename)\n\n  return {\n    onDateReady: listener = {\n      listeners.push(listener);\n      listeners.forEach(listener = listener(fileData));\n    }\n  }\n}\n\n Using asynchronous operation with deferred execution\n\nThe trick here is to schedule the synchronous callback invocation to be executed \"in the future\", instead of being run immediately in the same event loop cycle. In Node.js this is possible using process.nextTick(), which defers the execution of a function until next the event loop cycle. This function is a very simple, it takes a callback and pushes it to the top of event queue, in front of any pending I/O event, and returns control immediately. So callback will run be invoked as soon as the event loop runs again.\n\nApply this technique to fix inconsistentRead():\n\nconst fs = require('fs');\nconst cache = {};\n\nfunction inconsistentRead(filename, callback) {\n  if (cache[filename]) {\n    // now invoked asynchronously\n    process.nextTick(() = callback(cache[filename]));\n  } else {\n    // async call\n    fs.readFile(filename, 'utf8', (err, data) = {\n      cache[filename] = data;\n      callback(data);\n    })\n  }\n}\n\nNow, our function is guaranteed to invoke its callback asynchronous, under any circumstances.\n\nAnother API for deferring the execution is setImmediate(). While their purposes are very similar, their semantics are quite different. Callback deferred with process.nextTick() run before any other I/O event fired, while with setImmediate(), the execution is queued behind any I/O event that is already in the queue. Since process.nextTick() runs before any already scheduled I/O, it might cause I/O starvation under certain circumstances, for example, a recursive invocation, this can never happen with setImmediate()\n\n Pattern:\n We guarantee that a callback is invoked asynchronously be deferring it execution using process.nextTick()\n\nNode.js callback convention\n\nCPS APIs and callbacks follows a set of specific convention.\n\n Callback come last\n\nIn all core Node.js methods, the standard convention is that when a function accept callback as input, this has to be passed as last parameter:\n\nfs.readFile(filename[, options], callback)\n\nError comes first\n\nIn Node.js, any errors produced by a CPS function is always passed as first argument of the callback, and any actual result is passed starting from the second argument. It the operation is succeeds without errors, the first error will be null or undefined:\n\nfs.readFile('foo.txt', 'utf8', (err, data) = {\n  if (err) {\n    handleError(err);\n  } else {\n    handleData(data);\n  }\n})\n\n Propagation errors\n\nPropagation errors in synchronous, direct function is done with well-known throw statement.\n\nIn CPS style however, proper propagation is done by passing the error to the next callback in the chain:\n\nfunction readJson(filename, callback) {\n  fs.readFile(filename, 'utf8', (err, data) = {\n    let parsed;\n    if (err) {\n      // propagate the error and exit\n      return callback(err);\n    }\n\n    try {\n      parsed = JSON.parse(data);\n    } catch(err) {\n      // catch parsing error\n      return callback(err);\n    }\n\n    // no error propagate just data\n    callback(null, parsed);\n  })\n}\n\nThe module system and its pattern\n\nModules are bricks for structuring non-trivial application, but also the main mechanism to enforce hiding information by keeping private all the function and variable that are not explicitly marked to be exported.\n\n The revealing module pattern\n\nOnce of the major problem in Javascript is an absence of namespacing. A popular technique to solve this issue is called the revealing module pattern: \n\nconst module = (() = {\n  const privateFoo = () = {};\n  const privateBar = [];\n\n  const exported = {\n    publicFoo: 'dataFoo',\n    publicBar: 'dataBar',\n  }\n\n  return export\n}())\n\nWe have a private scope and exporting only the parts that are meant to be public. As we'll see at the moment, the idea behind this pattern is used as a base for a Node.js module system.\n\nNode.js modules explained\n\nCommonJS is a group with the aim to standardize the Javascript ecosystem, and one of their most popular proposal is CommonJS module system. Node.js built its module system on the top of this specification, with the addition of some custom extensions.\n\n A homemade module loader\n\nTo explain how Node.js modules work let's built a similar system from scratch. The code mimics a subset of functionality of original require:\n\nfunction loadModule(filename, module, require) {\n  const wrappedSrc = `function(module, module, require) {\n    ${fs.readFileSync(filename, 'utf8')}\n  }(module, module.exports, require)`;\n\n  eval(wrappedSrc);\n}\n\nBear in mind, that this code is only for example, feature such as eval() or vm module can be easily used in a wrong way or with a wrong input to inject attack. They should be used always with extreme care.\n\nNow implementation of our require() function:\n\nfunction require(moduleName) {\n  console.log(Require invoked for module: ${moduleName});\n  const id = require.resolve(moduleName); // [1]\n\n  if (require.cache[id]) { // [2]\n    return require.cache[id].exports;\n  }\n\n  // module metadata\n  const module = { // [3]\n    exports: {},\n    id\n  };\n  // update the cache\n  require.cache[id] = module; // [4]\n\n  // load the module\n  loadModule(id, module, require); // [5]\n\n  // return exported variables\n  return module.exports; // [6]\n}\n\nrequire.cache = {};\nrequire.resolve = function(moduleName) {\n  // resolve a full module id from the moduleName\n}\n\nWhat our homemade module system does is explain as follows:\n\nModule name is accepted as input, and the very first thing that we do is resolve the full path of module, and receive module id. It's implementing by special resolving algorithm of require.resolve()\nIf the module has already been loaded it should be available in the cache.\nIf the module hasn't loaded yet, we set up environment for the first load. The property module.exports will be used to export public API.\nThe module object is cached.\nThe loadModule() code reads from its file, and the code is evaluated. We provide the module with module object that we just created, and a reference to require() function. The module exports its public API by manipulation or replacing the module.exports object.\nFinally the content of module.exports is returned from caller.\n\nDefining a modules\n\nBy looking how us require() works be are able to define a module:\n\n// module.js\n// load another module-dependency\nconst dependency = require('./anotherModule');\n\n// private section\nfunction privateFoo() {}\n\n// the exported API\nmodule.exports.run = function publicBar() {\n  privateFoo()\n}\n\nThe essential concept to remember that everything in the module is private unless it's assigned to module.exports\n\n Defining globals \n\nIt's still possible to define a global variable, in fact, module system exposes a special variable global, which can be used for this purpose\n\n\"module.exports\" VS \"exports\"\n\nA common source of confusion is the difference between using module.exports and exports to expose the public API. The code of our custom require function should again clear any doubts.\n\nThe variable exports is just a reference to initial value of module.exports, essentially it's an empty object before the module is loaded. This means that we can only attach new properties referencing by exports variable:\n\nexports.hello = () = { console.log('Hello') };\n\nReassigning the exports variable doesn't have any sense, because it doesn't change content of module.exports. That's how object in Javascript works. The following code therefore is wrong:\n\nexports.hello = () = { console.log('Hello') };\n\nIf we want to export something other than an object literal, we can reassigning module.exports as follow:\n\nmodule.exports = () = { console.log('Hello') };\n\n The \"require\" function is synchronous\n\nWe should take into account that our homemade require is synchronous. In fact, it returns the module contents using simple direct style therefore no callback is required. This is true for original Node.js require function too. As a consequence any assignments to module.exports must be synchronous. The following code is incorrect:\n\nsetTimeout(() = {\n  module.exports = () = {}\n}, 100);\n\nThis is one of the important reasons why Node.js libraries offer synchronous APIs as alternative to asynchronous ones.\n\nThe resolving algorithm\n\nNode.js solver the dependency hell elegantly by loading different version of module depending on where the module is loaded from. As we saw the resolve() function takes a module name (moduleName in our loader) as input, and it returns the full path of module. This path is used to load its code and to identify the module uniquely.\n\nThe resolving algorithm can be divided into the following three major branches:\nfile modules\ncore modules\npackage modules\n\nThe resolving algorithm can be be found at official spec.\n\nThe node_modules directory is where npm installs the dependencies of each package. Based on the algorithm, each package can have its own private dependencies. Consider the following structure:\n\nmyApp\n├── foo.js\n└── node_modules\n    ├── depA\n    │   └── index.js\n    ├── depB\n    │   ├── bar.js\n    │   └── node_modules\n    │       └── depA\n    │           └── index.js\n    └── depC\n        ├── foobar.js\n        └── node_modules\n            └── depA\n            └── index.js\n\nFollowing rules of resolving algorithm, using require('depA') will load a different file depending on the module that requires it:\n\nCalling require('depA') from /myApp/foo.js will load /myApp/node_modules/depA/index.js\nCalling require('depA') from /myApp/nodemodules/depB/bar.js will load /myApp/nodemodules/depB/node_modules/depA/index.js\nCalling require('depA') from /myApp/nodemodules/depC/foobar.js will load /myApp/nodemodules/depc/node_modules/depA/index.js\n\n The module cache\n\nEach module is only loaded and evaluated the first time it's required, since any subsequent call of require() will return the cached version. Again, it should be clear by looking at the code of homemade require() function.\n\nThe module cache is exposed via the require.cache reference, so it's possible to directly access it if needed.\n\nModule definition patterns\n\nThe module system besides being a mechanism for loading dependencies, is also a tool for defining APIs. To aim is to maximize information hading and API usability, with balancing with other software quality such as code reuse and extensibility.\n\n Named exports\n\nThe most basic method for exposing public API is using named exports, which consist to assignment all the public values to object referenced by exports or module.exports. Most of the Node.js core modules use this pattern.\n\n// file logger.js\nexports.info = (msg) = {\n  console.log(info: ${msg})\n};\n\nexports.verbose = (msg) = {\n  console.log(verbose: ${msg})\n};\n\n// file main.js\nconst logger = require('./logger');\n\nlogger.info('Info massage');\nlogger.verbose('Verbose massage');\n\nExporting a function\n\nOne of the most popular module definition pattern consists of reassigning of the whole module.exports variable to the function. The main goal to provide a clear entry point for the module, making it simpler to understand and use. It also honors the principle of small area surface. This way of defining modules also is known as the substack pattern.\n\n// file logger.js\nmodule.exports = (msg) = {\n  console.log(info: ${msg})\n};\n\nA possible extension for this pattern is using the exported function as namespace for other public APIs. This is a very powerful technique, because it still gives clarity of a single entry point.\n\n// the same file logger.js\nmodule.exports.verbose = (msg) = {\n  console.log(verbose: ${msg})\n};\n\n// file main.js\nconst logger = require('./logger');\n\nlogger('Info massage');\nlogger.verbose('Verbose massage');\n\n Pattern:\n Substack or Single Responsibility Principle (SRP)\n Expose the main functionality of a module by exporting only one function. Use the exported function as a namespace to expose any auxiliary functionality\n\n Exporting a constructor\n\nThe difference is with this approach we allow user to create a new instance using the constructor with ability to extend its prototype and forge new classes.\n\n// file logger.js\nclass Logger {\n  constructor(name) {\n    this.name = name;\n  }\n\n  log(msg) {\n    console.log([${this.name}] ${msg})\n  }\n\n  info(msg) {\n    console.log(info: ${msg})\n  }\n\n  verbose(msg) {\n    console.log(info: ${msg})\n  }\n}\n\nmodule.exports = Logger;\n\nA variation of this pattern consists of applying a security check against invocation that doesn't use new directive. This a little trick allows us to use our module as factory:\n\nfunction LoggerFactory(name) {\n  if (!this instanceof Logger) {\n    return new Logger(name)\n  }\n  return new Logger(name);\n}\n\nA much cleaner approach is offered by ES6 new.targer which is available starting from Node.js v6. The syntax expose the new.targer which is called meta property, made available inside all the function, end evaluates to true at runtime if the function was called using the new directive.\n\nfunction LoggerFactory(name) {\n  if (!new.target) {\n    return new Logger(name);\n  }\n  return new Logger(name);\n}\n\nExporting an instance\n\nWe can leverage the caching mechanism of require() to define stateful instance with a state created from a constructor or factory, shared across different modules:\n\n// file logger.js\nclass Logger {\n  constructor(name) {\n    this.name = name;\n    this.count = 0;\n  }\n\n  log(msg) {\n    this.count++;\n    console.log([${this.name}] ${msg})\n  }\n}\n\nmodule.exports = new Logger('default');\n\n// file main.js\nconst logger = require('./logger.js');\nlogger.log('test the singleton');\n\nThis is much like a singleton pattern, however it doesn't guarantee the uniqueness of the instance across the whole application, as it happens with traditional singleton pattern. When analyzing the resolving algorithm, we have seen in fact, that a module might be installed multiple times inside the dependency tree of an application.\n\n Modifying other modules or the global scope\n\nA module can even export nothing. We should not forger that module can modify the global scope and the object in it, including other modules in the cache. In general it's considering as a bad practice.\n\n Pattern:\n Monkey patching is when module can modify other modules or object in global scope. It change the existing objects at runtime to change or extend their behavior or apply temporary fixes\n\nHow we can add a new function to another module:\n\n// file patcher.js\nrequire('./logger').customMessage = () = console.log('this is a new functionality');\n\n// main.js\nrequire('./patcher');\n\nconst logger = require('./logger');\nlogger.customMessage();\n\nThe technique is dangerous, because it affects the state of entire app.\n\nThe observer pattern\n\nTogether with the reactor, callbacks and modules, the observer pattern is one of the pillars of the platform and is used by mane Node.js core and user-land modules.\n\n Pattern Observer:\n Defines an object (subject), which can notify a set of observers (listeners) when change is occur.\n\nThe main difference from the callback pattern is that the subject can notify multiple observers, while a traditional CPS will propagate its result to only one listener, the callback.\n\n The EventEmitter class\n\nThe observer pattern built into core and it's available through the EventEmitter class. It allows to register one or multiple function as listeners, which will be notified when a particular event type is fired. The following explains the concept:\n\n{% image fancybox center images/event-emitter.png %}\n\nHow to require EventEmitter from core events module:\n\nconst EventEmitter = require('events');\nconst eeInstance = new EventEmitter;\n\nThe API is in official Node.js specification.\n\nWe can already see that there is a big difference between a listener and a traditional Node.js callback, in particular, the first argument isn't an error, but any data which is passed to emit() at the moment of invocation.\n\nCreating and using EventEmitter\n\nThe following code shows a function that uses EventEmitter to notify its subscribers in real time when a particular pattern is found in a list of files:\n\nconst EventEmitter = require('events');\nconst fs = require('fs');\n\nfunction findPattern(files, regexp) {\n  const emitter = new EventEmitter;\n\n  files.forEach(file = {\n    fs.readFile(file, 'utf8', (err, content) = {\n      let match;\n\n      if (err) {\n        emitter.emit('error', err);\n      }\n\n      emitter.emit('fileread', file); \n\n      if (match = content.match(regexp)) {\n        match.forEach(elem = emitter.emit('found', file, elem))        \n      }\n    })\n  })\n\n  return emitter;\n}\n\nLets see how findPattern can be used:\n\nfindPattern(\n  ['data1.txt', 'data2.txt'],\n  /foo \\w+/g\n)\n  .on('fileread', file = console.log(${file} was read))\n  .on('found', (file, match) = console.log(matched ${match} in file ${file}))\n  .on('error', err = console.log(Error: ${err}))\n\n Extends from EventEmitter class\n\nTo demonstrate the pattern lets implement the functionality of the findPattern():\n\nconst EventEmitter = require('events');\nconst fs = require('fs');\n\nclass FindPattern extends EventEmitter {\n  constructor(regexp) {\n    super();\n    this.regexp = regexp;\n    this.files = [];\n  }\n\n  addFile(file) {\n    this.files.push(file);\n\n    return this;\n  }\n\n  find() {\n    this.files.forEach(file = {\n      fs.readFile(file, 'utf8', (err, content) = {\n        let match;\n\n        if (err) {\n          this.emit('error', err);\n        }\n\n        this.emit('fileread', content); \n\n        if (match = content.match(this.regexp)) {\n          match.forEach(elem = this.emit('found', file, elem); )        \n        }\n      })\n    })\n    return this;\n  }\n}\n\nThe FindPattern prototype extends EventEmitter. In this way it becomes a fully-fledged observable class. The usage:\n\nconst findPatternObj = new FindPattern(/hello \\w+/g);\n\nfindPatternObj\n  .addFile('data1.txt')\n  .addFile('data2.txt')\n  .on('fileread', file = console.log(${file} was read))\n  .on('found', (file, match) = console.log(matched ${match} in file ${file}))\n  .on('error', err = console.log(Error: ${err}))\n\nThis is a pretty common pattern in the Node.js ecosystem, for example, the Server object of the core HTTP module defines methods such as listen(), close(), setTimeout() and internally it inherits from the EventEmitter function. It allows to produce events such as request when a new connection is received, or connection when a new connection is established, or close when server is shut down.\n\nCombining callbacks with EventEmitter\n\nThere are also circumstances where EventEmitter can be combining with a callback. One example of this pattern is offered by the node-glob module, which performs a glob-style searching. The function glob(pattern, [options], callback) takes a callback that is invoked with the list of all files which are matched by the providing pattern. At the same time it returns EventEmitter that provides an interface to report over the state of the process:\n\nconst glob = require('glob');\n\nglob('*.txt', (err, files) = console.log(Founded files: ${JSON.stringify(files)}))\n  .on('match', match = console.log(Matched files: ${match}))\n\n Chapter 3: Asynchronous control flow patterns with callbacks\n\nOne of the common mistake is to fail into the trap of the callback hell and see how the code is growing horizontally rather than vertically, with the nesting which makes even simple routine hard to read and maintain.\n\nIn this chapter we we'll see how it's actually possible to tame callbacks and write clean, manageable asynchronous code with the aid of some patterns.\n\nCreating a simple web spider\n\nTo explain the problem we'll create a little CLI application that takes a web URL as input and downloads its contents locally into file.\n\n// file spider.js\nconst fs = require('fs');\nconst path = require('path');\nconst request = require('request'); // HTTP request client\nconst mkdirp = require('mkdirp'); // Recursively mkdir, like mkdir -p\nconst chalk = require('chalk'); // Terminal string styling done right.\n\nconst utils = require('./utils');\n\nfunction spider(url, cb) {\n  const filePath = utils.urlToFilePath(url);\n  const fileName = utils.urlToFileName(url);\n  let isFileExists = false;\n\n  fs.stat(filePath, (err, stats) = { // [1]\n    if (stats) {\n      cb(null, fileName, isFileExists = true);\n    } else {\n      request(url, (err, response, body) = { // [2]\n        if (err) {\n          cb(err);\n        } else {\n          mkdirp(filePath, err = { // [3]\n            if (err) {\n              cb(err);\n            } else {\n              fs.writeFile(path.join(filePath, fileName), body, err = { // [3]\n                if (err) {\n                  cb(err);\n                } else {\n                  cb(null, fileName, isFileExists);\n                }\n              })\n            }\n          })\n        }\n      })\n    }\n  })\n}\n\nspider(process.argv[2], (err, fileName, fileExists) = {\n  if (err) {\n    console.log(chalk.red(Error: ${err}));\n  } else if (fileExists) {\n    console.log(chalk.blue(File: ${fileName} exists));\n  } else {\n    console.log(chalk.green(File: ${fileName} is downloaded));\n\n  }\n})\n\n// file utils.js\n/*\nConverts urls to simplified strings\n*/\nconst slugifyUrl = require('slugify-url');\n\nexports.urlToFilePath = urlToFilePath;\nexports.urlToFileName = urlToFileName;\n\nfunction urlToFilePath(url) { // http://example.com/bar\n  const slashChar = '/';\n\n  return slugifyUrl(url, { slashChar }); // example.com/bar\n}\n\nfunction urlToFileName(url) { // http://example.com/bar\n  const slashChar = '/';\n  const parsedUrl = slugifyUrl(url, { slashChar }).split('/');\n\n  return parsedUrl[parsedUrl.length - 1]; // bar\n}\n\nThe preceding functions execute the following tasks:\n\nCheck if the URL was already downloaded by verifying that corresponding file hasn't already created.\nIf the file is not found, it would download content of provided URL\nThen it creates recursively directories\nFinally, it writes the body of HTTP response to file system\n\n The callback hell\n\nWe can surely notice that even though the algorithm was straightforward, the resulting code has several level of indentation and it's very hard to read. Implementing a similar function in direct style would more straightforward, and it would be very few chances to make it look so wrong. However, using CPS is another story, and making bad use of closure may lead to to incredible bad code.\n\nThat's known as callback hell or piramid of domm. The typical structure of code affected by the problem looks like the following:\n\nasyncFoo(err = {\n  asyncBar(err2 = {\n    asyncFooBar(err3 = {\n      // ...\n    })\n  })\n})\n\nAnother problem is caused by overlapping of the variable names used in each scope. Some people try to avoid it with variation of variables error, err, err2.\n\nAlso we should keep in mind that closure can create memory leaks that are not so easy to identify. We shouldn't forget that any context referenced by an active closure is retained from garbage collector.\n\nApplying the callback discipline\n\nBasic principles that can help to keep the nesting level low and improve the organization of our code in general:\n\nyou must exit as soon as possible. Use return, continue or break, depending on context to immediately exit the current statement\ncreate a named function for callbacks. Will keep our code shallow and better look for stack trace\nmodularize the code. Create a small, reusable function whenever it's possible\n\nAfter applying the following recommendation our spider() would look as following:\n\nfunction spider(url, cb) {\n  const filePath = utils.urlToFilePath(url);\n  const fileName = utils.urlToFileName(url);\n  let isFileExists = false;\n\n  fs.stat(filePath, (err, stats) = {\n    if (stats) {\n      return cb(null, fileName, isFileExists = true); // [!]\n    }\n    download(url, filePath, fileName, isFileExists, cb);\n  })\n}\n\nfunction download(url, filePath, fileName, isFileExists, cb) {\n  request(url, (err, response, body) = {\n    if (err) {\n      return cb(err); // [!]\n    } else {\n      saveFile(filePath, fileName, body, isFileExists, cb); // [!]\n    }\n  })\n}\n\nfunction saveFile(filePath, fileName, content, isFileExists, cb) {\n  mkdirp(filePath, err = {\n    if (err) {\n      return cb(err); // [!]\n    } else {\n      writeContent(filePath, fileName, content, isFileExists, cb);\n    }\n  })\n}\n\nfunction writeContent(filePath, fileName, content, isFileExists, cb) {\n  fs.writeFile(path.join(filePath, fileName), content, err = {\n    if (err) {\n      return cb(err); // [!]\n    } else {\n      return cb(null, fileName, isFileExists); // [!]\n    }\n  })\n}\n\n Sequential execution\n \nExecuting a set of task in sequence means running them one at time, one ofter other. The order of execution matters. The concept:\n\n{% image fancybox center images/sequential-execution.png %}\n\nThere are different variation of this flow:\n\nexecution a set of known task in sequence, without chaining and propagate the result\nusing output of task as the input to the next task, also known as chain, pipe, or waterfall\niterating over a collection while running an asynchronous task on each element, one ofter other\n\nExecution a set of known task in sequence\n\nWe've already met a sequential execution while implementing the spider() function. Taking that code as guideline we can generalize the solution into the following pattern:\n\nfunction task1(cb) {\n  asyncOperation(() = task2(cb))\n}\n\nfunction task2(cb) {\n  asyncOperation(() = task3(cb))\n}\n\nfunction task3(cb) {\n  asyncOperation(() = cb()) // finally executes the callback\n}\n\nfunction asyncOperation(cb) { // emulates asynchronous operation\n  setTimeout(() = cb());\n}\n\ntask1(() = console.log('task 1, 2 and 3 executed'));\n Sequential iteration with crawling of links\n\nWhat if we want to invoke an asynchronous operation for each file in a collection?\n\nWith new feature, downloading all the links contained in the web-page recursively. To do that, we are going to extract all links from the page and than trigger our web spider on each of them recursively and in sequence.\n\nThe new version of spider() is as following:\n\nfunction spider(url, nesting, callback) {\n  const filename = utilities.urlToFilename(url);\n  fs.readFile(filename, 'utf8', (err, body) = {\n    if(err) {\n      if(err.code ! == 'ENOENT') {\n        return callback(err);\n      } \n      return download(url, filename, (err, body) = {\n        if(err) {\n          return callback(err);\n        }\n        spiderLinks(url, body, nesting, callback);\n      });\n    }\n\n    spiderLinks(url, body, nesting, callback);\n  });\n}\n\nfunction spiderLink(url, body, nesting, cb) {\n  if (nesting === 0) {\n    return process.nextTick(cb);\n  }\n  // require('get-urls')\n  const links = utils.getUrls(body); // [1]\n\n  function iterate(index) { // [2]\n    if (index === links.length) {\n      return cb();\n    }\n\n    spider(links[index], nesting - 1, err = { // [3]\n      if (err) {\n        return cb(err);\n      }\n      iterate(index - 1);\n    })\n  }\n  iterate(0); // [4]\n}\n\nThe important steps to understand:\n\nObtain the list of all links on the page using the utils.getUrls(). This links should return only with the same hostname\nIterate through links via local function iterate(). The first thing it checks if the index is equal to the length of links, in which case it immediately invokes the cb() as it means it proceeds all items\nAt this point everything is ready to processing the links. It invokes the spider() function by decreasing the nesting level and invoking the next step of iteration then the operation is complete\nIt's a bootstrapping the iteration by iterate(0)\n\nThe pattern \"sequential iteration\" \n\nIt can be generalize as follow:\n\nfunction iterate(index) {\n  if (index === tasks.length) {\n    return finish();\n  }\n\n  const task = tasks[index];\n  task(function() {\n    iterate(index + 1);\n  })\n}\n\nfunction finish() {\n  // iteration completed\n}\n\niterate(0);\n\nIt's important to notice that these type of algorithm become really recursive if task() is an asynchronous operation. In such a case there might be a risk of hitting the maximum call stack limit.\n\n Pattern sequential iterator:\n execute a list of tasks in sequence by creating a function iterate() which invokes the next available task in the collection and makes sure to invoke next step of iteration when the current task is completed\n\n Parallel execution \n\nThere is some situation when the order of execution of the set of asynchronous tasks is not important and we want just to be notified when all these running tasks are completed.\n\n{% image fancybox center images/parallel-execution.png %}\n\nWe realize that even thought we have one thread we can still achieve concurrency, thanks to not-blocking nature of Node.js. In fact, the word parallel is used improperly in this case, as it doesn't mean that the task run simultaneously, but rather their execution is carried out by an underlying non-blocking API and invoked by the event loop.\n\nAs we know, a task gives control back to the event loop when it request a new asynchronous operation, allowing the event loop to execute another task. The proper word is to use for this kind of flow is concurrency, but we still use parallel for simplicity sake.\n\nConcurrency vs Parallelism\n\nThe following diagram shows how two asynchronous tasks can run in parallel in a Node.js program:\n\n{% image fancybox center images/parallel-execution-diagram.png %}\n\nWe have Main function that executes two asynchronous tasks:\n\nThe Main function triggers the execution of Task1 and Task2. As they are asynchronous operations the immediately return control to Main, which then returns to event loop\nWhen the asynchronous operation of Task1 is completed, the event loop gives control to it. When task1 completes the internal synchronous operation processing as well, it notifies the Main\nThe same as described in p2 but now with event loop triggers the Task2. At this point Main function knows that Task1 and Task2 are completed, so it can continue the execution or return the result of the operation to another callback.\n\nExecution with \"spiderLinks\"\n\nSo far application is executing the recursive download of the linked pages in a sequential fashion. We can easily improve performance of this process by downloading all the linked pages in parallel:\n\nfunction spiderLink(url, body, nesting, cb) {\n  if (nesting === 0) {\n    return process.nextTick(cb);\n  }\n  const links = utils.getUrls(body);\n\n  if (links.length === 0) {\n    return process.nextTick(cb)\n  }\n\n  let completed = 0;\n  let hasErrors = false;\n\n  function done(err) {\n    if (err) {\n      hasErrors = true;\n      return cb(err);\n    }\n    if (++completed === links.length && !hasErrors) {\n      return cb()\n    }\n  }\n\n  links.forEach(link = {\n    spider(link, nesting - 1, done);\n  })\n}\n\nThe trick to make our application to wait for all the task to complete is to invoke the spider() with a special callback done(). The done() increases a counter when a spider() task completes. When the number of completed downloads reaches the size of links[], the final callback is invoked.\n\n The pattern \"unlimited parallel execution\"\n\nWe can represent a generic version of the pattern:\n\nconst tasks = [ /.../ ];\nlet completed = 0;\n\ntasks.forEach(task = {\n  task(() = {\n    if (++competed === tasks.length) {\n      finish();  \n    }\n  })\n})\n\nfunction finish() {\n  // all tasks are completed\n}\n\n Pattern unlimited parallel execution\n Run a set of asynchronous tasks in parallel by spawning them all at once, and then waiting for all of them to complete by counting the number of the times their callback are invoked\n\nLimited parallel execution\n\nImagine having thousands of files to read, URLs to access, or DB queries run in parallel. A common problem in such situation is running out of memory. In all such situation its a good idea to limit the number of tasks that can run in the same time. The following diagram show a situation where we have five tasks that run in parallel with an concurrency limit of 2:\n\n{% image fancybox center images/concurency-limit.png %}\n\nThe algorithm to execute a set of given tasks in parallel with limited concurrency:\n\nconst tasks = [ /.../ ];\nlet concurrency = 0;\nlet running = 0;\nlet completed = 0;\nlet index = 0;\n\nfunction next() {\n  while(running < concurrency && index < tasks.length) {\n    const task = tasks[index];\n\n    running++;\n    task(() = {\n      if (completed === tasks.length) {\n        return finish();\n      }\n      completed++;\n      running--;\n      next();\n    })\n  }\n}\n\nnext();\n\nfunction finish() {\n  // all tasks are completed\n}\n\n \"TaskQueue\" to rescue\n\nWe are now going to implement a simple class which will combine a queue algorithm we presented before:\n\nclass TaskQueue {\n  constructor(concurrency) {\n    this.concurrency = concurrency;\n    this.running = 0;\n    this.queue = [];\n  }\n\n  pushTask(taks) {\n    this.queue.push(task);\n    this.next();\n  }\n\n  next() {\n    while(this.running < this.concurrency && this.queue.length) {\n      const task = this.queue.shift();\n\n      this.running++;\n      task(() = {\n        this.running--;\n        this.next();\n      })\n    }\n  }\n}\n\nNow we can update our spiderLink() to execute tasks in a limited parallel flow:\n\nconst TaskQueue = require('./task-queue');\nconst downloadQueue = new TaskQueue(2);\n\nfunction spiderLink(url, body, nesting, cb) {\n  if (nesting === 0) {\n    return process.nextTick(cb);\n  }\n  const links = utils.getUrls(body);\n\n  if (links.length === 0) {\n    return process.nextTick(cb)\n  }\n\n  let completed = 0;\n  let hasErrors = false;\n\n  links.forEach(link = {\n    downloadQueue.pushTask(done = {\n      spider(link, nesting - 1, done);\n    })\n  })\n}\n\nChapter 4: Asynchronous Control Flow with ES6 and beyond\n\nWe are going to explore some of the most famous alternatives, promises, generators and an innovative syntax of ES7 the async await.\n\nHistorically, there have been many different implementation of promise libraries, and most of them aren't compatible between each other. The JS community worked hard to sort out this limitation and these efforts leads to creation of Promise/A+ spec.\n\nThe several poplar libraries which implement the Promise/A+ spec:\n\nBluebird\nQ\nRSVP\nWhen.js\nES6 promises\n\n ES6 Promises techniques\nPromisifying a Node.js style function\n\nIn JS not all the asynchronous functions and libraries support promises out-of-box. We can convert a typical callback-based function into one that returns a promise, this process is also known as promisification:\n\nmodule.exports.promisify = function(fn) {\n  return function promisified(...callArgs) {\n    return new Promise((resolve, reject) = { //[1]\n      callArgs.push((err, result, ...restResults) = { //[2]\n        if (err) {\n          return reject(err); //[3]\n        }\n        console.log(callArgs)\n        if (callArgs.length <= 2) { //[4]\n          resolve(result);\n        } else {\n          resolve([result, ...restResults]);\n        }\n      });\n\n      // the same as fn.apply(null, callArgs)\n      fn(...callArgs); //[5]\n    });\n  }\n};\n\nThis is how it works:\n\nThe promisified() creates a new promise using Promise constructor and immediately return it to caller\nWe make sure to pass a special callback to fn(). As we know that the callback always comes last, we append it to the arguments (args) provided to the promisified()\nIn the special callback if we receive an error we immediately reject an error\nIf no error, we resolve the promise with a value or an array of values, depending how many results are passing to callback\nFinally, we simply invoke the fs() with the list of arguments we have built\n\nAnother approach is to use one of the ready-production npm packages, for example tini-promisify\n\n Sequential execution \n\nWe are now ready to convert our web spider application to use promises:\n\nconst utilities = require('utilities');\nconst promisify = utilities.promisify;\n\n// const fs = require(fs);\nconst request = promisify(require('request'));\nconst makedirp = promisify(require('makedirp'));\nconst readFile = promisify(require(fs.readFile));\nconst writeFile = promisify(require(fs.writeFile));\n\nfunction spider(url, nesting) {\n  const filePath = utils.urlToFilePath(url);\n  const fileName = utils.urlToFileName(url);\n\n  return readFile(path.join(filePath, fileName), 'utf8')\n    .then(body = spiderLink(url, body, nesting))\n    .catch((err) = {\n      if (err) {\n        if (err.code === 'ENOENT') { \n          return download(url, fileName);\n        }\n      }\n    })\n    .then(body = {\n      spiderLink(url, body, nesting)\n    })\n}\n\nfunction download(url, filename) {\n  let body = body;\n\n  return request(url)\n    .then(resp = {\n      body = resp.body;\n      return mkdirp(path.dirname(url));\n    })\n    .then(() = writeFile(filename, body))\n    .then(() = {\n      console.log(Download and saved ${fileName} from ${url});\n      return body;\n    })\n}\n\nAlso we modify its invocation as follow:\n\nspider(url, 5)\n  .then(() = console.log(chalk.green(Download and saved from ${url})))\n  .catch((err) = console.log(chalk.red(Error: ${err})));\n\nIf we look again at code we have written so far, we would be pleasantly surprised by the fact that we haven't include any error propagation logic, as we would be forced to do with callbacks. This is clearly a huge advantage, as it reduced boilerplate in our code.\n\nSequential iteration \n\nSo far it was shown how simple and elegant is to implement sequential execution flow using promises. However code involves only the execution of a well known set of asynchronous operation. So, we missing peace that will complete our exploration of sequential execution flow with implementation of asynchronous iteration using promises\n\nfunction spiderLink(url, body, nesting) {\n  const links = utils.getUrls(body);\n  let promise = Promise.resolve();\n  \n  if (nesting === 0) {\n    return promise;\n  }\n\n  links.forEach(link = {\n    promise = promise.then(() = spider(link, nesting--;))\n  })\n\n  return promise;\n}\n\nTo iterate asynchronously over links we had dynamically build a chain of promises:\n\nStarting with an \"empty\" promise, resolving to undefined. This is a starting point to build our chain\nThen, in the loop, we're updating the promise variable with a new promise which is invoked from then() on the previous promise in the chain. This is actually our asynchronous iteration pattern using promises.\n\nLet's extract a pattern for a sequential execution using promises:\n\nconst tasks = [/.../];\nlet promise = Promise.resolve();\n\ntasks.forEach(task = {\n  promise = promise.then(() = task());\n})\n\n// an alternative with \"reduce()\"\n/*\ntasks.reduce((prev, task) = {\n  return prev.then(() = task());\n}, Promise.resolve())\n*/\n\npromise.then(() = /all task are completed/)\n\n The pattern: sequential iteration with promises\n Dynamically builds a chain of promises in a loop\n\n Parallel execution\n\nAnother execution flow is become trivial with promises is the parallel execution flow using Promise.all(). This static method creates promise which fulfills only when all the promises received as input are fulfilled:\n\nfunction spiderLink(url, body, nesting) {\n  const links = utils.getUrls(body);\n  \n  if (nesting === 0) {\n    Promise.resolve()\n  }\n\n  let promises = links.map(link = spider(link, --nesting));\n\n  return Promise.all(promises);\n}\n\nLimited parallel execution\n\nIn fact, the pattern we've implemented in TaskQueue class can be easily adapted to support tasks that return a promise. This can be achieve by modifying next():\n\nnext() {\n  while(this.running < this.concurrency && this.queue.length) {\n    const task = this.queue.shift();\n\n    this.running++;\n    \n    task().then(() = {\n      completed++;\n      running--;\n      this.next();\n    })\n  }\n}\n\nThen we can modify the spideLinks() to achieve limit of concurrency:\n\nconst TaskQueue = require('./task-queue');\nconst downloadQueue = new TaskQueue(2);\n\nfunction spiderLink(url, body, nesting) {\n  if (nesting === 0 || links.length === 0) {\n    return Promise.resolve;\n  }\n  const links = utils.getUrls(body);\n\n  let completed = 0;\n  let hasErrors = false;\n\n  return Promise((resolve, reject) = {\n    let completed = 0;\n    let error = false;\n\n    links.forEach(link = {\n      let task = () = {\n        return spider(link, --nesting)\n          .then(() = {\n            if (++completed === links.length) {\n              resolve()\n            }\n          })\n          .catch((err) = {\n            if (!error) {\n              error = true;\n              reject();\n            }\n          })\n      };\n      downloadQueue.pushTask(task)\n    })\n  })\n}\n\n Exposing callbacks and promises in public APIs\n\nNow let's imagine that we want to build a public library that performs asynchronous operations. Do we need to create CPS API or a promise-oriented one?\n\nThe first approach is used by popular libraries such as request, redis and mysql, consists of offering a simply API that is only based on callbacks and leaves the developer the option to promisify the exposed functionality of needed. Some of these libraries provides helpers to achieve a such behavior.\n\nThe second approach is more transparent. It offers the developers a callback-oriented API, but it makes the callback argument optional. When the callback is not passed, the function will immediately return a Promise object. This approach gives possibility to choose at call time what interface to adopt, without any needs to promisify the functionality in advance. Many libraries, such as mongoose or sequelize, support this approach.\n\nA dummy module that executes division asynchronously:\n\n//divider.js\nmodule.exports = (divident, divisor, cb) {\n  return new Promise(resolve, reject) = {\n    process.nextTich(() = {\n      const result = divident / divisor;\n\n      if (!Number.isInteger(result)) {\n        const err = new Error('Invalid operands');\n\n        if (cb) return cb(err);\n        reject(err);\n      }\n      if (cb) return cb(null, result);\n      resolve(result);\n    })\n  }\n}\n\n//main.js\nconst divider = require('./divider')\ndivider(10, 0, (err, res) = {\n  if (err) return console.error(err);\n\n  console.log(res);\n});\n\ndivider(10, 2)\n  .then(res = console.log(res))\n  .catch(err = console.error(err));\n\nGenerators\n\nIn fact, in a normal function we can only have one entry point which corresponds to the invocation of function itself. A generator is similar to a function, but in addition, it can be suspended (using the yield statement) and then resumed at a later time.\n\n Asynchronous control flow with generators\n\nTo demonstrate how generator will help us with this by creating a special function that accepts a generator as an argument and allows us to use asynchronous code inside the generator. The function take care to resume the execution of the generator when the asynchronous operation is complete:\n\nfunction asyncFlow(generatorFn) {\n  const generator = generatorFn(cb);\n  generator.next();\n\n  // special callback to resume/stop the generator\n  // resume by passing back the result receiving in the cb function\n  function cb(err, ...result) {\n    if (err) {\n      return generator.throw(err);\n    }\n\n    generator.next(result);\n  }\n}\n\nTo demonstrate the power of this simple function with new module:\n\n// clone.js\nconst fs = require('fs');\nconst path = require('path');\n\nasyncFlow(function* (cb) {\n  const filename = path.basename(__filename);\n  const content = yield fs.readFile(filename, 'utf8', cb);\n\n  yield fs.writeFile(cloneof${filename}, content, cb);\n  console.log('clone created');\n})\n\nRemarkable with help of asyncFlow() we were able to write asynchronous code using the linear approach, as we using blocking function! The callback passed to each asynchronous function will in turn resume the generator as soon as a asynchronous operation is complete.\n\nThere are two other variation of these technique, one involves to use promises and other use thunks.\n\nA thunk used in the generator based control flow it's just a function which partially applies all the arguments of original function except its callback. An example of thunkified version of fs.readFile():\n\nfunction readFileThunk(filename, options) {\n  return function(cb) {\n    fs.readFile(filename, options, cb);\n  }\n}\n\nBoth promises and thunks allow us to create generators that do not need a callback argument. Thunkfied version of asynkFlow():\n\nconst fs = require('fs');\nconst path = require('path');\n\nasyncFlowWithThunks(function* () {\n  const filename = path.basename(__filename);\n  const content = yield readFileThunk(filename, 'utf8');\n\n  yield writeFileThunk(cloneof${filename}, content);\n  console.log('clone created');\n})\n\nfunction readFileThunk(filename, options) {\n  return function(cb) {\n    fs.readFile(filename, options, cb);\n  }\n}\n\nfunction writeFileThunk(filename, constent) {\n  return function(cb) {\n    fs.writeFile(filename, constent, cb);\n  }\n}\n\nfunction asyncFlow(generatorFn) {\n  const generator = generatorFn();\n  const thunk = generator.next().value;\n  thunk && thunk(cb);\n  \n  function cb(err, ...result) {\n    let thunk;\n\n    if (err) {\n      return generator.throw(err);\n    }\n\n    thunk = generator.next(result).value;\n    thunk && thunk(cb);\n  }\n}\n\nIn the same way we could implement a version with promises:\n\nconst fs = require('fs');\nconst path = require('path');\n\nasyncFlowWithPromises(function* () {\n  const filename = path.basename(__filename);\n  const content = yield readFilePromise(filename, 'utf8');\n\n  yield writeFilePromise(cloneof${filename}, content);\n  console.log('clone created');\n})\n\nfunction readFilePromise(filename, options) {\n  const readFile = promisify(fs.readFile);\n  return (cb) = {\n    fs.readFile(filename, options, cb);\n  };\n}\n\nfunction writeFilePromise(filename, content) {\n  const readFile = promisify(fs.writeFile);\n  return (cb) = {\n    fs.writeFile(filename, content, cb);\n  };\n}\n\nfunction promisify(fn) {\n  return function promisified(...callArgs) {\n    return new Promise((resolve, reject) = { \n      callArgs.push((err, result, ...restResults) = { \n        if (err) {\n          return reject(err); \n        }\n        console.log(callArgs)\n        if (callArgs.length <= 2) { \n          resolve(result);\n        } else {\n          resolve([result, ...restResults]);\n        }\n      });\n      \n      fn(...callArgs); \n    });\n  }\n}\n\nfunction asyncFlow(generatorFn) {\n  const generator = generatorFn();\n  const thunk = generator.next().value;\n  thunk && thunk(cb);\n  \n  function cb(err, ...result) {\n    let thunk;\n\n    if (err) {\n      return generator.throw(err);\n    }\n\n    thunk = generator.next(result).value;\n    thunk && thunk(cb);\n  }\n}\n\nGenerator based control flow using \"co\"\n\nIn this section we chose to use co. It supports several types of yieldables:\n\nthunks\npromises\narray (parallel execution)\nobject (parallel execution)\ngenerators (delegation)\ngenerator function (delegation)\n\nTo convert Node.js style function to thunks, we are going to library thunkify\n\nSequential execution\n\nLoad and convert all dependencies:\n\n// spider.js\nconst thunkify = require('thunkify');\nconst co = require('co');\nconst path = require('path');\n\nconst request = thunkify(require('request'));\nconst fs = require('fs');\nconst mkdirp = thunkify(require('mkdirp'));\nconst readFile = thunkify(fs.readFile);\nconst writeFile = thunkify(fs.writeFile);\nconst nextTick = thunkify(process.nextTick);\n\nIs interesting to point out if we decided to use the promisified version of our function instead of their thunkified alternatives, so code would be remain exactly the same, thanks to the fact that co supports both promises and thunks yiedlable objects.\n\nNow implementation of download() and spider() becomes trivial:\n\nfunction* download(url, filename) {\n  console.log(download ${url});\n  const response = yield request(url);\n  const body = response[1];\n\n  yield mkdirp(path.dirname(filename));\n  yield writeFile(filename, body);\n  console.log(downloaded and saved file ${filename});\n\n  return body;\n}\n\nfunction* spider(url, nesting) {\n  const filename = utilities.urlToFilename(url);\n  let body;\n\n  try {\n    body = yield readFile(url, 'utf8');\n  } catch(e) {\n    if (e.code !== 'ENOENT') {\n      throw e;\n    }\n    body = yield download(url, filename);\n  }\n  yield spiderLink(url, body, nesting);\n}\n\nThe interesting detail to notice that we're able to use a try...catch and propagate error with throw! Another remarkable line is where we use yield download() which is not a promise nor a thunk, but just another generator. This is possible thanks to co.\n\nConverting spiderLinks() becomes trivial as well:\n\nfunction spiderLinks(url, body, nesting) {\n  if (nesting === 0) {\n    return nextTick();\n  }\n\n  const links = utilities.getPageLinks(body);\n  links.forEach(link = {\n    yield spider(link, nesting - 1);\n  })\n}\n\nThe is no pattern to show for sequential iteration, generators and co are doing the all dirty work for us, so we're able to write asynchronous iteration as we were using blocking, direct APIs.\n\nNow an important entry point:\n\nco(function* () {\n  const nesting = 1;\n  try {\n    yield spider(process.argv[2], nesting);\n  } catch(e) {\n    console.log(e);\n  }\n})\n\nThe whole implementation: \n\nconst thunkify = require('thunkify');\nconst co = require('co');\nconst path = require('path');\n\nconst request = thunkify(require('request'));\nconst fs = require('fs');\nconst mkdirp = thunkify(require('mkdirp'));\nconst readFile = thunkify(fs.readFile);\nconst writeFile = thunkify(fs.writeFile);\nconst nextTick = thunkify(process.nextTick);\n\nconst utilities = require('./utils');\n\nco(function* () {\n  const nesting = 1;\n  try {\n    yield spider(process.argv[2], nesting);\n  } catch(e) {\n    console.log(e);\n  }\n})\n\nfunction* download(url, filename) {\n  console.log(download ${url});\n  const response = yield request(url);\n  const body = response[1];\n\n  yield mkdirp(path.dirname(filename));\n  yield writeFile(filename, body);\n  console.log(downloaded and saved file ${filename});\n\n  return body;\n}\n\nfunction* spider(url, nesting) {\n  const filename = utilities.urlToFileName(url);\n  let body;\n\n  try {\n    body = yield readFile(filename, 'utf8');\n  } catch(e) {\n    if (e.code !== 'ENOENT') {\n      throw e;\n    }\n    body = yield download(url, filename);\n  }\n  yield spiderLinks(filename, body, nesting);\n}\n\nfunction* spiderLinks(url, body, nesting) {\n  if (nesting === 0) {\n    return nextTick();\n  }\n\n  const links = utilities.getUrls(body);\n\n  for (var i = 0; i < links.length; i++) {\n    yield spider(links[i], nesting - 1);\n  }\n}\n\n Parallel execution\n\nThe bad news about generators is that they are good to write sequential algorithm, they can't be used to parallelize the execution of set of tasks.\n\nLuckily, for the specific case of the unlimited parallel execution, co already allows us to obtain it natively by simpling yielding an array of promises, thunks, etc.\n\nfunction* spiderLinks(url, body, nesting) {\n  if (nesting === 0) {\n    return nextTick();\n  }\n\n  const links = utilities.getUrls(body);\n  const tasks = links.map(link = spider(link, nesting - 1));\n  yield tasks;\n}\n\nWhat we just did was just to collect all the download tasks, which are essentially generators, and then yield on the resulting array. All these task will be executed by co in parallel and then execution will be resumed when all tasks finish running.\n\nLimited parallel execution\n\nThe main straightforward approach for me is to use co-limiter\n\nconst co = require('co');\nconst wait = require('co-wait');\nconst limiter = require('co-limiter');\n\nconst limit = limiter(2);\n\nconst job = function *() {\n  console.log('Doing something...');\n  yield wait(1000);\n}\n\nfor (let i = 0; i < 10; i++) {\n  co(function *() {\n    yield limit(job());\n  })();\n}\n\n \"async...await\" with Babel\n\nPreparation:\n\ninstall babel cli\n$ npm install -D babel-cli\n extension to support \"async...await\" parsing\n$ npm install -D babel-plugin-syntax-async-functions\nbabel-plugin-transform-async-to-generator\nrun the example\n$ node_modules\\.bin\\babel-node --plugins\n\"syntax-async-functions,transform-async-to-generator\" index.js\n\nThe problem is that generator function are designed to deal mostly as iterators and their usage with asynchronous operations feel a bit cumbersome. It might be hard to understand, leading to code that hard to read and maintain.\n\nThe async function specification aims to dramatically improve the language model for waiting asynchronous code by introducing async and await directives:\n\nconst promisify = require('tiny-promisify');\nconst request = promisify(require('request'));\n\nfunction getPage(url) {\n  return request(url).then(res = {\n    return res.body;\n  });\n}\n\nasync function main() {\n  const html = await getPage('http://example.com');\n  console.log(html);\n}\nmain();\n\nconsole.log('loading...');\n\n Comparison Table\n\nPlain JS\n  Pros:\n    Does not require any additional libraries or technology\n    Offer the best performance\n    Provides the best compatibility with 3-th party libraries\n    Allows creation of ad hoc and more advanced algorithms\n  Cons:\n    Require extra code and relatively complex algorithms\nPromises\n  Pros:\n    Simplify the most common control flow patters\n    Robust error handling\n    Part of ES6 spec\n  Cons:\n    Require promisify callback-based APIs\n    A small performance hit\nGenerators:\n  Pros:\n    Makes non-blocking code looks like a blocking one\n    Simplify error handling\n    Part of ES6 spec\n  Cons:\n    Require a complementary control flow library\n    Require callback or promises to implement non-sequential flows\n    Require thunkify or promisify nongenerator-based APIs\nAsync await\n  Pros:\n    Makes a non-blocking code looks like blocking\n    Clean and intuitive syntax\n    Future part of spec\n  Cons:\n    Not yet a standard\n    Require transpilers such as Babel\n  ",
        "tags": []
    },
    {
        "uri": "/post/NodeList-vs-Array-in-Javascript",
        "title": "NodeList vs Array in Javascript",
        "content": "\nEssentially, a NodeList is what you get when you call any method such as  elem.getElemetsByTagName(), elem.querySelectorAll() and so on.\n\n!--more--\n\nWe should note here that NodeLists are not exactly part of the JavaScript but they are instead part of the DOM APIs the browsers provide through JavaScript. \n\nvar myList = document.querySelectorAll('.story-item');\nconsole.log(myList)\n[\n  div class=\"story-item\"…/div\n  ,\n  div class=\"story-item\"…/div\n  ,\n  […]\n  ,\n  div class=\"story-item\"../div\n  ,\n]\n\n// basic array actions\nconsole.log(myList.length) // 7\nconsole.log(myList[2]) // div class=\"story-item\"../div\n\nSo far, myList has been talking and walking like an array so we can probably assume that it’s an array of some sorts. However, it all goes to hell when you try to call any of the basic array methods:\n\nmyList.slice(2) // indexed from 0\n\nTypeError: Result of expression 'myList.slice' [undefined] is not a function.\n\nWait, what happened? Well, this is where the between NodeLists and arrays in JavaScript start to surface. Let’s see what is distinguish array and NodeList: \n\nconsole.log(myList.constructor.prototype) // \"[object NodeListConstructor]\"\n\nvar surelyArray = ['foo', 'bar'];\n\nconsole.log(surelyArray.constructor.prototype) //\"function Array() { [native code] }\"\n\nSo those two elements, myList and surelyArray are definitely constructed by different constructors so it’s no wonder that they don’t share the same methods.\n\nWhile arrays are essentially a collection of elements held in memory and are part of the JavaScript, NodeLists are live references to actual DOM elements.\n\nLet’s see a quick way to convert a NodeList into an array:\n\n//borrowing the slice() method from the Array’s prototype\nvar myArray = Array.prototype.slice.call(myList, 0);\n\nconsole.log(myArray.constructor.prototype) //\"function Array() { [native code] }\"\n\n//call pop method\nmyArray.pop() //div class=\"story-item\"…/div\n\n//Internet Explorer 9 cannot handle calling slice() on NodeLists\nvar myIEArray = [];\n\nfor (var i = 0; i < myList.length; ++i) { myIEArray.push(myList[i]); }\nconsole.log(myIEArray.constructor.prototype) //\"function Array() { [native code] }\"\n\nES6 approach: \n\n// Spread operator\n[...elements].forEach(callback);\n\n// Array.from()\nArray.from(elements).forEach(callback);\n\n// for...of statement\nfor (var div of elements) { callback(div) };\n\nOne thing is worth mentioning though; when you convert your NodeList into an array, you are no longer dealing with a live NodeList but instead an array of DOM nodes.",
        "tags": []
    },
    {
        "uri": "/post/OOP-in-prototype-style",
        "title": "OOP in prototype style",
        "content": "\nThe main point is that one object can be prototype of another object. That means if property isn't found in the object - than it takes from prototype object. In JavaScript this implementation is at the language level.\n\n!--more--\n\nInheritance through link proto\n\nInheritance in JavaScript is realized via special property proto (In specs EcmaScript the name is [[Prototype]]). In ES5 the property was available in Chrome / Firefox and Safari, but in other browser was hidden. ES6 includes proto property as standard. In this article, for more efficient way I'll use proto property, but for legacy you should use Object.getPrototypeOf()\n\nIf the object, for instance rabbit, has a special link proto to another object animal, that mean, that all property which are searched in the rabbit, will be also searched in the animal object.\n\nvar animal = { eats: true },\n    rabbit = { jumps: true };\n\nrabbit.proto = animal;\n\nconsole.log(rabbit.eats) //true\n\nWe can write any object in prototype object:\n\nvar rabbit = {foo: 'bar'};\n\nrabbit.proto = window;\n\nconsole.log(rabbit.location) // call location object through window object\n\nSo, object pointed by proto it is his prototype. In another words prototype it's \"Backup Storage of Properties and Methods\", which automatically used in the search.\n\n    Method hasOwnProperty\n\nSimple loop for...in or loop through iterable objects (Array, Mas, Set, arguments object) can't distinguish between the own properties and properties of his prototype\n\nvar animal = {\n  eats: true\n};\n\nvar rabbit = {\n  jumps: true,\n  proto: animal\n};\n\nfor (var key in rabbit) {\n  alert( key + \" = \" + rabbit[key] ); // \"eats\"; \"jumps\"\n}\n\nFor iterate only through own properties with obj.hasOwnProperty(prop):\n\nscript src=\"https://gist.github.com/qetr1ck-op/f69804da0f8a16a29f79.js\"/script\n\nPrototype Chain\n\nIn object proto can be another proto object and so on. For example, the inheritance chain of three object donkey - winnie - owl:\n\nscript src=\"https://gist.github.com/qetr1ck-op/d57b779a057e164bf1d2.js\"/script\n\n    Methods to work with proto\n\nBy historical reason we have methods to get/set proto property:\n\nscript src=\"https://gist.github.com/qetr1ck-op/54c9dbea765318e4a2c2.js\"/script\n\nObject.create(proto, descriptors) creates new bempty object with proto object:\n\nscript src=\"https://gist.github.com/qetr1ck-op/970d7c61bf7452fd8b5e.js\"/script\n\nThis method only allows create new empty object. He can't change prototype of an existing object.\n\nCreate an empty collection, without prototype chain with Object.create(null):\n\nscript src=\"https://gist.github.com/qetr1ck-op/99be3a7345429941c2eb.js\"/script\n\nExercise with proto\n\n1.1\nscript src=\"https://gist.github.com/qetr1ck-op/d20e3a520e4dc06a5f63.js\"/script\n\n1.2\nscript src=\"https://gist.github.com/qetr1ck-op/32ce09bfa0ca65d5346d.js\"/script\n\n    F.prototype\n\nProperty prototype can point on any object but it has sense, when it's assigned to function-constructor.\n\nWhen project is creating via new, in his proto object writes link from prototype of function-constructor.\n\nscript src=\"https://gist.github.com/qetr1ck-op/c4ac921c558015b4a481.js\"/script\n\nExercises with prototype and new\n\n1.1\n\nscript src=\"https://gist.github.com/qetr1ck-op/079e4c21baa262ca5f44.js\"/script\n\n1.2\n\nscript src=\"https://gist.github.com/qetr1ck-op/340acc108182399dbd38.js\"/script\n\n1.3\n\nscript src=\"https://gist.github.com/qetr1ck-op/275f8d2485c73f3a365a.js\"/script\n\n1.4\n\nscript src=\"https://gist.github.com/qetr1ck-op/9b042fd1294bb8529477.js\"/script\n\n1.5\n\nscript src=\"https://gist.github.com/qetr1ck-op/36a799bfd94038ea3a88.js\"/script\n\n2.1\n\nscript src=\"https://gist.github.com/qetr1ck-op/aadce099bb5b8ddf7a02.js\"/script\n\n!--  --\n\n    \"Classes\". Where methods come from empty {}\n\nLets begin with creating empty object end call method toString:\n\nscript src=\"https://gist.github.com/qetr1ck-op/d0902bca8a134b7c101f.js\"/script\n\nIt's obviously, that { } is empty. But then who generates method toString()? Off-course this makes method toString() which is built-in Object.prototype.\n\nIn details it works like this:\n\nCreating object literal obj = { } means shorthand form for obj = new Object(), were Object is built-in function-constructor for objects\nWhile new Object invokes, new object has receives obj.proto = Object.prototype.\nobj.toString === Object.prototype.toString method will be taken from prototype object.\n\nBuild-in \"Classes\"\n\nThe same methods use in arrays Array, functions Function and other objects. Build-in methods are in Array.prototype, Function.prototype, etc.\n\nThats why everywhere JS developers like to say that \"All objects inherit from Object\". But it's a quite incorrect. All objects inherit from Object.prototype via proto link.\n\nIn some cases, method can overrides. For example, \"class\" Array has it's own toString, which is in Array.prototype.toString:\n\nscript src=\"https://gist.github.com/qetr1ck-op/823a2dfdf760938c91fd.js\"/script\n\n    Exercises with overriding prototype\n\n1.1\n\nscript src=\"https://gist.github.com/qetr1ck-op/df77c34e3efec24039e6.js\"/script\n\n1.2\n\nscript src=\"https://gist.github.com/qetr1ck-op/188c0afa47da9b036b73.js\"/script\n\n1.3\n\nscript src=\"https://gist.github.com/qetr1ck-op/e733ebd38e35616ed565.js\"/script\n\n1.4\n\nscript src=\"https://gist.github.com/qetr1ck-op/a292315fd0ddd6477827.js\"/script\n\nDeclares own \"Classes\"\n\nFor create \"Class\" you need:\n\nDeclare function-constructor\nWrite all required methods and properties in prototype\n\nscript src=\"https://gist.github.com/qetr1ck-op/fde34608e4532f82d166.js\"/script\n\n    Property constructor\n\nProperty constructor is in every function, even if it isn't declare. So concept is next, the property constructor should have link to function, which creates the object:\n\nscript src=\"https://gist.github.com/qetr1ck-op/02ee2ee811e78b50274c.js\"/script\n\nBut when you overriding the prototype, property constructor disappears:\n\nscript src=\"https://gist.github.com/qetr1ck-op/c43b5a7d1ec3afd701af.js\"/script\n\nSo how it works: animal - Animal.prototype (new Object) - Object.prototype\n\nPrototype OOP\n\nClasses it isn't only function-constructor with prototype, it's also additional opportunities for OOP development.\n\nFor example two \"Classes\" and realization of \"Class inheritance\":\n\nscript src=\"https://gist.github.com/qetr1ck-op/4aed9017910b8e0d2c39.js\"/script\n\nSaveMyDay:\n\non a href=\"https://learn.javascript.ru/prototypes\"</a learn.javascript.ru",
        "tags": []
    },
    {
        "uri": "/post/Operator-typeof-Class-instanceof-Duck-Typing-and-Polymorphism",
        "title": "Operator typeof, [[Class]], instanceof,  Duck Typing and Polymorphism",
        "content": "\nFunny to hear when developer says that JS does not have types =) Let's see how to distinguish them right.\n\n!--more--\n\nOperator typeof\n\nOperator typeof return type of argument. He has two syntax: typeof x and typeof(x).\n\ntypeof undefined // \"undefined\" \n\ntypeof 0    // \"number\" \n\ntypeof true // \"boolean\" \n\ntypeof \"foo\" // \"string\" \n\ntypeof {} // \"object\" \ntypeof [] // \"object\" \ntypeof new Date // \"object\" \n\ntypeof null  // \"object\" \ntypeof function(){} // \"function\" \n\ntypeof operator works great with primitive types, except null, as well as functions. But ordinary objects, arrays, and date for typeof all look the same, they are of type 'object'.\n\nThat's why we can't distinguish them using typeof.\n\n    [[Class]] for objects\n\nvar date = new Date,\n    arr = [1,2];\n\nconsole.log({}.toString.call(date)); // [object Date]\nconsole.log({}.toString.call(arr)); // [object Array]\n\nconsole.log(getType(date)); // Date\nconsole.log(getType(arr)); // Array\nconsole.log(getType({})); // Object\nconsole.log(getType('str')); // String\nconsole.log(getType(11)); // Number\n\nfunction getType(instance) {\n  return {}.toString.call(instance).slice(8,-1);\n}\n\nWe use this method because the internal implementation of the Object toString returns the standard [[Class]].\n\nThis method can give the type only for embedded objects. For user constructors always [[Class]] = \"Object\":\n\nfunction Animal(name) { \n  this.name = name;\n}\nvar animal = new Animal(\"Rabbit\");\n\nconsole.log(getType(animal)); // Object\n\nDuck Typing\n\n «If it looks like a duck, swims like a duck and quacks like a duck, then it probably is a duck (who cares what it really is)»\n\nMeaning duck typing - to verify the methods and properties, regardless of the type of object.\n\n// check if array has method split\nvar x = [1,2,3];\n\nif (x.splice) {\n  alert('Array');\n}\n\n// check if date has method getTime\nvar z = new Date();\n\nif (z.getTime) {\n  alert('Date!');\n}\n\nTo check who created the object or his prototype, is the operator:\n\n//check custom objects\nfunction Animal(name) { \n  this.name = name;\n}\nvar animal = new Animal(\"Bee\");\n\nconsole.log( animal instanceof Animal ); // true\nconsole.log( Object.getPrototypeOf(animal) == Animal.prorotype ); // true\nconsole.log( animal.contstructor.prototype == Animal.prorotype ); // true\n\n//also works for inner objects\nvar d = new Date(); \nconsole.log( d instanceof Date ); // true\nconsole.log( Object.getPrototypeOf(d) == Date.prorotype ); // true\nconsole.log( d.contstructor.prototype == Date.prorotype ); // true\n\nfunction f() { }\nconsole.log( f instanceof Function ); // true\nconsole.log( Object.getPrototypeOf(f) == Function.prorotype ); // true\nconsole.log( f.contstructor.prototype == Function.prorotype ); // true\n\n    Polymorphism\n\nPolymorphic functions, ie, those which are differently treated arguments(polymorphically operate), depending on their type. For example, the output may have a different format numbers and dates.\n\nIn example we use type checking to create a polymorphic function sayHi. It will work in three modes:\n\nNo arguments: outputs \"Hello\".\nWith an argument, which is not an array: displays \"Hello\" + string argument\nWith an argument, which is an array - \"Hello\" + arr[i]\n\nfunction sayHi(who) {\n  if (!arguments.length) {\n    console.log('Hello');\n    return;\n  }\n\n  if ( Array.isArray(who) ) {\n    for(var i=0; i<who.length; i++) sayHi(who[i]);\n    return;\n  }\n\n  console.log('Hello, ' + who);\n}\n\nsayHi(); // Hello\nsayHi(\"Bob\"); // Hello, Bob\n\nsayHi( [\"Bob\", [\"Sam\", \"Din\"] ] ); // Hello Bob..Sam..Din\n\nSaveMyDay:\n\non learn.javascript.ru",
        "tags": []
    },
    {
        "uri": "/post/Organizing-an-application-using-AMD-with-require-js",
        "title": "Organizing an application using AMD with require.js",
        "content": "\nRequireJS is a JavaScript file and module loader. It is optimized for in-browser use, but it can be used in other JavaScript environments\n\n!--more--\n\nWhat is AMD?\nAsynchronous Module Definitions designed to load modular code asynchronously in the browser and server. It is actually a fork of the Common.js specification. Many script loaders have built their implementations around AMD, seeing it as the future of modular JavaScript development.\n\n    Example File Structure\nThere are many different ways to lay out your files and I believe it is actually dependent on the size and type of the project. In the example below views and templates are mirrored in file structure.\n\n├── imgs\n├── css\n│   └── style.css\n├── templates\n│   ├── projects\n│   │   ├── list.html\n│   │   └── edit.html\n│   └── users\n│       ├── list.html\n│       └── edit.html\n├── js\n│   ├── libs\n│   │   ├── jquery\n│   │   │   ├── jquery.min.js\n│   │   ├── backbone\n│   │   │   ├── backbone.min.js\n│   │   └── underscore\n│   │   │   ├── underscore.min.js\n│   ├── models\n│   │   ├── users.js\n│   │   └── projects.js\n│   ├── collections\n│   │   ├── users.js\n│   │   └── projects.js\n│   ├── views\n│   │   ├── projects\n│   │   │   ├── list.js\n│   │   │   └── edit.js\n│   │   └── users\n│   │       ├── list.js\n│   │       └── edit.js\n│   ├── router.js\n│   ├── app.js\n│   ├── main.js  // Bootstrap\n│   ├── order.js //Require.js plugin\n│   └── text.js  //Require.js plugin\n└── index.html\n\nBootstrapping your application\n\nUsing Require.js we define a single entry point on our index page. We should setup any useful containers that might be used by our Backbone views.\n\nNote: The data-main attribute on our single script tag tells Require.js to load the script located at \"js/main.js\". It automatically appends the \".js\"\n\n!doctype html\nhtml lang=\"en\"\nhead\n    titleJackie Chan/title\n    !-- Load the script \"js/main.js\" as our entry point --\n    script data-main=\"js/main\" src=\"js/libs/require/require.js\"/script\n/head\nbody\n\ndiv id=\"container\"\n  div id=\"menu\"/div\n  div id=\"content\"/div\n/div\n\n/body\n/html\n\nYou should most always end up with quite a light weight index file. You can serve this off your server and then the rest of your site off a CDN ensuring that everything that can be cached, will be.\n\n    What does the require.js look like?\n\nOur bootstrap file will be responsible for configuring Require.js and loading initially important dependencies.\n\nIn the example below we configure Require.js to create a shortcut alias to commonly used scripts such as jQuery, Underscore and Backbone.\n\nNote: Modules are loaded relatively to the boot strap and always append with .js. So the module app will load app.js which is in the same directory as the bootstrap.\n\n// Filename: main.js\n\n// Require.js allows us to configure shortcut alias\n// There usage will become more apparent further along in the tutorial.\nrequire.config({\n  paths: {\n    jquery: 'libs/jquery/jquery',\n    underscore: 'libs/underscore/underscore',\n    backbone: 'libs/backbone/backbone'\n  }\n\n});\n\nrequire([\n\n  // Load our app module and pass it to our definition function\n  'app',\n], function(App){\n  // The \"app\" dependency is passed in as \"App\"\n  App.initialize();\n});\n`",
        "tags": []
    },
    {
        "uri": "/post/Original-effects-with-CSS3-transition",
        "title": "Original effects with CSS transition",
        "content": "\nThe power of CSS3 is enormous and in this post I create appearing effect of \"Sign In Form\" using differn style in each example.\n\n!--more--\n\nActually, now transition property of CSS supporting almost in all browsers, just in some case you need to use prefix -webkit, -moz, -ms, -o. You may check it on Can I use...\n\nAwesome and simple CSS3 Transition generator (and not only).\n\nMore about transition-timing-funtion with example.\n\nIf you look closely you may see that in all example firstly I hide \"Sign In Form\" with transform: scale, rotate, translateX/Y and add transition. Than I use different value of transform, transition-delay, opacity for show original transition CSS effects.\n\nExample 1\n\np data-height=\"268\" data-theme-id=\"10606\" data-slug-hash=\"gwJsh\" data-default-tab=\"result\" data-user=\"qetr1ck-op\" class='codepen'See the Pen a href='http://codepen.io/qetr1ck-op/pen/gwJsh/'CSS3 transition effects example 1/a by qetr1ck-op (a href='http://codepen.io/qetr1ck-op'@qetr1ck-op/a) on a href='http://codepen.io'CodePen/a./p\n\nscript async src=\"//assets.codepen.io/assets/embed/ei.js\"/script\n\nIn first example I used transition for base elements with different timestamps and time function. Also I used transform: translateY property that push \"Sign In Form\" and child elements from current position.\n\nWhen you click on main section, you can see delay property that emulate animation. In this example I added a transition-delay: ...s which make transition effect start a bit later.\n\n Example 2\n\np data-height=\"268\" data-theme-id=\"10606\" data-slug-hash=\"wlxGq\" data-default-tab=\"result\" data-user=\"qetr1ck-op\" class='codepen'See the Pen a href='http://codepen.io/qetr1ck-op/pen/wlxGq/'CSS3 transition effects example 2/a by qetr1ck-op (a href='http://codepen.io/qetr1ck-op'@qetr1ck-op/a) on a href='http://codepen.io'CodePen/a./p\n\nIn second example I used new div.content, you can see it in HTML mark-up. For \"Sign In Form\" I applied transform: translate(...px, ...px) rotate(...deg) for children used only translate. Of course added transition for elements.\n\nTranslate transformation in order move elements in place. The \"Sign In Form\" will also be rotated. The each elements of the description will come with a little delay.\n\nExample 3\n\np data-height=\"270\" data-theme-id=\"10606\" data-slug-hash=\"tLaic\" data-default-tab=\"result\" data-user=\"qetr1ck-op\" class='codepen'See the Pen a href='http://codepen.io/qetr1ck-op/pen/tLaic/'CSS3 transition effects example 3/a by qetr1ck-op (a href='http://codepen.io/qetr1ck-op'@qetr1ck-op/a) on a href='http://codepen.io'CodePen/a./p\n\nIn third example I used the translate and  transforms: rotate to bring up content.\n\nThan I just need to reset transform: translateX(0px) rotate(0deg) and add transition-delay: ...s.\n\n Example 4\n\nHere in four example I performed zoom out for main block and zoom in for \"Sign In Form\" with rotation effect. All thanks to transform: scale and rotate.\n\np data-height=\"266\" data-theme-id=\"10606\" data-slug-hash=\"aGqou\" data-default-tab=\"result\" data-user=\"qetr1ck-op\" class='codepen'See the Pen a href='http://codepen.io/qetr1ck-op/pen/aGqou/'CSS3 transition effects example 4/a by qetr1ck-op (a href='http://codepen.io/qetr1ck-op'@qetr1ck-op/a) on a href='http://codepen.io'CodePen/a./p\n\nExample 5\n\nIn this example I used transform: translateX() and transition timing function ease-in-out. Transition effect make the \"Sign In Form\" slide from right, with pushing effect for main container.\n\np data-height=\"268\" data-theme-id=\"10606\" data-slug-hash=\"Jbzvm\" data-default-tab=\"result\" data-user=\"qetr1ck-op\" class='codepen'See the Pen a href='http://codepen.io/qetr1ck-op/pen/Jbzvm/'CSS3 transition effects example 5/a by qetr1ck-op (a href='http://codepen.io/qetr1ck-op'@qetr1ck-op/a) on a href='http://codepen.io'CodePen/a./p\n\n Example 6\n\n* *\n\nIn sixth example I performed that \"Sign In Form\" comes from the front, zooming out until its original size: transform: scale(from 10 to 1). And inputs will slide from bottom, used transform: translateY.\n\np data-height=\"271\" data-theme-id=\"10606\" data-slug-hash=\"Deijo\" data-default-tab=\"result\" data-user=\"qetr1ck-op\" class='codepen'See the Pen a href='http://codepen.io/qetr1ck-op/pen/Deijo/'CSS3 transition effects example 6/a by qetr1ck-op (a href='http://codepen.io/qetr1ck-op'@qetr1ck-op/a) on a href='http://codepen.io'CodePen/a./p\n\nExample 7\n\nIn this seven example the idea is to rotate the image to center and scale it down: transform: rotate(0deg)-(720deg) scale(1)-(0). Then the \"Sign In Form\" comes from up with description content following. transform: translateY()).\n\nAlso Added delay for the \"Sign In Form\" elements transition-delay: ..s. This will show us the rotating main block first and then the description will come into. In the reverse transition, everything will disappear immediately and image will rotate back.\n\np data-height=\"268\" data-theme-id=\"10606\" data-slug-hash=\"pIrwa\" data-default-tab=\"result\" data-user=\"qetr1ck-op\" class='codepen'See the Pen a href='http://codepen.io/qetr1ck-op/pen/pIrwa/'CSS3 transition effects example 7/a by qetr1ck-op (a href='http://codepen.io/qetr1ck-op'@qetr1ck-op/a) on a href='http://codepen.io'CodePen/a./p\n\n Example 8\n\nIn eighth example I used an animation which recreate a bounce effect. The \"Sign In Form\" will bounce in from top. animation: bounceY 0.9 linear.\n\nanimation: bounceY 0.9 linear\n\np data-height=\"277\" data-theme-id=\"10606\" data-slug-hash=\"veLhG\" data-default-tab=\"result\" data-user=\"qetr1ck-op\" class='codepen'See the Pen a href='http://codepen.io/qetr1ck-op/pen/veLhG/'CSS3 transition effects example 8/a by qetr1ck-op (a href='http://codepen.io/qetr1ck-op'@qetr1ck-op/a) on a href='http://codepen.io'CodePen/a./p\n\n",
        "tags": []
    },
    {
        "uri": "/post/pattern-craft",
        "title": "PatternCraft",
        "content": "\nAn awesome explanation of GOF design patterns. The only way to learn pattern is to know what problem it solves.\n\n!--more--\n\nState\n\nThe State Design Pattern can be used, for example, to manage the state of tank in StarCraft game.\n\nThe pattern consists in isolating the state logic in different classes than having multiple ifs to determinate the flow.\n\nclass TankState {\n    constructor(damage = 5, canMove = true) {\n        Object.assign(this, { damage, canMove });\n    }\n\n    static get defaultState() { return new SiegeState(); }\n}\n\n// state 1\nclass SiegeState extends TankState {\n    constructor() {\n        super(20, false);\n    }\n}\n\n// state #2\nclass SpeedState extends TankState {\n    constructor() {\n        super(5, true);\n    }\n}\n\nclass Tank {\n    constructor() {\n        this.state = TankState.defaultState;\n    }\n\n    // implementation bellow relies only on current state, without using multiple if/switch\n    get canMove() { return this.state.canMove; } \n\n    get damage() { return this.state.damage; }\n}\n\nTest specs:\n\ndescribe('State pattern', () = {\n    it('Default tank state is SiegeState', () = {\n        const tank = new Tank();\n        \n        expect(tank.state instanceof SiegeTank).to.be.true;\n    });\n\n    it('SiegeState', () = {\n        const tank = new SiegeState();\n\n        expect(tank.damage).to.equal(20);\n        expect(tank.canMove).to.be.false;\n    });\n\n    it('SpeedState', () = {\n        const tank = new SpeedState();\n\n        expect(tank.damage).to.equal(5);\n        expect(tank.canMove).to.be.true;\n    });\n})\n\nStrategy\n\nThe Strategy Design Pattern can be used, for example, to determinate how a unit moves in StarCraft game.\n\nThe pattern consists in having different strategy for one functionality. A unit, for example, can move by walking or flying or swimming.\n\n// strategy 1\nclass Walk() {\n    move(unit) {\n        unit.position += 5;\n    }\n}\n// strategy #2\nclass Fly() {\n    move(unit) {\n        unit.position += 20;\n    }\n}\n\nclass Viking {\n    constructor() {\n        this.moveBehavior = new Walk();\n        this.position = 0;\n    }\n\n    move() { this.moveBehavior.move(this); } // delegate behavior to strategy\n}\n\nTest specs:\n\ndescribe('Strategy pattern', () = {\n    it('Default viking move behavior is Walk', () = {\n        const viking = new Viking();\n        \n        expect(viking.moveBehavior instanceof Walk).to.be.true;\n    });\n\n    it('Walk behavior', () = {\n        const viking = new Viking();\n\n        viking.move();\n        expect(viking.position).to.equal(5);\n        viking.move();\n        expect(viking.position).to.equal(10);\n    });\n\n    it('Fly behavior', () = {\n        const viking = new Viking();\n        \n        viking.moveBehavior = new Fly();\n        viking.move();\n        expect(viking.position).to.equal(20);\n        viking.move();\n        expect(viking.position).to.equal(40);\n    });\n})\n\nAdapter\n\nThe Adapter Design Pattern can be used, to insert an external character in the game.\n\nThe pattern consists in having a wrapper class to adapt the external source.\n\n// in app characters\nclass Marine {\n  attack(target) {\n    target.health -= 6;\n  }\n}\n\nclass Zealot {\n  attack(target) {\n    target.health -= 8;\n  }\n}\n\nclass Zergling {\n  attack(target) {\n    target.health -= 5;\n  }\n}\n\n// external\nclass Mario {\n  jumpAttack() {\n    console.log('Mamamia!');\n    return 3;\n  }\n}\n\n// mario adapter\nclass MarioAdapter {\n    constructor(mario) {\n        this.mario = mario;\n    }\n    \n    attack(target) {\n        target.health -= this.mario.jumpAttack();\n    }\n}\n\nTest specs: \n\ndescribe('Adapter pattern', () = {\n    it('Mario can not attack', () = {\n        const mario = new Mario();\n        \n        expect(mario.attack).to.be.undefined;\n    });\n\n    it('MarioAdapter can attack', () = {\n        const mario = new MarioAdapter();\n        const target = { health: 50 };\n\n        mario.attack(target);\n\n        expect(target.health).to.equal(47);\n    });\n})\n\n Visitor\n\nThe Strategy Design Pattern can be used, for example, to determinate how an attack deals a different amount of damage to unit in StarCraft game.\n\nThe pattern delegates the responsibilities to different class. When a unit takes a damage it can say to the visitor what do with itself.\n\nclass Soldier {\n    constructor(health = 100) {\n        Object.assign(this, { health });\n    }\n}\n\nclass Marine extends Soldier {\n    constructor() {\n        super();\n    }\n    \n    // an idiomatic name\n    accept(visitor) {\n        visitor.visitLight(this);\n    }\n}\n\nclass Marauder extends Soldier {\n    constructor() {\n        super(180);\n    }\n    \n    accept(visitor) {\n        visitor.visitArmored(this);\n    }\n}\n\n// visitor\nclass TankBullet {\n    visitLight(unit) {\n        unit.health -= 11;\n    }\n    visitArmored(unit) {\n        unit.health -= 32;\n    }\n}\n\nTest specs: \n\ndescribe('Visitor pattern', () = {\n    it('Visit light', () = {\n        const marine = new Marine();\n        const tankBullet = new TankBullet();\n        \n        tankBullet.visitLight(marine);\n\n        expect(mario.health).to.be(89);\n    });\n\n    it('Visit armored', () = {\n        const marauder = new Marauder();\n        const tankBullet = new TankBullet();\n        \n        tankBullet.visitArmored(marauder);\n\n        expect(mario.health).to.be(148);\n    });\n})\n\nDecorator\n\nThe Decorator Design Pattern can be used, for example, to manage upgrades.\n\nThe pattern is consists in upgrade your base class with extra functionality.\n\nA decorator will receive an instance of base class and use it to call a new thing you want.\n\nclass Marine {\n    constructor(_damage, _armor) {\n        Object.assign(this, { _damage, _armor });\n    }\n\n    get damage { return this._damage; }\n    get armor { return this._armor; }\n}\n\n// decorator 1\nclass WeaponUpgrade {\n    constructor(unit) {\n        this.unit = unit;\n    }\n\n    get damage { return this.unit.damage + 1; }\n    get armor { return this.unit.armor; }\n}\n\n// decorator #2\nclass ArmorUpgrade {\n    constructor(unit) {\n        this.unit = unit;\n    }\n\n    get damage { return this.unit.damage; }\n    get armor { return this.unit.armor + 1; }\n}\n\nlet marine = new Marine();\nmarine = new WeaponUpgrade(marine);\nmarine = new WeaponUpgrade(marine);\n\nTest specs: \n\ndescribe('Decorator pattern', () = {\n    it('Weapon upgrade', () = {\n        let marine = new Marine(10, 2);\n        \n        marine = new WeaponUpgrade(marine);\n        marine = new WeaponUpgrade(marine);\n\n        expect(marine.damage).to.be(12);\n        expect(marine.armor).to.be(2);\n    });\n\n    it('Armor upgrade', () = {\n        let marine = new Marine(10, 2);\n        \n        marine = new ArmorUpgrade(marine);\n        marine = new ArmorUpgrade(marine);\n\n        expect(marine.armor).to.be(4);\n        expect(marine.damage).to.be(10);\n    });\n})\n\nStrategy\n\nThe Strategy Design Pattern can be used, for example, to queue actions.\n\nThe pattern consists in isolating command logic in a class so it can:\n\nqueue: you can queue actions to move a probe to a different locations\nundone: you can tell a probe to build something and then call a stop command to undo the action\nvalidate: you can check if the action can be executed or not, you can not move if building action is in progress\n\nclass Probe {\n    constructor(commands = [], minerals = 0, x = 0, y = 0) {\n        Object.assign(this, {\n            position: { x, y },\n            commands,\n            minerals\n        });\n    }\n\n    move(x, y) {\n        this.commands = [...this.commands, new MoveCommand(this, x, y)];\n    }\n\n    gather() {\n        this.commands = [...this.commands, new GatherCommand(this)];\n    }\n}\n\n// command 1\nclass MoveCommand {\n    constructor(unit, x, y) {\n        Object.assign(this, { unit, x, y});\n    }\n\n    // idiomatic \n    execute() {\n        this.unit.position.x = this.x;\n        this.unit.position.y = this.y;\n    }\n}\n\n// command #2\nclass GatherCommand {\n    constructor(unit) {\n        this.unit = unit;\n    }\n\n    execute() {\n        if (this.canExecute) {\n            this.unit.minerals += 5;\n        }\n    }\n\n    get canExecute() {\n        return this.unit.minerals === 0;\n    }\n}\n\nTest specs: \n\ndescribe('Command pattern', () = {\n    it('MoveCommand should move unit', () = {\n        const unit = new Probe();\n        const moveBehavior = new MoveBehavior(unit, 10, 20);\n\n        moveBehavior.execute();\n\n        expect(unit.position.x).to.equal(10);\n        expect(unit.position.y).to.equal(20);\n    });\n\n    it('GatherCommand should gather resources', () = {\n        const unit = new Probe();\n        const moveBehavior = new GatherBehavior(unit);\n\n        moveBehavior.execute();\n\n        expect(unit.materials).to.equal(5);\n    });\n\n    it('GatherCommand should only gather resources if unit does not have resources', () = {\n        const unit = new Probe();\n        const moveBehavior = new GatherBehavior(unit);\n\n        expect(unit.materials).to.equal(5);\n        moveBehavior.execute();\n        expect(unit.materials).to.equal(5);\n        moveBehavior.execute();\n        expect(unit.materials).to.equal(5);\n    });\n})\n\nProxy\n\nThe Proxy Design Pattern can be used, for example, to create a drone by using a proxy cocoon class.\n\nThe pattern is responsible (\"stands in\") for all requests on original object, typical extend or change behavior, than delegates action again to original object.\n\n// original\nclass Drone {\n    move(x, y) {\n        this.x = x;\n        this.y = y;\n    }\n}\n\n// proxy\nclass Cocoon {\n    constructor() {\n        this.lifetime = 3000;\n        // proxing\n        this.hatchDrone();\n    }\n\n    hatchDrone() {\n        setTimeout(this.onHatchDroneDone.bind(this), this.lifetime);\n    }\n    \n    onHatchDroneDone() {\n      this.drone = new Drone();\n      this.drone.move(this.rallyPath.x, this.rallyPath.y);\n    }\n\n    move(x, y) {\n        if (this.drone) {\n            this.drone.move(x, y);\n        } else {\n          this.rallyPath = { x, y };\n        }\n    }\n}\n\ndescribe('Proxy pattern', () = {\n    it('Create drone when cocoon is hatched', done = {\n        const drone = new Cocoon();\n        \n        drone.move(10, 20);\n\n        expect(drone.drone).to.be.undefined;\n        expect(drone.rallyPath).to.be({ x: 10, y: 20 });\n\n        setTimeout(() = {\n            expect(drone.drone).to.be.defined;\n            expect(drone.drone.x).to.be.equal(10);\n            expect(drone.drone.y).to.be.equal(20);\n            done();\n        }, drone.lifetime)\n    });\n\n    it('Visit armored', () = {\n        const marauder = new Marauder();\n        const tankBullet = new TankBullet();\n        \n        tankBullet.visitArmored(marauder);\n\n        expect(mario.health).to.be(148);\n    });\n})\n\nA classical JS example to proxing, for example, HTTP request by adding logging before every action:\n\n// proxy\nconst proxiedFetch = fetch;\n\nfetch = (url) = {\n    // proxing\n    console.log('logging...');\n    // original\n    proxiedFetch(url);\n}\n\nSave my day:\n\nOriginal series of John Lindquist\nJust a great resource of Design Patterns",
        "tags": []
    },
    {
        "uri": "/post/Performance-Javascript-adding-text-to-a-node",
        "title": "Performance: JavaScript adding text to a node",
        "content": "\nWhat is the most reasonable approach?\n\n!--more--\n\njQuery's .html() with previously encoded text\nQuery's .text()\ninnerHTML with previously encoded text\ninnerText / textContent\ndocument.createTextNode once per element\ndocument.createTextNode once per test run\n\n* *\n\nLink on jsPerf",
        "tags": []
    },
    {
        "uri": "/post/Performance-JavaScript-loops",
        "title": "Performance: JavaScript loops",
        "content": "\nIs it faster to use the native forEach or just loop with for?\n\n!--more--\n\nTypes of methods for test:\n\nforEach\nfor loop, simple\nfor loop, cached length\nfor loop, reverse\nfor loop, cached length, callback\n$.each\nfor ... in\nfor loop, reverse decrement\nother crazy loops\n\nIs it faster to use the native forEach or just loop with for?\n\nObviously, the most faster loop is for with cashed array length. But in my case it was ordinary for loop :)\n\nAlso I was confused that Array.forEach method is slowest more than 89% from classic for loop... \n\nScreenshot from jsperf: \n\nSaveMyDay:\n\non jsperf.com",
        "tags": []
    },
    {
        "uri": "/post/Practical-design-patterns-in-JavaScript",
        "title": "Practical design patterns in JavaScript",
        "content": "\n\nOne of the most important aspects of writing maintainable code is being able to notice the repeating themes in that code and optimize them. This is an area where knowledge of design patterns can prove invaluable.\n\nI take a look at a number of popular JavaScript design patterns and explore why certain patterns may be suitable for your projects.\n\n!--more--\n\nWhy is it important to understand patterns and be familiar with them?\n\nSo, why is it important to understand patterns and be familiar with them? Design patterns have three main benefits:\n\nPatterns are proven solutions: They provide solid approaches to solving issues in software development using proven techniques that reflect the experience and insights the developers that helped define them bring to the pattern.\nPatterns can be easily reused: A pattern usually reflects an out of the box solution that can be adapted to suit our own needs. \nPatterns can be expressive: When we look at a pattern there’s generally a set structure and vocabulary to the solution presented that can help express rather large solutions quite elegantly.\n\n Categories Of Design Pattern\n\nDesign patterns can be broken down into a number of different categories. In this section we’ll review three of these categories:\n\nCreation Design Patterns\n\nThe basic approach to object creation might otherwise lead to added complexity in a project whilst these patterns aim to solve this problem by controlling the creation process.\n\nSome of the patterns that fall under this category are: Constructor, Factory, Prototype, Singleton.\n\n Structural Design Patterns\n\nTypically identify simple ways to realize relationships between different objects.\n\nPatterns that fall under this category include: Decorator, Facade, Flyweight.\n\nBehavioral Design Patterns\n\nBehavioral patterns focus on improving the communication between disparate objects in a system.\n\nSome behavioral patterns include: Mediator, Observer.\n\n Table of 23 Design Patterns mentioned by the GoF\n\nI personally found the following table a very useful reminder of what a number of patterns has to offer - it covers the 23 Design Patterns mentioned by the GoF:\n\nCreation Design Patterns in depth\n\nDevelopers commonly wonder whether there is an ideal pattern or set of patterns they should be using in their workflow. There isn't a true single answer to this question; each script and web application we work on is likely to have its own individual needs and we need to think about where we feel a pattern can offer real value to an implementation.\n\n The Constructor Pattern\n\nIn classical object-oriented programming languages, a constructor is a special method used to initialize a newly created object once memory has been allocated for it. \n\nIn JavaScript, as almost everything is an object, we're most often interested in object constructors.\n\nObject Creation\n\n// Each of the following options will create a new empty object:\nconst newObject = {};\n \n// or\nconst newObject = Object.create( Object.prototype );\n \n// or\nconst newObject = new Object();\n\nWhere the Object constructor in the final example creates an object wrapper for a specific value, or where no value is passed, it will create an empty object and return it.\n\n Basic Constructors\n\nBy simply prefixing a call to a constructor function with the keyword new, we can tell JavaScript we would like the function to behave like a constructor and instantiate a new object with the members defined by that function.\n\nInside a constructor, the keyword this references the new object that's being created:\n\nfunction Car( model, year, miles ) {\n \n  Object.assign(this, { model, year, miles });\n \n  this.toString = function () {\n    return ${this.model} has done ${this.miles} miles;\n  };\n}\n \n// Usage:\nconst civic = new Car( \"Honda Civic\", 2009, 20000 );\nconst mondeo = new Car( \"Ford Mondeo\", 2010, 5000 );\n \nconsole.log( civic.toString() );\nconsole.log( mondeo.toString() );\n\nConstructors With Prototypes\n\nFunctions, like almost all objects in JavaScript, contain a prototype object. When we call a JavaScript constructor to create an object, all the properties of the constructor's prototype are then made available to the new object:\n\nfunction Car( model, year, miles ) {\n \n  Object.assign(this, { model, year, miles });\n \n}\n \n// Note here that we are using Object.prototype.newMethod rather than\n// Object.prototype so as to avoid redefining the prototype object\nCar.prototype.toString = () = ${this.model} has done ${this.miles} miles;\n \n// Usage:\nconst civic = new Car( \"Honda Civic\", 2009, 20000 );\nconst mondeo = new Car( \"Ford Mondeo\", 2010, 5000 );\n \nconsole.log( civic.toString() );\nconsole.log( mondeo.toString() );\n\n Constructors with ES6 class\n\nconst Car = class {\n    constructor(props) {\n        Object.assign(this, props);\n    }\n\n    toString() {\n        return ${this.model} has done ${this.miles} miles;\n    }\n}\n\n// Usage:\n \nconst civic = new Car( {model: \"Honda Civic\", year: 2009, miles: 20000} );\nconst mondeo = new Car( {model: \"Honda Civic\", year: 2009, miles: 20000} );\n \nconsole.log( civic.toString() );\nconsole.log( mondeo.toString() );\n\nConstructors with ES6 class for Node.js\n\n// in the end/or better on the beginning share you constructor\nmodule.exports = Car;\n\n Constructors in Angular1.x\n\n// Task.factory.js\nconst app = angular.module('taskManager');\n\napp.factory('Task', () = {\n    const Task = class {\n        constructor(name) {\n            this.name = name;\n            this.completed = false;\n        }\n\n        complete() {\n            this.complete = true;\n            console.log(compete task: ${this.name});\n        }\n\n        save() {\n            console.log(save task: ${this.name}); \n        }\n    }\n\n    return Task;\n})\n\nThe Module Pattern\n\nModules are an integral piece of any robust application's architecture and typically help in keeping the units of code for a project both cleanly separated and organized.\n\nIn JavaScript, there are several options for implementing modules. These include:\n\nThe Module pattern\nObject literal notation\nAMD modules\nCommonJS modules\nES6 modules\n\n The Revealing Module Pattern\n\nWe would simply define all of our functions and variables in the private scope and return an anonymous object with pointers to the private functionality we wished to reveal as public:\n\nvar myRevealingModule = (function () {\n    var privateVar = \"Ben Cherry\",\n        publicVar = \"Hey there!\";\n\n    function privateFunction() {\n        console.log( \"Name:\" + privateVar );\n    }\n\n    function publicSetName( strName ) {\n        privateVar = strName;\n    }\n\n    function publicGetName() {\n        privateFunction();\n    }\n\n    // Reveal public pointers to\n    // private functions and properties\n\n    return {\n        setName: publicSetName,\n        greeting: publicVar,\n        getName: publicGetName\n    };\n\n})();\n\nmyRevealingModule.setName( \"Paul Kinlan\" );\n\nThe Module Pattern for Node.js\n\n// just export what you need\n\nmodule.exports = myRevealingModule();\n\n// Usage:\nvar myModule = require('./myRevealingModule');\n\n// module.setName...\n\n The Module Pattern for Angular1.x\n\n// taskRepo.factory.js\nconst = app.module(taskManager);\n\napp.factory(taskRepo);\n\nfunction taskRepo($http) {\n    const db = {};\n\n    const get = (id) = {\n        log(Getting task ${id});\n    }\n\n    const save = (task) = {\n        log(Save ${task.nae} to the db);\n    }\n\n    return { get, save };\n}\ntaskRepo.$inject = ['$http'];\n\nThe Singleton Pattern\n\nIn JavaScript, Singletons serve as a shared resource namespace which isolate implementation code from the global namespace so as to provide a single point of access for functions:\n\nclass Singleton {\n\n  static instance;\n\n  constructor(){\n    if(instance){\n      return instance;\n    }\n\n    this.state = \"duke\";\n    this.instance = this;\n  }\n\n}\n\n// usage\nconst first = new Singleton();\nconst second = new Singleton();\n\nconsole.log(first === second); // true\n\n The Singleton Pattern for Node.js\n\nFrom Node.js docs information about caching modules:\n\nModules are cached after the first time they are loaded. This means (among other things) that every call to require('foo') will get exactly the same object returned, if it would resolve to the same file.\n\nIf you want to have a module execute code multiple times, then export a function, and call that function.\n\n// repo.js\n// just return a function call\n// for singleton\n\nmodule.exports = repo();\n\n// import a singleton\nconst require = repo();\n\nThe Singleton Pattern for Angular1.x\n\nBy default all service all singleton, because they are providers, more info here.\n\n The Factory Pattern\n\nFactory provide a generic interface for creating objects, where we can specify the type of factory object we wish to be created.\n\nImagine that we have a UI factory where we are asked to create a type of UI component. Rather than creating this component directly using the new operator or via another creation constructor, we ask a Factory object for a new component instead. We inform the Factory what type of object is required (e.g Button, Panel) and it instantiates this, returning it to us for use:\n\n// Types.js - Constructors used behind the scenes\n \n// A constructor for defining new cars\nfunction Car( options ) {\n \n  // some defaults\n  this.doors = options.doors || 4;\n  this.state = options.state || \"brand new\";\n  this.color = options.color || \"silver\";\n \n}\n \n// A constructor for defining new trucks\nfunction Truck( options){\n \n  this.state = options.state || \"used\";\n  this.wheelSize = options.wheelSize || \"large\";\n  this.color = options.color || \"blue\";\n}\n \n \n// FactoryExample.js\n \n// Define a skeleton vehicle factory\nfunction VehicleFactory() {}\n \n// Define the prototypes and utilities for this factory\n \n// Our default vehicleClass is Car\nVehicleFactory.prototype.vehicleClass = Car;\n \n// Our Factory method for creating new Vehicle instances\nVehicleFactory.prototype.createVehicle = function ( options ) {\n \n  switch(options.vehicleType){\n    case \"car\":\n      this.vehicleClass = Car;\n      break;\n    case \"truck\":\n      this.vehicleClass = Truck;\n      break;\n    //defaults to VehicleFactory.prototype.vehicleClass (Car)\n  }\n \n  return new this.vehicleClass( options );\n \n};\n \n// Create an instance of our factory that makes cars\nvar carFactory = new VehicleFactory();\nvar car = carFactory.createVehicle( {\n            vehicleType: \"car\",\n            color: \"yellow\",\n            doors: 6 } );\n \n// Test to confirm our car was created using the vehicleClass/prototype Car\n \n// Outputs: true\nconsole.log( car instanceof Car );\n \n// Outputs: Car object of color \"yellow\", doors: 6 in a \"brand new\" state\nconsole.log( car );\n\nAbstract Factories\n\nIt is also useful to be aware of the Abstract Factory pattern, which aims to encapsulate a group of individual factories with a common goal. \n\nIt separates the details of implementation of a set of objects from their general usage:\n\nvar abstractVehicleFactory = (function () {\n \n  // Storage for our vehicle types\n  var types = {};\n \n  return {\n      getVehicle: function ( type, customizations ) {\n          var Vehicle = types[type];\n \n          return (Vehicle ? new Vehicle(customizations) : null);\n      },\n \n      registerVehicle: function ( type, Vehicle ) {\n          var proto = Vehicle.prototype;\n \n          // only register classes that fulfill the vehicle contract\n          if ( proto.drive && proto.breakDown ) {\n              types[type] = Vehicle;\n          }\n \n          return abstractVehicleFactory;\n      }\n  };\n})();\n \n \n// Usage:\nabstractVehicleFactory.registerVehicle( \"car\", Car );\nabstractVehicleFactory.registerVehicle( \"truck\", Truck );\n \n// Instantiate a new car based on the abstract vehicle type\nvar car = abstractVehicleFactory.getVehicle( \"car\", {\n            color: \"lime green\",\n            state: \"like new\" } );\n \n// Instantiate a new truck in a similar manner\nvar truck = abstractVehicleFactory.getVehicle( \"truck\", {\n            wheelSize: \"medium\",\n            color: \"neon yellow\" } );\n\n Structural Design Patterns in depth\n\nStructural design patterns are ones that focus on easing the relationship between different components of an application. They help to provide stability by ensuring that if one part of the app changes, the entire thing doesn't need to as well.\n\nMixins \n\nMixins allow objects to borrow (or inherit) functionality from them with a minimal amount of complexity. \n\nImagine that we define a Mixin containing utility functions in a standard object literal as follows:\n\nvar myMixins = {\n \n  moveUp: function(){\n    console.log( \"move up\" );\n  },\n \n  moveDown: function(){\n    console.log( \"move down\" );\n  },\n \n  stop: function(){\n    console.log( \"stop! in the name of love!\" );\n  }\n \n};\n\nWe can then easily extend the prototype of existing constructor functions to include this behavior using a helper such as the Underscore.js _.extend() method:\n\n// A skeleton carAnimator constructor\nfunction CarAnimator(){\n  this.moveLeft = function(){\n    console.log( \"move left\" );\n  };\n}\n \n// A skeleton personAnimator constructor\nfunction PersonAnimator(){\n  this.moveRandomly = function(){ /../ };\n}\n \n// Extend both constructors with our Mixin\n_.extend( CarAnimator.prototype, myMixins );\n_.extend( PersonAnimator.prototype, myMixins );\n \n// Create a new instance of carAnimator\nvar myAnimator = new CarAnimator();\nmyAnimator.moveLeft();\nmyAnimator.moveDown();\nmyAnimator.stop();\n \n// Outputs:\n// move left\n// move down\n// stop! in the name of love!\n\n Mixins with ES6\n\nObject.assign( CarAnimator.prototype, myMixins );\nObject.assign( PersonAnimator.prototype, myMixins );\n\nThe Decorator Pattern\n\nThe Decorator pattern isn't heavily tied to how objects are created but instead focuses on the problem of extending their functionality.\n\nAdding new attributes to objects in JavaScript is a very straight-forward process so with this in mind, a very simplistic decorator may be implemented as follows:\n\n// The constructor to decorate\nfunction MacBook() {\n \n  this.cost = function () { return 997; };\n  this.screenSize = function () { return 11.6; };\n \n}\n \n// Decorator 1\nfunction memory( macbook ) {\n \n  var v = macbook.cost();\n  macbook.cost = function() {\n    return v + 75;\n  };\n \n}\n \n// Decorator 2\nfunction engraving( macbook ){\n \n  var v = macbook.cost();\n  macbook.cost = function(){\n    return v + 200;\n  };\n \n}\n \n// Decorator 3\nfunction insurance( macbook ){\n \n  var v = macbook.cost();\n  macbook.cost = function(){\n     return v + 250;\n  };\n \n}\n \nvar mb = new MacBook();\nmemory( mb );\nengraving( mb );\ninsurance( mb );\n \n// Outputs: 1522\nconsole.log( mb.cost() );\n \n// Outputs: 11.6\nconsole.log( mb.screenSize() );\n\n The Decorator Pattern in Angular1.x\n\nMore information about decorator method in off documentation or here\n\nangular.module( \"Demo\", [] );\n\nangular.module( \"Demo\" ).run(\n    function runBlock( greeting ) {\n        console.log( greeting( \"Joanna\" ) );\n    }\n);  \n\nangular.module( \"Demo\" ).factory(\n    \"greeting\",\n    function greetingFactory() {\n        return( greeting );\n        // I return a greeting for the given name.\n        function greeting( name ) {\n            return( \"Hello \" + name + \".\" );\n        }\n    }\n);\n\nangular.module( \"Demo\" ).decorator(\n    \"greeting\",\n    function greetingDecorator( $delegate ) {\n        // Return the decorated service.\n        return( decoratedGreeting );\n        // I append a new message to the existing greeting.\n        function decoratedGreeting( name ) {\n            return( $delegate( name ) + \" How are you doing?\" );\n        }\n    }\n);\n\nSub-classing\n\nSub-classing is a term that refers to inheriting properties for a new object from a base or superclass object. In traditional object-oriented programming, a class B is able to extend another class A. Here we consider A a superclass and B a subclass of A. As such, all instances of B inherit the methods from A. B is however still able to define its own methods, including those that override methods originally defined by A.\n\nWe first need a base object:\n\nvar Person = function( firstName, lastName ){\n \n  this.firstName = firstName;\n  this.lastName = lastName;\n  this.gender = \"male\";\n \n};\n\nNext, we'll want to specify a new class (object) that's a subclass of the existing Person object:\n\n// a new instance of Person can then easily be created as follows:\nvar clark = new Person( \"Clark\", \"Kent\" );\n \n// Define a subclass constructor for for \"Superhero\":\nvar Superhero = function( firstName, lastName, powers ){\n \n    // Invoke the superclass constructor on the new object\n    // then use .call() to invoke the constructor as a method of\n    // the object to be initialized.\n \n    Person.apply( this, arguments );\n \n    // Finally, store their powers, a new array of traits not found in a normal \"Person\"\n    this.powers = powers;\n};\n \nSuperhero.prototype = Object.create( Person.prototype );\nvar superman = new Superhero( \"Clark\", \"Kent\", [\"flight\",\"heat-vision\"] );\n\n Sub-classing with ES6\n\nclass Person {\n  constructor ( firstName, lastName, gender = \"male\" ){\n  \n    Object.assign(this, { firstName, lastName, gender });\n  \n  };\n}\n\nclass Superhero extends Person {\n  constructor ( firstName, lastName, gender, powers ){\n    super(firstName, lastName, gender);\n    this.powers = powers;\n  };\n}\n\n// usage\nconst superman = new Superhero( \"Clark\", \"Kent\", \"female\", [\"flight\",\"heat-vision\"] );\n\nThe Facade Pattern\n\nThis pattern provides a convenient higher-level interface to a larger body of code, hiding its true underlying complexity.\n\nWhenever we use jQuery's $(el).css() or $(el).animate() methods, we're actually using a Facade - the simpler public interface that avoids us having to manually call the many internal methods in jQuery core required to get some behavior working.\n\nIn a similar manner, we're all familiar with jQuery's $(document).ready(..). Internally, this is actually being powered by a method called bindReady(), which is doing this:\n\nbindReady: function() {\n    ...\n    if ( document.addEventListener ) {\n      // Use the handy event callback\n      document.addEventListener( \"DOMContentLoaded\", DOMContentLoaded, false );\n \n      // A fallback to window.onload, that will always work\n      window.addEventListener( \"load\", jQuery.ready, false );\n \n    // If IE event model is used\n    } else if ( document.attachEvent ) {\n \n      document.attachEvent( \"onreadystatechange\", DOMContentLoaded );\n \n      // A fallback to window.onload, that will always work\n      window.attachEvent( \"onload\", jQuery.ready );\n               ...\n\n Flyweight\n\nThe Flyweight pattern is a classical structural solution for optimizing code that is repetitive, slow and inefficiently shares data. It aims to minimize the use of memory in an application by sharing as much data as possible with related objects\n\nThere are two ways in which the Flyweight pattern can be applied. The first is at the data-layer, where we deal with the concept of sharing data between large quantities of similar objects stored in memory.\n\nThe second is at the DOM-layer where the Flyweight can be used as a central event-manager to avoid attaching event handlers to every child element in a parent container we wish to have some similar behavior.\n\nBehavior Design Patterns in depth\n\n The observer\n\nThe Observer is a design pattern where an object (known as a subject) maintains a list of objects depending on it (observers), automatically notifying them of any changes to state.\n\nWe can now expand on what we've learned to implement the Observer pattern with the following components:\n\nSubject: maintains a list of observers, facilitates adding or removing observers\nObserver: provides a update interface for objects that need to be notified of a Subject's changes of state\nConcreteSubject: broadcasts notifications to observers on changes of state, stores the state of ConcreteObservers\nConcreteObserver: stores a reference to the ConcreteSubject, implements an update interface for the Observer to ensure state is consistent with the Subject's\n\nFirst, let's model the list of dependent Observers a subject may have:\n\nfunction ObserverList(){\n  this.observerList = [];\n}\n \nObserverList.prototype.add = function( obj ){\n  return this.observerList.push( obj );\n};\n \nObserverList.prototype.count = function(){\n  return this.observerList.length;\n};\n \nObserverList.prototype.get = function( index ){\n  if( index  -1 && index < this.observerList.length ){\n    return this.observerList[ index ];\n  }\n};\n \nObserverList.prototype.indexOf = function( obj, startIndex ){\n  var i = startIndex;\n \n  while( i < this.observerList.length ){\n    if( this.observerList[i] === obj ){\n      return i;\n    }\n    i++;\n  }\n \n  return -1;\n};\n \nObserverList.prototype.removeAt = function( index ){\n  this.observerList.splice( index, 1 );\n};\n\nThe Subject and the ability to add, remove or notify observers on the observer list:\n\nfunction Subject(){\n  this.observers = new ObserverList();\n}\n \nSubject.prototype.addObserver = function( observer ){\n  this.observers.add( observer );\n};\n \nSubject.prototype.removeObserver = function( observer ){\n  this.observers.removeAt( this.observers.indexOf( observer, 0 ) );\n};\n \nSubject.prototype.notify = function( context ){\n  var observerCount = this.observers.count();\n  for(var i=0; i < observerCount; i++){\n    this.observers.get(i).update( context );\n  }\n};\n\nFull example here\n\nDifferences Between The Observer And Publish/Subscribe Pattern\n\nWhilst the Observer pattern is useful to be aware of, quite often in the JavaScript world, we'll find it commonly implemented using a variation known as the Publish/Subscribe pattern.\n\nThe Publish/Subscribe pattern however uses a topic/event channel which sits between the objects wishing to receive notifications (subscribers) and the object firing the event (the publisher). \n\nThis event system allows code to define application specific events which can pass custom arguments containing values needed by the subscriber. The idea here is to avoid dependencies between the subscriber and publisher.\n\nHere is an example of how one might use the Publish/Subscribe if provided with a functional implementation powering publish(),subscribe() and unsubscribe() behind the scenes:\n\nvar eventBus = (function(){\n  var topics = Object.create({});\n  \n  return {\n    subscribe: function(topic, listener) {\n      // Create the topic's object if not yet created\n      if(!topics[topic]) topics[topic] = [];\n\n      // Add the listener to queue\n      var index = topics[topic].push(listener) -1;\n\n      // Provide handle back for removal of topic\n      return {\n        unsubscribe: function() {\n          delete topicstopic;\n        }\n      };\n    },\n    publish: function(topic, info) {\n      // If the topic doesn't exist, or there's no listeners in queue, just leave\n      if(!topics[topic]) return;\n\n      // Cycle through topics queue, fire!\n      topics[topic].forEach(function(item) {\n            item(info != undefined ? info : {});\n      });\n    }\n  };\n})();\n\nSubscribe in order to be notified for events:\nvar subscription = events.subscribe('/page/load', function(obj) {\n    // Do something now that the event has occurred\n});\n\n// ...sometime later where I no longer want subscription...\nsubscription.unsubscribe();\n\nPublishing: \n\nevents.publish('/page/load', {\n    url: '/some/url/path' // any arguments\n});\n`",
        "tags": []
    },
    {
        "uri": "/post/Preflighted-HTTP-OPTIONS-requests",
        "title": "Preflighted HTTP OPTIONS requests",
        "content": "\nWhat is not-so-simple HTTP request?\n\n!--more--\n\nThe Cross-Origin Resource sharing short overview\n\nThe CORS standard works by adding new HTTP headers that allows servers to describe the sets of origins that are permitted to read that information.\n\nIf browser performs request with \"side-effects\" aka not a \"simple request\", the specification says that that browser need to \"preflight\" an HTTP OPTIONS request. And then, upon \"approval\" from the server, sends the actual request.\n\n The \"simple request\"\n\nA simple cross-site request is one that meets all the following conditions:\n\nThe only allowed methods are:\n\nGET\nHEAD\nPOST\n\nApart the headers which are set automatically by the browser (Connection, User-Agent, etc.), the only headers which are allowed to be manually set are:\n\nAccept\nAccept-Language\nContent-Language\nContent-Type\n\nThe only allowed values for the Content-Type header are:\n\napplication/x-www-form-urlencoded\nmultipart/form-data\ntext/plain\n\nPreflighted requests\n\nUnlike simple requests, \"preflighted\" first send an HTTP request by the OPTIONS method to the resource on the server, in order to determine whether the actual request is safe to send.\n\nAn example which creates XHR and an HTTP transaction log.\n\n CORS flow\n\nAn awesome diagram of processing HTTP CORS transaction",
        "tags": []
    },
    {
        "uri": "/post/prettier-as-a-formating-tool-for-JS",
        "title": "Prettier as a formating tool for JS",
        "content": "\nPrettier is an opinionated JavaScript formatter with advanced support for language features from ES2017, JSX, and Flow. It removes all original styling and ensures that all outputted JavaScript conforms to a consistent style. \n\nThis goes way beyond ESLint and other projects built on it. Unlike ESLint, there aren't a million configuration options and rules. But more importantly: everything is fixable. This works because Prettier never \"checks\" anything; it takes JavaScript as input and delivers the formatted JavaScript as output.\n\nIn technical terms: Prettier parses your JavaScript into an AST (Abstract Syntax Tree) and pretty-prints the AST, completely ignoring any of the original formatting. Say hello to completely consistent syntax!\n\nLinks\n\nGithub repo\nIntegration list app\nIntegration with WebStorm\n",
        "tags": []
    },
    {
        "uri": "/post/Prevent-CSS-Caching",
        "title": "Prevent CSS Caching in Wordpress",
        "content": "\nIf you update your WordPress theme’s style.css, you may have noticed that you have to “force-reload” your site in your browser to see the changes. This is because your browser keeps a copy of the CSS cached on your hard drive. \n\n!--more--\n\nDepending on how your server is set up, it may not check for a new version of the stylesheet for a couple hours, or longer! And even if you force-reload to see the changes, visitors who have previously accessed your site may still get the old CSS. \n\nOne way to solve this is to “version” your CSS file, by adding:\n\n<link rel=\"stylesheet\" \nhref=\"?php bloginfo('stylesheeturl'); echo '?' . filemtime( getstylesheet_directory() . '/style.css'); ?\" type=\"text/css\" media=\"screen, projection\" /\n\nSave my day: \n\nMark post\nCss-tricks",
        "tags": []
    },
    {
        "uri": "/post/Reading-files-in-JavaScript-with-File-API",
        "title": "Reading files in JavaScript with File API",
        "content": "\nReading files in Javascript with File API\n\n!--more--\n\nOverview\n\nUsing File API or file-reader interfaces on the client side code can be checked as to whether the MIME type of the uploaded file to its expansion, or set limits on the size.\n\nThis spec provides an API for representing file objects in web applications:\n\nA FileList interface, which represents an array of individually selected files from the underlying system. The user interface for selection can be invoked via input type=\"file\" multiple\nA File interface, which includes readonly informational attributes about a file such as its name, MIME type, and the date of the last modification\nA Blob interface, which represents immutable raw binary data, and allows access to ranges of bytes within the Blob object as a separate Blob.\nA FileReader interface, which provides methods to read a File or a Blob, and an event model to obtain the results of these reads.\nA URL scheme for use with binary data such as files, so that they can be referenced within web applications.\n\n   Check for the File API support.\n\n// Check for the various File API support.\nif (window.File && window.FileReader && window.FileList && window.Blob) {\n  // Great success! All the File APIs are supported.\n} else {\n  alert('The File APIs are not fully supported in this browser.');\n}\n\nUsing form input for selecting\n\nThe most straightforward way to load a file is to use a standard input type=\"file\" element. JavaScript returns the list of selected File objects as a FileList. Here's an example that uses the multiple attribute to allow selecting several files at once:\n\ninput type=\"file\" id=\"files\" name=\"files[]\" multiple /\noutput id=\"list\"/output\n\nscript\n  function handleFileSelect(evt) {\n    var files = evt.target.files; // FileList object\n\n    // files is a FileList of File objects. List some properties.\n    var output = [];\n    for (var i = 0, f; f = files[i]; i++) {\n      output.push('li', escape(f.name), ' (', f.type || 'n/a', ') - ',\n                  f.size, ' bytes, last modified: ',\n                  f.lastModifiedDate ? f.lastModifiedDate.toLocaleDateString() : 'n/a',\n                  '/li');\n    }\n    document.getElementById('list').innerHTML = 'ul' + output.join('') + '/ul';\n  }\n\n  document.getElementById('files').addEventListener('change', handleFileSelect, false);\n/script\n\nscript async src=\"//assets.codepen.io/assets/embed/ei.js\"/script\np data-height=\"185\" data-theme-id=\"10606\" data-slug-hash=\"nhHCi\" data-default-tab=\"result\" data-user=\"qetr1ck-op\" class='codepen'See the Pen a href='http://codepen.io/qetr1ck-op/pen/nhHCi/'Using form input for selecting/a by qetr1ck-op (a href='http://codepen.io/qetr1ck-op'@qetr1ck-op/a) on a href='http://codepen.io'CodePen/a./p\n\n    Using drag and drop for selecting\n\nAnother technique for loading files is native drag and drop from the desktop to the browser. We can modify the previous example slightly to include drag and drop support:\n\ndiv id=\"drop_zone\"Drop files here/div\noutput id=\"list\"/output\n\nscript\n  function handleFileSelect(evt) {\n    evt.stopPropagation();\n    evt.preventDefault();\n\n    var files = evt.dataTransfer.files; // FileList object.\n\n    // files is a FileList of File objects. List some properties.\n    var output = [];\n    for (var i = 0, f; f = files[i]; i++) {\n      output.push('li', escape(f.name), ' (', f.type || 'n/a', ') - ',\n                  f.size, ' bytes, last modified: ',\n                  f.lastModifiedDate ? f.lastModifiedDate.toLocaleDateString() : 'n/a',\n                  '/li');\n    }\n    document.getElementById('list').innerHTML = 'ul' + output.join('') + '/ul';\n  }\n\n  function handleDragOver(evt) {\n    evt.stopPropagation();\n    evt.preventDefault();\n    evt.dataTransfer.dropEffect = 'copy'; // Explicitly show this is a copy.\n  }\n\n  // Setup the dnd listeners.\n  var dropZone = document.getElementById('drop_zone');\n  dropZone.addEventListener('dragover', handleDragOver, false);\n  dropZone.addEventListener('drop', handleFileSelect, false);\n/script\n\np data-height=\"268\" data-theme-id=\"10606\" data-slug-hash=\"EnsgL\" data-default-tab=\"result\" data-user=\"qetr1ck-op\" class='codepen'See the Pen a href='http://codepen.io/qetr1ck-op/pen/EnsgL/'Using drag and drop for selecting/a by qetr1ck-op (a href='http://codepen.io/qetr1ck-op'@qetr1ck-op/a) on a href='http://codepen.io'CodePen/a./p\n\nReading files\n\nNow comes the fun part!\n\nAfter you've obtained a File reference, instantiate a FileReader object to read its contents into memory. When the load finishes, the reader's onload event is fired and its result attribute can be used to access the file data.\n\nFileReader includes four options for reading a file, asynchronously:\n\nFileReader.readAsBinaryString(Blob|File) - The result property will contain the file/blob's data as a binary string. Every byte is represented by an integer in the range [0..255]\nFileReader.readAsText(Blob|File, opt_encoding) - The result property will contain the file/blob's data as a text string. By default the string is decoded as 'UTF-8'. Use the optional encoding parameter can specify a different format.\nFileReader.readAsDataURL(Blob|File) - The result property will contain the file/blob's data encoded as a data URL.\nFileReader.readAsArrayBuffer(Blob|File) - The result property will contain the file/blob's data as an ArrayBuffer object.\n\nOnce one of these read methods is called on your FileReader object, the onloadstart, onprogress, onload, onabort, onerror, and onloadend can be used to track its progress.\n\nThe example below filters out images from the user's selection, calls reader.readAsDataURL() on the file, and renders a thumbnail by setting the src attribute to a data URL:\n\nstyle\n  .thumb {\n    height: 75px;\n    border: 1px solid 000;\n    margin: 10px 5px 0 0;\n  }\n/style\n\ninput type=\"file\" id=\"files\" name=\"files[]\" multiple /\noutput id=\"list\"/output\n\nscript\n  function handleFileSelect(evt) {\n    var files = evt.target.files; // FileList object\n\n    // Loop through the FileList and render image files as thumbnails.\n    for (var i = 0, f; f = files[i]; i++) {\n\n      // Only process image files.\n      if (!f.type.match('image.*')) {\n        continue;\n      }\n\n      var reader = new FileReader();\n\n      // Closure to capture the file information.\n      reader.onload = (function(theFile) {\n        return function(e) {\n          // Render thumbnail.\n          var span = document.createElement('span');\n          span.innerHTML = ['<img class=\"thumb\" src=\"', e.target.result,\n                '\" title=\"', escape(f.name), '\"/'\n            ].join('');;\n          document.getElementById('list').insertBefore(span, null);\n        };\n      })(f);\n\n      // Read in the image file as a data URL.\n      reader.readAsDataURL(f);\n    }\n  }\n\n  document.getElementById('files').addEventListener('change', handleFileSelect, false);\n/script\n\np data-height=\"187\" data-theme-id=\"10606\" data-slug-hash=\"sJpmy\" data-default-tab=\"result\" data-user=\"qetr1ck-op\" class='codepen'See the Pen a href='http://codepen.io/qetr1ck-op/pen/sJpmy/'sJpmy/a by qetr1ck-op (a href='http://codepen.io/qetr1ck-op'@qetr1ck-op/a) on a href='http://codepen.io'CodePen/a./p\n\nMonitoring the progress of a read\n\nOne of the nice things that we get for free when using async event handling is the ability to monitor the progress of the file read; useful for large files, catching errors, and figuring out when a read is complete.\n\nThe onloadstart and onprogress events can be used to monitor the progress of a read.\n\nstyle\n  progress_bar {\n    margin: 10px 0;\n    padding: 3px;\n    border: 1px solid #000;\n    font-size: 14px;\n    clear: both;\n    opacity: 0;\n    -moz-transition: opacity 1s linear;\n    -o-transition: opacity 1s linear;\n    -webkit-transition: opacity 1s linear;\n  }\n  #progress_bar.loading {\n    opacity: 1.0;\n  }\n  #progress_bar .percent {\n    background-color: #99ccff;\n    height: auto;\n    width: 0;\n  }\n/style\n\ninput type=\"file\" id=\"files\" name=\"file\" /\nbutton onclick=\"abortRead();\"Cancel read/button\ndiv id=\"progress_bar\"div class=\"percent\"0%/div/div\n\nscript\n  var reader;\n  var progress = document.querySelector('.percent');\n\n  function abortRead() {\n    reader.abort();\n  }\n\n  function errorHandler(evt) {\n    switch(evt.target.error.code) {\n      case evt.target.error.NOTFOUNDERR:\n        alert('File Not Found!');\n        break;\n      case evt.target.error.NOTREADABLEERR:\n        alert('File is not readable');\n        break;\n      case evt.target.error.ABORT_ERR:\n        break; // noop\n      default:\n        alert('An error occurred reading this file.');\n    };\n  }\n\n  function updateProgress(evt) {\n    // evt is an ProgressEvent.\n    if (evt.lengthComputable) {\n      var percentLoaded = Math.round((evt.loaded / evt.total) * 100);\n      // Increase the progress bar length.\n      if (percentLoaded < 100) {\n        progress.style.width = percentLoaded + '%';\n        progress.textContent = percentLoaded + '%';\n      }\n    }\n  }\n\n  function handleFileSelect(evt) {\n    // Reset progress indicator on new file selection.\n    progress.style.width = '0%';\n    progress.textContent = '0%';\n\n    reader = new FileReader();\n    reader.onerror = errorHandler;\n    reader.onprogress = updateProgress;\n    reader.onabort = function(e) {\n      alert('File read cancelled');\n    };\n    reader.onloadstart = function(e) {\n      document.getElementById('progress_bar').className = 'loading';\n    };\n    reader.onload = function(e) {\n      // Ensure that the progress bar displays 100% at the end.\n      progress.style.width = '100%';\n      progress.textContent = '100%';\n      setTimeout(\"document.getElementById('progress_bar').className='';\", 2000);\n    }\n\n    // Read in the image file as a binary string.\n    reader.readAsBinaryString(evt.target.files[0]);\n  }\n\n  document.getElementById('files').addEventListener('change', handleFileSelect, false);\n/script\n\np data-height=\"216\" data-theme-id=\"10606\" data-slug-hash=\"GKbhy\" data-default-tab=\"result\" data-user=\"qetr1ck-op\" class='codepen'See the Pen a href='http://codepen.io/qetr1ck-op/pen/GKbhy/'Monitoring the progress of a read/a by qetr1ck-op (a href='http://codepen.io/qetr1ck-op'@qetr1ck-op/a) on a href='http://codepen.io'CodePen/a./p\n\nSaveMyDay:\n\nFile Api library\nhtml5rocks.com",
        "tags": []
    },
    {
        "uri": "/post/Reset-Checkout-and-Revert",
        "title": "Git reset, checkout and revert",
        "content": "\nThe git reset, git checkout and git revert let you to undo changes in repository, and the first two can be use to manipulate either commits or individual files.\n\n!--more--\n\nThe image bellow will help to think about each command in terms of their effect on the three main components of Git workflow. Keep this components always in mind when you're working with this commands.\n\nReset\n\nOn the commit-level, resetting is way to move a tip of a branch to a different commit. This can be used to remove commits from the current branch. Following command moves branch backwards by two commits:\n\ngit checkout hotfix\ngit reset HEAD~2\n\nIn other words, you're saying that you want to throw away this commits:\n\nThis usage of git reset is a simple way to undo changes that haven't been shared with any one else. I use this command when I've started working on feature find myself thinking that, \"Oh crap, what am I doing? I should start over\".\n\nThere are following flags:\n\n--soft - the stage and working areas are not altered in this way\n--mixed - only the staged area is affected. This is option be default\n--hard - the stage and working are both updated to match the specific commit\n\nIt's easer to thing of these modes by their scope:\n\nThe command is often used with HEAD or with serious of commits hash as the parameter:\n\n has effect on unstaging all changes, but leaves them in a working directory\ngit reset --mixed HEAD\n\ncompletely throw away all changes\ngit reset --hard HEAD\n\n reset a specif commit\ngit reset --hard commit-hash\n\nreset a series using ancestor notation\ngit reset dev~5..dev\n\n reset a series using commit hashes\ngit reset --no-edit ffffffff..12345678\n\nBe careful when passing other than HEAD, since this re-writes the current branch history\n\nCheckout\n\nWhen passed a branch name, it lets you to switch between branches:\n\ngit checkout hotfix\n\nInternally it moves HEAD to a different branch updates the working directory to match. Since this has a potential to overwrite local changes, Git forces you to commit or stash any changes in a working directory. Unlike git reset it doesn't move any branches around.\n\nI can also check arbitrary commits by passing the commit reference of the branch:\n\ngit checkout HEAD~2\n\nThis is useful for quickly inspecting an old version of your project. However, since there are no reference to the current HEAD, this puts you in a detached HEAD state. This can be dangerous if you start adding new commits, because there won't be a way to get back them after you switch to an another branch. For this reason, you should always create a new branch before adding commits to a detached HEAD.\n\n Revert\n\nReverting undoes a commit by creating a new commit. This is a safe way to undo changes, as it has no change of re-writing the commit history. For example, the following command will figure out the changes in the 2nd to last commit, create a new commit to undoing these changes:\n\ngit checkout hotfix\ngit revert HEAD~2\n\nThat can be visualized as following:\n\nContrast this with git reset, which does alter the existing commit history. For this reason git revert should be used to undo changes on a public branch and git reset should be reserved for undoing changes on a private branch.\n\nYou can also think of a git revert as a tool for undoing committed changes, while git reset HEAD is for undoing uncommitted changes.\n\nIf I just want to revert with a specific commit I use --no-commit:\n\n-n is shortcut for --no-commit\ngit revert -n commit hash\ngit commit -m 'the commit message'\n\nAnother flow can be if you want to revert multiple commits:\n\ngit revert --no-commit commit hash A\ngit revert --no-commit commit hash B\ngit revert --no-commit commit hash C\ngit commit -m 'the commit message'\n\nIf there are sequence of commits which I want to revert:\n\ngit revert --no-commit HEAD~3..\n or\ngit revert --no-commit A..HEAD  \ngit commit -m 'the commit message'\n\nThe problem can be appeared when you want to revert a merge commit. The -m parameter specified the parent number. This is need because a merge commit has more than one parent, and Git doesn't know which parent was the mainline, and which parent was the branch you want to un-merge.\n\ngit revert -m 1 commit-hash \ngit commit -m \"Reverting the last merge-commit which messed the repo.\"\ngit push -u origin master\n\nThe dedicating answer about how to revert merged commit which has been pushed on remote\n\nSave my day:\n\nAdvanced Git Tutorials",
        "tags": []
    },
    {
        "uri": "/post/RESTful-Web-Services-with-Node-js-and-Express",
        "title": "RESTful Web Services with Node.js and Express",
        "content": "\nNode.js is a simple and powerful tool for backend development. When combined with express, you can create lightweight, fast, scalable APIs quickly and simply.\n!--more--\n\nWhat is REST anyway?\n\nThe term REpresentational S**tate **Transfer came from a dissertation written by Roy Fielding back in 2000.\nHe described a series of constraints that should be in place whenever two systems talk to each other. \n\nSo ultimately REST is just a series of rules in place for your server, so everyone who uses your service understand \nwhat it does and how it works.\n\n The Uniform interface\n\nWhenever you're dealing with RESTful service you'll be dealing with a resource or resources and all that really means\nis you're dealing with with nouns.\n\nUniform resource are built around things, not actions.\n\nFor example dealing with books as a resource, the url be http://domain/books. With authors it would be /authors.\n\nThe another part of uniform interface are HTTP verbs that we use in our request will dictate the type of activity\nwe're trying to do on the resource:\n\nGET will simply request data (/books get all or /books/:id a unique book)\nPOST uses to add data (/books add new book)\nDELETE will remove an entity (books/:id)\nPUT is used for update or replace a resource\nPATCH updates piece of that resource\n\nThe last part of interface is HATEOS (Hypermedia as the Engine of Application State). Basically all that means is \nthat in each request will be a set of hyperlinks that you can use to navigate the API. In example, what type of \nactions you can do on a particular resource.\n\nThe project \n\nThe project walk through how to stand up a lightweight Express server serving truly RESTful services using Node.js, Mongoose, and MongoDB. \nThere are implemented all of the RESTful verbs to get, add, and update data with working through unit and e2e-integration tests for our services.\n\nLink on GitHub \n\nSave my day:\n\nRESTful Web Services with Node.js and Express by Jonathan Mills on pluralsight",
        "tags": []
    },
    {
        "uri": "/post/simple-favicon-generator",
        "title": "Favicon generator",
        "content": "\nWith so many platforms and icons, it's hard to know exactly what you should do. What are the dimensions of favicon.ico? How many Touch icons do I need? RealFaviconGenerator did the research and testing for you.\n\n!--more--\n\nLink\n\nrealfavicongenerator.net",
        "tags": []
    },
    {
        "uri": "/post/Start-new-project-on-Angular-1-5",
        "title": "Start new project on Angular ^1.5",
        "content": "\nGreat series of recommendation how/why to start new \"NG2 ready\" Angular 1.5 app with architecture of component-oriented approach.\n\n!--more--\n\nHow to do it right\n\nStarting a new app in Angular 1.5, does it make sense?\nAngular 1.5 app as tree of components\nCommunication between Angular 1.5 components and with API\nA flexible Angular 1.5 project structure (the \"fractal\" approach)\nWriting Angular 1.5 in ES6\nUnit testing Angular 1.5 components\n\n Style guides for app\n\nAngularJS styleguide from Todd Motto\n\nGenerators\n\nYo gulp-angular generator",
        "tags": []
    },
    {
        "uri": "/post/static-site-with-a-dynamic-search",
        "title": "A static site with a dynamic search function",
        "content": "\nA static site with a dynamic search function? Yes. Alternatively to embeddable scripts from Google or other search engines you can provide your visitors a custom search by indexing your content files directly.\n\n!--more--\n\nhugo-lunr\n\nhugo-lunr - A simple way to add site search to your static Hugo site using lunr.js. Hugo-lunr will create an index file of any html and markdown documents in your Hugo project\n\n implementation\n\nsource code\n\nHow to Make lunr.js and Jekyll Work Together (with Gotchas)",
        "tags": []
    },
    {
        "uri": "/post/The-Difference-Between-Throttling-and-Debouncing",
        "title": "The difference between throttling and debouncing",
        "content": "\nOne of the biggest mistakes I see when looking to optimize existing code is the absence of the debounce/throttle function. Both of them are ways to limit the amount of JavaScript you are executing based on DOM events for performance reasons. But they are, you guessed it, different.\n\n!--more--\n\nThrottle\n\n \"Execute this function at most once every 100 milliseconds\"\n\nThrottling enforces a maximum number of times a function can be called over time. \n\nSay under normal circumstances you would call this function 1,000 times over 10 seconds. If you throttle it to only once per 100 milliseconds, it would only execute that function at most 100 times:\n\n10s * 1,000 calls = 10,000ms\n10,000ms / 100ms throttling = 100 maximum calls\n\n Debounce\n\n \"Execute this function only if 100 milliseconds have passed without it being called\"\n\nDebouncing enforces that a function not be called again until a certain amount of time has passed without it being called. \n\nPerhaps a function is called 1,000 times in a quick burst, dispersed over 3 seconds, then stops being called. \n\nIf you have debounced it at 100 milliseconds, the function will only fire once, at 3.1 seconds, once the burst is over. Each time the function is called during the burst it resets the debouncing timer.\n\nWhat's the point?\n\nOne major use case for these concepts is certain DOM events, like scrolling and resizing. For instance, if you attach a scroll handler to an element, and scroll that element down say 5000px, you're likely to see 100+ events be fired. If your event handler does a bunch of work (like heavy calculations and other DOM manipulation), you may see performance issues (jank). \n\nQuick hit examples:\n\nWait until the user stops resizing the window\nDon't fire an ajax event until the user stops typing\nMeasure the scroll position of the page and respond at most every 50ms\nEnsure good performance as you drag elements around in an app\n\n How to do it\n\nWith lodash\n\nDebounce and throttle:\n\n$(\"body\").on('scroll', _.throttle(function() {\n  // Do expensive things\n}, 100));\n\n$(window).on('resize', _.debounce(function() {\n  // Do expensive things\n}, 100));\n\n Vanilla JS debounce\n\n// Returns a function, that, as long as it continues to be invoked, will not\n// be triggered. The function will be called after it stops being called for\n// N milliseconds. If immediate is passed, trigger the function on the\n// leading edge, instead of the trailing.\nfunction debounce(func, wait, immediate) {\n    var timeout;\n    return function() {\n        var context = this, args = arguments;\n        var later = function() {\n            timeout = null;\n            if (!immediate) func.apply(context, args);\n        };\n        var callNow = immediate && !timeout;\n        clearTimeout(timeout);\n        timeout = setTimeout(later, wait);\n        if (callNow) func.apply(context, args);\n    };\n};\n\nYou'll pass the debounce function the function to execute and the fire rate limit in milliseconds. Here's an example usage:\n\nvar myEfficientFn = debounce(function() {\n    // All the taxing stuff you do\n}, 250);\n\nwindow.addEventListener('resize', myEfficientFn);\n\nVanilla JS throttle\n\nBelow is an actual throttle function, that fires a message every 250ms by default (rather than at the end of a burst of events):\n\nfunction throttle(fn, threshhold, scope) {\n  threshhold || (threshhold = 250);\n  var last,\n      deferTimer;\n  return function () {\n    var context = scope || this;\n\n    var now = Date.now(),\n        args = arguments;\n    if (last && now < last + threshhold) {\n      // hold on to it\n      clearTimeout(deferTimer);\n      deferTimer = setTimeout(function () {\n        last = now;\n        fn.apply(context, args);\n      }, threshhold);\n    } else {\n      last = now;\n      fn.apply(context, args);\n    }\n  };\n}\n\n$('body').on('mousemove', throttle(function (event) {\n  console.log('tick');\n}, 1000));\n\n Demo\n\np data-height=\"710\" data-theme-id=\"10606\" data-slug-hash=\"GoPGrx\" data-default-tab=\"result\" data-user=\"qetr1ck-op\" class='codepen'See the Pen a href='http://codepen.io/qetr1ck-op/pen/GoPGrx/'The Difference Between Throttling, Debouncing, and Neither/a by qetr1ck-op (a href='http://codepen.io/qetr1ck-op'@qetr1ck-op/a) on a href='http://codepen.io'CodePen/a./p\nscript async src=\"//assets.codepen.io/assets/embed/ei.js\"/script",
        "tags": []
    },
    {
        "uri": "/post/top-10-mistakes-when-you-develop-on-angularjs",
        "title": "TOP 10 mistakes when you develop on AngularJS",
        "content": "\nThe top 10 mistakes when beginners start to develop on AngularJS.\n\n!--more--\n\nMVC directory structure\n\nWhen you work with MVC / MVW frameworks it's convenience to structure code by MVC components using the following template:\n\ntemplates/\n├───login.html\n└───feed.html\napp/\n├───app.js\n└───controllers/\n    ├───LoginController.js\n    └───FeedController.js\n    directives/\n    └───FeedEntryDirective.js\n    services/\n    ├───LoginService.js\n    └───FeedService.js\n    filters/\n    └───CapitalizeFilter.js\n\nBut when project will rise it's hard to use such structure of folders. You always need to open a few folder at the same time. It isn't depend what IDE or tool you use (Sublime, VS, Vim with NerdTree) - it's uncomfortable.\n\nTo avoid this this developers often use grouping by functionality type:\n\napp/\n├───app.js\n└───Feed/\n    ├───feed.html\n    ├───FeedController.js\n    ├───FeedEntryDirective.js\n    └───FeedService.js\n    Login/\n    ├───_login.html\n    ├───LoginController.js\n    └───LoginService.js\n    Shared/\n    └───CapitalizeFilter.js\n\nThe structure allows more faster search for files which are related to the same feature. It may puzzled at the beginning to share js with html or even with test files. But it saves a lot of time, because it's more natural.\n\n  Not scalable Modules\n\nAt the beginning of development all functionalities include in a single module. But manage a such type of code is inconvenient:\n\nlet app = angular.module('app',[]);\napp.service('MyService', function(){\n    //service code\n});\n\napp.controller('MyCtrl', function($scope, MyService){\n    //controller code\n});\n\nThe next most common approach is grouping objects by type:\n\nlet services = angular.module('services',[]);\nservices.service('MyService', function(){\n    //service code\n});\n\nlet controllers = angular.module('controllers', ['services']);\ncontrollers.controller('MyCtrl', function($scope, MyService){\n    //controller code\n});\n\nlet app = angular.module('app', ['controllers', 'services']);\n\nFor better scalability and future re-usability - split code by feature:\n\nlet sharedServicesModule = angular.module('sharedServices',[]);\nsharedServices.service('NetworkService', function($http){});\n\nlet loginModule = angular.module('login', ['sharedServices']);\nloginModule.service('loginService', function(NetworkService){});\nloginModule.controller('loginCtrl', function($scope, loginService){});\n\nlet app = angular.module('app', ['sharedServices', 'login']);\n\nMinification with Dependency Injection\n\nPattern DI in AngularJS uses out of box. DI helps to keep code clean and helps with testing process.\n\nlet app = angular.module('app',[]);\napp.controller('MainCtrl', function($scope, $timeout) { //MainCtrl has dependency on $scope and $timeout\n    $timeout(function(){\n        console.log($scope);\n    }, );\n});\n\n//And code after minification:\n\nlet app=angular.module(\"app\",[]);app.controller(\"MainCtrl\",function(e,t){t(function(){console.log(e)})})\n\nNow AngularJS can't resolve minificated variables. Easiest solution is:\n\napp.controller('MainCtrl', ['$scope', '$timeout', function($scope, $timeout){\n    $timeout(function() {\n        console.log($scope);\n    });\n}]);\n\n//another best practice approach with $inject\n\napp.controller('MainCtrl', mainCtrl);\n\nmainCtrl.$inject = ['$scope', '$timeout'];\n\nfunction mainCtrl($scope, $timeout) {\n     $timeout(function() {\n        console.log($scope);\n    });\n}\n\nNow Angular can resolve dependency.\n\nAnother way to handle DI with minification is ng-annotate module. More information on official AngularJS docs\n\n Global Dependencies\n\nOften when writing AngularJS apps there will be a dependency on an object that binds itself to the global scope. This means it's available in any AngularJS code, but this breaks the dependency injection model.\n\nAngularJS makes it simple to encapsulate these globals into modules so they can be injected like standard AngularJS modules:\n\nlet underscore = angular.module('underscore', []);\nunderscore.factory('_', function() {\n    return window._; //Underscore must already be loaded on the page\n});\n\nlet app = angular.module('app', ['underscore']);\n\napp.controller('MainCtrl', ['$scope', '_', function($scope, _) {\n    init = function() {\n        _.keys($scope);\n    }\n\n    init();\n}]);\n\nFat controllers\n\nIt's easy, especially when starting out, to put to much logic in the controller. Controller should never do a DOM manipulation. That's work for directives! Likewise business logic should live in services.\n\nApp data should be also stored and fetched in services, except when we need bound to the $scope. Services are singletons that persist throughout the lifetime of the application, while controllers are transient between application states. If data is stored in the controller then it will need to be fetched from somewhere when it is instantiate.\n\nAngularJS works best when following the Single Responsibility Principle (SRP). If the controller is a coordinator between the view and the model, then the amount of logic it has should be minimal. This will also make testing much simpler.\n\n Service vs Factory vs Provider\n\nWhat is service:\n\nIt provides methods to keep, share and organize data across the lifetime of the Angular app\nLazy loads, Angular only creates instance of a service when an application component depends on it\nSingleton object, application component dependent on the service work with the single instance\n\nAn Angular service can be created in five different ways:\n\nservice\nfactory\nprovider\nvalue\nconstant\n\nThe most verbose, but also the most comprehensive one is a Provider recipe. The remaining four recipe types — Value, Factory, Service and Constant — are just syntactic sugar on top of a provider recipe.\n\nHere is a great examples by Misko:\n\nmodule.value('a', 123);\nmodule.constant('A', 321); //can't modify with a decorator\n\nfunction Controller(a, A) {\n    expect(a).toEqual(123);\n    expect(A).toEqual(231);\n}\n\nIn this case the injectors simply return the value. But what if you want to compute the value?\n\nmodule.factory('b', function(a) {\n    return a*2;\n});\n\nfunction Controller(b) {\n    expect(b).toEqual(246);\n}\n\nSo factory is a function which responsible to creating or/and modifying the value. Notice that the the factory function can ask for other dependencies\n\nIf you want to be more OO and have a class?\n\nmodule.factory('greeterFactory', function(a) {\n    function Greeter(a) {\n        this.greet = function() {\n            return 'Hello ' + a;\n        }\n    }\n    \n    return new Greeter(a);\n});\n\n//or with service\nmodule.service('greeterService', function(a) {\n    this.greet = function() {\n        return 'Hello ' + a;\n    }\n});\n\nfunction Controller(greeterFactory, greeterService) {\n    expect(greeter instanceof Greeter).toBe(true);\n    expect(greeter.greet()).toEqual('Hello 123');\n    \n    const greeter2 = new greeter2;\n    expect(greeter2 instanceof greeterFactory).toBe(true);\n    expect(greeter2.greet()).toEqual('Hello 123');\n}\n\nBut if we want to configure service function before injection? Use provider:\n\nmodule.provider('greeter3', function() {\n    var salutation = 'Hello';\n    this.setSalutation = function(s) {\n        salutation = s;\n    }\n\n    function Greeter(a) {\n        this.greet = function() {\n            return ${salutation} ${a};\n        }\n    }\n\n    this.$get = function(a) {\n        return new Greeter(a);\n    };\n});\n\n// configuration in config phase\nmodule('abc', []).config(function(greeter3Provider) {\n    greeter3Provider.setSalutation('Halo');\n});\n\nfunction Controller(greeter2) {\n    expect(greeter2.greet()).toEqual('Halo 123');\n}\n\nAs a side note, service, factory, and value are all derived from provider:\n\nmodule.service = function(name, Class) {\n    provider.provide(name, function() {\n        this.$get = function($injector) {\n            return $injector.instantiate(Class);\n        };\n    });\n}\n\nmodule.factory = function(name, factory) {\n    provider.provide(name, function() {\n        this.$get = function($injector) {\n            return $injector.invoke(factory);\n        };\n    });\n}\n\nmodule.value = function(name, value) {\n    provider.factory(name, function() {\n        return value;\n    });\n};\n\nAlways dot in VM $scope's\n\nIn AngularJS every $scope prototypical inherits from its parent $scope till the highest level $rootScope.\n\ndiv ng-controller=\"navCtrl\"\n   span{{user}}/span !-- won't be updating --\n   div ng-controller=\"loginCtrl\"\n      span{{user}}/span\n      input ng-model=\"user\"/input !-- changes update only loginCtrl scope --\n   /div\n/div\n\nWhen looking up for primitive value, the prototype chain is not consulted. If navCtrl updated simultaneously then a prototype chain lookup is required, this won't happen when the value is an object:\n\ndiv ng-controller=\"navCtrl\"\n   span{{user.name}}/span\n   div ng-controller=\"loginCtrl\"\n      span{{user.name}}/span\n      input ng-model=\"user.name\"/input\n   /div\n/div\n\n Unit testing AngularJS apps\n\nJavaScript is a dynamically typed language which comes with great power of expression, but it also comes with almost no help from the compiler.\nFor this reason we feel very strongly that any code written in JavaScript needs to come with a strong set of tests.\n\nNot to do an end-to-end testing with Protractor\n\nProtractor uses the Jasmine test framework for defining tests. Protractor has a very robust API for different page interactions.\nThere are other end to end test tools, but Protractor has the advantage of understanding how to work with AngularJS code, especially when it comes to $digest cycles and more.\n\n Full-Spectrum Testing with Karma\n\nAwesome post about testing AngularJS with Karma, passage from the post:\n\nKarma is an amazing testing tool which is designed to take all the frustration out of setting up a working test runner when testing JavaScript code.\nKarma works by spawning up each browser that is specified within its configuration file and then running JavaScript code against those browsers to see if they pass certain tests.\nCommunication between Karma and each of the browsers is handled with the karma service running in the terminal using socket.io.\nEach time a test is run, Karma records its status and then tallies up which browsers have failed for each test and which ones passed and timed out.\nThis makes each test work 100% natively in each browser without the need to test individually.\nAlso, since the Karma service runs on a port and keeps track of browsers by itself, you can easily hook up other browsers and devices to it just by visiting its broadcasting port.\nOh and did I mention that Karma is fast? Yeah it's really fast...\n\nUsing jQuery\n\nAngularJS is a framework for building scalable apps. jQuery is a famous library for simplifying DOM manipulation, event handling, AJAX operation.\n\nAngularJS is about architecture of app, not augmenting HTML pages.\n\nTry to stop using jQuery and imperative paradigm, just let your code to extend HTML syntax in declarative style.\n\nDOM manipulation should only be done in directives, but this doesn't mean they have to be jQuery wrappers. Always consider what features AngularJS already provides before reaching for jQuery.\n\nSave my day:\n\nOriginal post",
        "tags": []
    },
    {
        "uri": "/post/Understanding-Components-approach-and-Thinking-in-React",
        "title": "Understanding components approach and thinking in React",
        "content": "\nThe parts of a web user interface building blocks for both simple websites and modern front-end applications. \n\n!--more--\n\nUnderstanding Components\n\nThese parts are commonly referred to as UI components or UI widgets. The browser offers many native components and, when these are not enough, custom components like Bootstrap, Kendo UI, Semantic UI, UI Kit can be used.\n\nUI component is a region in a web page that contains an isolated UI feature that is distinct from everything around it. For example, an HTML select element is considered a native HTML UI component.\n\nAn HTML select element can be placed into a web page and a developer gets:\n\nAn isolated, reusable, and decoupled instance of a select with no side effects;\nA default styled UI element that a user can interact with;\nConfiguration that affects the state via properties that are passed declaratively to the component by way of HTML attributes, text, and child components (i.e. option) that can contain attributes and text as well;\nAn API to imperatively program the component, affecting state, via the DOM and JavaScript (i.e. DOM events and methods).\n\nThe main primitive (speaking about React, Angular & Ember) is this idea of a component. I think everyone has some notion of what a component is. The idea is that it should be an atomic UI piece that is composable and reusable, and should work with other pieces.\n\n \"We’re not designing pages, we’re designing systems of components\"\n\n Thinking in React\n\nOne of the many great parts of React is how it makes you think about apps as you build them. I'll walk through the process of building a searchable product data table using React.\n\nStart with a mock\n\nImagine that we already have a JSON API which returns some data that looks like this:\n\n[\n  {category: \"Sporting Goods\", price: \"$49.99\", stocked: true, name: \"Football\"},\n  {category: \"Sporting Goods\", price: \"$9.99\", stocked: true, name: \"Baseball\"},\n  {category: \"Sporting Goods\", price: \"$29.99\", stocked: false, name: \"Basketball\"},\n  {category: \"Electronics\", price: \"$99.99\", stocked: true, name: \"iPod Touch\"},\n  {category: \"Electronics\", price: \"$399.99\", stocked: false, name: \"iPhone 5\"},\n  {category: \"Electronics\", price: \"$199.99\", stocked: true, name: \"Nexus 7\"}\n];\n\n Step 1: break the UI into a component hierarchy\n\nThe first thing you'll want to do is to draw boxes around every component (and subcomponent) in the mock and give them all names. \n\nBut how do you know what should be its own component? \n\nJust use the same techniques for deciding if you should create a new function or object. One such technique is the single responsibility principle, that is, a component should ideally only do one thing. If it ends up growing, it should be decomposed into smaller subcomponents.\n\nComponents that appear within another component in the mock should appear as a child in the hierarchy:\n\nFilterableProductTable\n    SearchBar\n    ProductTable\n        ProductCategoryRow\n        ProductRow\n\nStep 2: Build a static version in React\n\nscript async src=\"//jsfiddle.net/qetr1ck/voyqdw3f/embed/js,html,css,result/dark/\"/script\n\nTo build a static version of your app that renders your data model, you'll want to build components that reuse other components and pass data using props. props are a way of passing data from parent to child. \n\nState is reserved only for interactivity, that is, data that changes over time. Since this is a static version of the app, you don't need it here.\n\n Step 3: Identify the minimal representation of UI state\n\nTo make your UI interactive, you need to be able to trigger changes to your underlying data model. React makes this easy with state.\n\nThink of all of the pieces of data in our example application. We have:\n\nThe original list of products\nThe search text the user has entered\nThe value of the checkbox\nThe filtered list of products\n\nLet's go through each one and figure out which one is state. Simply ask three questions about each piece of data:\n\nIs it passed in from a parent via props? If so, it probably isn't state.\nDoes it change over time? If not, it probably isn't state.\nCan you compute it based on any other state or props in your component? If so, it's not state.\n\nSo finally, our state is:\n\nThe search text the user has entered\nThe value of the checkbox\n\nStep 4: Identify where your state should live\n\nThis is often the most challenging part for newcomers to understand, so follow these steps to figure it out:\n\nIdentify every component that renders something based on that state.\nFind a common owner component (a single component above all the components that need the state in the hierarchy).\nIf you can't find a component where it makes sense to own the state, create a new component simply for holding the state.\n\nLet's run through this strategy for our application:\n\nProductTable needs to filter the product list based on state and SearchBar needs to display the search text and checked state.\nThe common owner component is FilterableProductTable.\nIt conceptually makes sense for the filter text and checked value to live in FilterableProductTable\n \nWe've decided that our state lives in FilterableProductTable. First, add a getInitialState() method to FilterableProductTable that returns {filterText: '', inStockOnly: false} to reflect the initial state of your application. \n\nThen, pass filterText and inStockOnly to ProductTable and SearchBar as a prop. Finally, use these props to filter the rows in ProductTable and set the values of the form fields in SearchBar.\n\n Step 5: Add inverse data flow\n\nNow it's time to support data flowing the other way: the form components deep in the hierarchy need to update the state in FilterableProductTable.\n\nIf you try to type or check the box in the previous version of the example, you'll see that React ignores your input. This is intentional, as we've set the value prop of the input to always be equal to the state passed in from FilterableProductTable.\n\nSince components should only update their own state, FilterableProductTable will pass a callback to SearchBar that will fire whenever the state should be updated. We can use the onChange event on the inputs to be notified of it. And the callback passed by FilterableProductTable will call setState(), and the app will be updated.\n\nscript async src=\"//jsfiddle.net/qetr1ck/voyqdw3f/3/embed/js,html,result/dark/\"/script",
        "tags": []
    },
    {
        "uri": "/post/units-of-measurement-px-em-rem-and-other",
        "title": "Units of measurement: \"px\", \"em\", \"rem\" and other",
        "content": "\nI will try not only to write about variety of units, but also build a full picture - what and when better to choose.\n\n!--more--\n\nPixels: \"px\"\n\nPixel px - is the most basic, absolute and final unit of measurement.\n\nThe number of pixels on monitor is set in screen resolution configuration. A px is such a one pixel on the screen. All values browser eventually translated into pixels.\n\nThe main advantage px is clarity.\n\nThe px are not relative and don't allow to set relationships between other dimensions.\n\n Relatively to font size: \"em\"\n\nMeasurement in em are relative, they are defined by current context.\n\n1em it's current font size.\n\nSince the value of em is calculated to the current font size, the nested string will 1.5 times larger than parent:\n\ndiv style=\"font-size:1.5em\"\n  My size is 1.5em\n  div style=\"font-size:1.5em\"My size is parrentSize * 1.5/div\n/div\n\nPercentage, \"%\"\n\nThe % as the em are relative to current context measurements but there are nuances.\n\nIs works different with these properties: margin-left, line-height, width/height with position: fixed.\n\nThe same example:\n\ndiv style=\"font-size:150%\"\n  My size is 1.5em\n  div style=\"font-size:150%\"My size is parrentSize + 150%/div\n/div\n\n Mixture of \"px\" and \"em\": \"rem\"\n\nMeasure rem defines font size relatively to html element size.\n\np data-height=\"268\" data-theme-id=\"10606\" data-slug-hash=\"bVzVaQ\" data-default-tab=\"result\" data-user=\"qetr1ck-op\" class='codepen'See the Pen a href='http://codepen.io/qetr1ck-op/pen/bVzVaQ/'em vs rem/a by qetr1ck-op (a href='http://codepen.io/qetr1ck-op'@qetr1ck-op/a) on a href='http://codepen.io'CodePen/a./p\nscript async src=\"//assets.codepen.io/assets/embed/ei.js\"/script\n\nRelatively to screen size: vw, vh, vmin, vmax\n\nThe principles behind vw, vh are to represent percentage of browser viewport width / height.\n\n1vw = 1/100 of the current viewport width, i.e. 1% of width.\n\n10vh = 10/100 of the current viewport height, i.e. 10% of height.\n\nAfter first glance, it seems that vw, vh are redundant, because we already have % measurement system:\n\ndiv {\n  width: 100%;\n}\n\nLimitation of percentage measurement system:\n\nviewport height is always hard to measure, as the height of body depends on content, not on the dimension of the browser window\n\nbody measurement cannot be applied to the font-size, because it relates to parent container, not to the dimension of viewport\n\nExample, backgrounds and vh:\n\np data-height=\"268\" data-theme-id=\"10606\" data-slug-hash=\"ZbdWvp\" data-default-tab=\"result\" data-user=\"qetr1ck-op\" class='codepen'See the Pen a href='http://codepen.io/qetr1ck-op/pen/ZbdWvp/'Backgrounds and the vh unit /a by qetr1ck-op (a href='http://codepen.io/qetr1ck-op'@qetr1ck-op/a) on a href='http://codepen.io'CodePen/a./p\nscript async src=\"//assets.codepen.io/assets/embed/ei.js\"/script\n\nExample, backgrounds and vw:\n\np data-height=\"268\" data-theme-id=\"10606\" data-slug-hash=\"xwoVPX\" data-default-tab=\"result\" data-user=\"qetr1ck-op\" class='codepen'See the Pen a href='http://codepen.io/qetr1ck-op/pen/xwoVPX/'Backgrounds and the vw unit /a by qetr1ck-op (a href='http://codepen.io/qetr1ck-op'@qetr1ck-op/a) on a href='http://codepen.io'CodePen/a./p\nscript async src=\"//assets.codepen.io/assets/embed/ei.js\"/script\n\nImage, vw:\n\np data-height=\"268\" data-theme-id=\"10606\" data-slug-hash=\"bVPpaX\" data-default-tab=\"result\" data-user=\"qetr1ck-op\" class='codepen'See the Pen a href='http://codepen.io/qetr1ck-op/pen/bVPpaX/'Images and vw width /a by qetr1ck-op (a href='http://codepen.io/qetr1ck-op'@qetr1ck-op/a) on a href='http://codepen.io'CodePen/a./p\nscript async src=\"//assets.codepen.io/assets/embed/ei.js\"/script\n\nRespectively are related to the maximum or minimum of those widths and heights, depending on which is smaller and larger. For example, if the browser was set to 1100px wide and the 700px tall, 1vmin would be 7px and 1vmax would be 11px.\n\n1vmin = 1vw or 1vh, whichever is smaller\n1vmax = 1vw or 1vh, whichever is larger",
        "tags": []
    },
    {
        "uri": "/post/web-services-WSDL-SOAP-envelope-with-JavaScript",
        "title": "Web Services, WSDL, SOAP envelope with JavaScript",
        "content": "\nThe main concept of Web Services is to exchange data between two devices using standardized protocols and messages.\n\n!--more--\n\nWhat is Web Service and WSDL?\n\nThe W3C defines a Web services: a software system designed to support machine-to-machine interaction over network. Other systems interact with the Web service using SOAP messages, REST, or using HTTP with an XML serialization with other Web-related standards.\n\nAnd for be little clear about WSDL (Web Services Description Language) - describes services as collection of network endpoints or ports in XML format.\n\nExchange messages usually accomplished by protocol HTTP. However, it should be noted that it is still used, but very rarely, protocol - SMTP (Simple Mail Transfer Protocol).\n\n SOAP protocol\n\nProtocol SOAP transfers messages or small amount of information. SOAP messages formatted in XML and are typically send using HTTP. Some time ago SOAP was spelled as Simply Object Access Protocol. But time passed and everybody saws that protocol isn't simple and nothingness in common with access to objects.\n\nimg alt=\"post-img\" src=\"images/posts/web-services-WSDL-SOAP-envelope-with-JavaScript/soaps.jpg\" alt=\"SOAP is just a soap\"\n\nExample of SOAP envelope\n\nThe SOAP message has 3 parts: envelope, head, body. Body contains all response/request data. Also can say that head isn't required and in modern apps doesn't used.\n\nimg alt=\"post-img\" src=\"images/posts/web-services-WSDL-SOAP-envelope-with-JavaScript/soap-message.gif\" alt=\"Example of SOAP envelope\"\n\nExample of SOAP XML:\n\n?xml version=\"1.0\" encoding=\"utf-8\" ?\n<soapenv:Envelope\n\txmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n\txmlns:xsd=\"http://www.w3.org/2001/XMLSchema\"\n\txmlns:soapenv=\"http://schemas.xmlsoap.org/soap/envelope/\"\n\txmlns:urn=\"urn:WebservicesName\" !-- service name --\n\tsoap:Header\n\t    m:Trans xmlns:m=\"http://schemas.xmlsoap.org/soap/encoding/\"Header/m:Trans\n        /soap:Header\n\tsoapenv:Body\n\t\t!-- method name --\n\t\t<urn:ProductService.getProductByHash\n\t\t\tsoapenv:encodingStyle=\"http://schemas.xmlsoap.org/soap/encoding/\"\n\t\t\t!-- request to server --\n\t\t\treturn xsi:type=\"getProductByHash \"\n\t\t\t\tproducthash xsi:type=\"xsd:string\"product hash here!/producthash\n\t\t\t/return\n\t\t/urn:ProductService.getProductByHash\n\t/soapenv:Body\n/soapenv:Envelope\n\nWhat here have happened? In the beginning I created SOAP envelope, which call service with URN (Uniform Resource Name). Then calling method getProductByHash.\n\nSOAP response of web-service have next view, only body tag:\n\nsoapenv:Body\n\t<urn:ProductService.getProductByHash\n\t\tsoapenv:encodingStyle=\"http://schemas.xmlsoap.org/soap/encoding/\"\n\t\treturn xsi:type=\"getProductByHash \".\n\t\t  !-- response example --\n\t\t\tproductid xsi:type=\"xsd:string\"260891/emagid\n\t\t/return\n\t/urn:ProductService.getProductByHash\n/soapenv:Body\n\nCreate/receive SOAP request/response via $.soap\n\nThis script uses $.ajax to send a SOAP envelope. It can take XML DOM, XML string or JSON as input and the response can be returned as either XML DOM, XML string or JSON too.\n\nExample:\n\n$.soap({\n    url: 'http://my.server.com/soapservices/',\n    method: 'helloWorld',\n\n    data: {\n        name: 'Remy Blom',\n        msg: 'Hi!'\n    },\n\n    success: function (soapResponse) {\n        // do stuff with soapResponse\n        // if you want to have the response as JSON use soapResponse.toJSON();\n        // or soapResponse.toString() to get XML string\n        // or soapResponse.toXML() to get XML DOM\n    },\n    error: function (SOAPResponse) {\n        // show error\n    }\n})\n\nFull a href=\"https://github.com/doedje/jquery.soap\"$.soap/a documentation.\n",
        "tags": []
    },
    {
        "uri": "/post/what-is-event-bubbling-and-capturing",
        "title": "What is event bubbling and capturing?",
        "content": "\nEvent bubbling and capturing are two ways of event propagation in the HTML DOM API.\n\n!--more--\n\nWhen an event occurs in an element inside another element, and both elements have registered a handle for that event. The event propagation mode determines in which order the elements receive the event.\n\nWith bubbling, the event is first captured and handled by the innermost element and then propagated to outer elements.\nWith capturing, the event is first captured by the outermost element and propagated to the inner elements.\n\nCapturing is also called trickling, which helps remember the propagation order:\n\n \"trickle down, bubble up\"\n\nBack in the old days, Netscape advocated event capturing, while Microsoft promoted event bubbling. Both are part of the W3C Document Object Model Events standard (2000).\n\nIE < 9 uses only event bubbling, whereas IE9+ and all major browsers support both. \n\nWe can use the addEventListener(type, listener, useCapture) to register event handlers for in either bubbling (default) or capturing mode. To use the capturing model pass the third argument as true.\n\nscript async src=\"//jsfiddle.net/qetr1ck/2chdLb0d/1/embed/result,js,html,css/dark/\"/script\n\nWhat to use?\n\nIt depends on what you want to do. There is no better. The difference is the order of the execution of the event handlers. Most of the time it will be fine to fire event handlers in the bubbling phase but it can also be necessary to fire them earlier.",
        "tags": []
    },
    {
        "uri": "/search",
        "title": "",
        "content": "",
        "tags": []
    }
]